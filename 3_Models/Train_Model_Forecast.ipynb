{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Forecast Model - Daily\n",
    "\n",
    "In this notebook we'll train a deep learning model that learns if a target price or stop loss would be hit for a long/short trade in the next days based on historical price data.\n",
    "\n",
    "Model:\n",
    "* Multilayer Perceptron (MLP) (Feedforward neural network)\n",
    "* 3 layers: input, hidden, output\n",
    "* Binary Classification\n",
    "* `Input`: Close, SMA(2 to 16), ROC(2 to 16)\n",
    "* `Output`: Does a long or short trade hit the profit target (2%) without hitting a stop loss (1.5%) in the next five days?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_long_short_predict\n"
     ]
    }
   ],
   "source": [
    "%run ../2_Strategies/init_model.py 'model_long_short_predict'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting local/model_long_short_predict/input/config/hyperparameters.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile local/{model_name}/input/config/hyperparameters.json\n",
    "{ \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1) Get Data from Athena and S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'algotrading-demo-ver1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get S3 bucket\n",
    "s3bucket=!(aws s3 ls | grep algotrading- | awk  '{print $3}')\n",
    "s3bucket=s3bucket[0]\n",
    "s3bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyAthena in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (3.14.1)\n",
      "Requirement already satisfied: boto3>=1.26.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from PyAthena) (1.38.30)\n",
      "Requirement already satisfied: botocore>=1.29.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from PyAthena) (1.38.30)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from PyAthena) (2025.5.1)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from PyAthena) (2.9.0)\n",
      "Requirement already satisfied: tenacity>=4.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from PyAthena) (9.1.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.26.4->PyAthena) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3>=1.26.4->PyAthena) (0.13.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore>=1.29.4->PyAthena) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil->PyAthena) (1.17.0)\n",
      "Requirement already satisfied: numexpr in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (2.11.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from numexpr) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install PyAthena\n",
    "!{sys.executable} -m pip install --upgrade numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "region = sess.boto_session.region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-13</th>\n",
       "      <td>26.76</td>\n",
       "      <td>26.83</td>\n",
       "      <td>26.41</td>\n",
       "      <td>26.69</td>\n",
       "      <td>23623918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-14</th>\n",
       "      <td>26.80</td>\n",
       "      <td>26.81</td>\n",
       "      <td>26.38</td>\n",
       "      <td>26.48</td>\n",
       "      <td>27477260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-15</th>\n",
       "      <td>26.23</td>\n",
       "      <td>26.47</td>\n",
       "      <td>26.19</td>\n",
       "      <td>26.27</td>\n",
       "      <td>26081909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-16</th>\n",
       "      <td>26.44</td>\n",
       "      <td>26.65</td>\n",
       "      <td>26.34</td>\n",
       "      <td>26.59</td>\n",
       "      <td>25702363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-17</th>\n",
       "      <td>26.57</td>\n",
       "      <td>26.63</td>\n",
       "      <td>26.21</td>\n",
       "      <td>26.33</td>\n",
       "      <td>30379903.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close         vol\n",
       "dt                                                \n",
       "2012-08-13  26.76  26.83  26.41  26.69  23623918.0\n",
       "2012-08-14  26.80  26.81  26.38  26.48  27477260.0\n",
       "2012-08-15  26.23  26.47  26.19  26.27  26081909.0\n",
       "2012-08-16  26.44  26.65  26.34  26.59  25702363.0\n",
       "2012-08-17  26.57  26.63  26.21  26.33  30379903.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from pyathena import connect\n",
    "connection_string = 'awsathena+rest://@'+region+'?s3_staging_dir=s3://'+s3bucket+'/results/'\n",
    "engine = create_engine(connection_string)\n",
    "df = pd.read_sql(\"SELECT dt,open,high,low,close,vol FROM algo_data.hist_data_daily;\", engine)\n",
    "df.set_index(pd.DatetimeIndex(df['dt']),inplace=True)\n",
    "del df['dt']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=1825\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-08-13</th>\n",
       "      <td>26.76</td>\n",
       "      <td>26.83</td>\n",
       "      <td>26.41</td>\n",
       "      <td>26.69</td>\n",
       "      <td>23623918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-14</th>\n",
       "      <td>26.80</td>\n",
       "      <td>26.81</td>\n",
       "      <td>26.38</td>\n",
       "      <td>26.48</td>\n",
       "      <td>27477260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-15</th>\n",
       "      <td>26.23</td>\n",
       "      <td>26.47</td>\n",
       "      <td>26.19</td>\n",
       "      <td>26.27</td>\n",
       "      <td>26081909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-16</th>\n",
       "      <td>26.44</td>\n",
       "      <td>26.65</td>\n",
       "      <td>26.34</td>\n",
       "      <td>26.59</td>\n",
       "      <td>25702363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-08-17</th>\n",
       "      <td>26.57</td>\n",
       "      <td>26.63</td>\n",
       "      <td>26.21</td>\n",
       "      <td>26.33</td>\n",
       "      <td>30379903.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             open   high    low  close         vol\n",
       "dt                                                \n",
       "2012-08-13  26.76  26.83  26.41  26.69  23623918.0\n",
       "2012-08-14  26.80  26.81  26.38  26.48  27477260.0\n",
       "2012-08-15  26.23  26.47  26.19  26.27  26081909.0\n",
       "2012-08-16  26.44  26.65  26.34  26.59  25702363.0\n",
       "2012-08-17  26.57  26.63  26.21  26.33  30379903.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv('local/'+model_name+'/input/data/training/data_orig.csv')\n",
    "print(\"count=%s\" % len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='dt'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df[\"close\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2) Run Data Preparation Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify Data Preparation Code\n",
    "\n",
    "In the following cell, you can modify the data preparation code or leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/model_long_short_predict_prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/{model_name}_prep.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import talib as ta\n",
    "from talib.abstract import *\n",
    "import math\n",
    "\n",
    "prefix = '/opt/ml/'\n",
    "input_path = prefix + 'input/data/training'\n",
    "\n",
    "data_orig_file = input_path+'/data_orig.csv'\n",
    "data_file = input_path+'/data.csv'\n",
    "\n",
    "d = pd.read_csv(data_orig_file,infer_datetime_format=True, parse_dates=['dt'], index_col=['dt'])\n",
    "print(d.head())\n",
    "\n",
    "repeatCount=15\n",
    "repeatStep=1\n",
    "lookBack=repeatCount*repeatStep\n",
    "forwardWindow=5\n",
    "\n",
    "profitTarget=2.0/100.0\n",
    "stopTarget=1.5/100.0\n",
    "\n",
    "iCount=lookBack\n",
    "\n",
    "# header\n",
    "hData=[\"dt\"]\n",
    "hData.append(\"close\")\n",
    "for a in range(0,repeatCount):\n",
    "    hData.append(\"sma\"+str((a+2)*repeatStep))\n",
    "for a in range(0,repeatCount):\n",
    "    hData.append(\"roc\"+str((a+2)*repeatStep))\n",
    "hData.append(\"long\")\n",
    "hData.append(\"short\")\n",
    "\n",
    "# data\n",
    "tData=[]\n",
    "\n",
    "inputs = {\n",
    "    'close': np.array(d[\"close\"])\n",
    "}\n",
    "sma=[]\n",
    "for a in range(0,repeatCount):\n",
    "    sma.append(SMA(inputs,timeperiod=(a+1)*repeatStep+1))\n",
    "roc=[]\n",
    "for a in range(0,repeatCount):\n",
    "    roc.append(ROC(inputs,timeperiod=(a+1)*repeatStep+1))\n",
    "\n",
    "closeList=d[\"close\"]\n",
    "dLen=len(d)\n",
    "n=0\n",
    "lCount=0\n",
    "sCount=0\n",
    "nCount=0\n",
    "n=0\n",
    "for idx,row in d.iterrows():\n",
    "    if n<dLen-forwardWindow-1:\n",
    "        dt1=idx\n",
    "        cl=row[\"close\"]\n",
    "        inputRec=[]\n",
    "        inputRec.append(idx)\n",
    "\n",
    "        inputRec0=[]\n",
    "\n",
    "        #close\n",
    "        inputRec0.append(cl)\n",
    "\n",
    "        #sma\n",
    "        for a in range(0,repeatCount):\n",
    "            if math.isnan(sma[a][n]):\n",
    "                inputRec0.append(cl)\n",
    "            else:\n",
    "                inputRec0.append(sma[a][n])\n",
    "\n",
    "        m1=min(inputRec0)\n",
    "        m2=max(inputRec0)\n",
    "        for a in inputRec0:\n",
    "            if m2-m1==0:\n",
    "                inputRec.append(0)\n",
    "            else:\n",
    "                inputRec.append((a-m1)/(m2-m1))\n",
    "\n",
    "        #roc\n",
    "        for a in range(0,repeatCount):\n",
    "            if math.isnan(roc[a][n]):\n",
    "                inputRec.append(0)\n",
    "            else:\n",
    "                inputRec.append(roc[a][n])\n",
    "\n",
    "        rClose=closeList[n+1:min(dLen-1,n+1+forwardWindow)].values.tolist()\n",
    "        low=min(rClose)\n",
    "        high=max(rClose)\n",
    "        \n",
    "        #long\n",
    "        long=0\n",
    "        if high>=cl+cl*profitTarget and low>=cl-cl*stopTarget:\n",
    "            long=1\n",
    "            lCount=lCount+1\n",
    "        inputRec.append(long)\n",
    " \n",
    "        #short\n",
    "        short=0\n",
    "        if low<=cl-cl*profitTarget and high<=cl+cl*stopTarget:\n",
    "            short=1\n",
    "            sCount=sCount+1\n",
    "        inputRec.append(short)\n",
    "\n",
    "        tData.append(inputRec)\n",
    "        n=n+1\n",
    "          \n",
    "print(\"lCount=%s,sCount=%s\" % (lCount,sCount))\n",
    "df1=pd.DataFrame(tData,columns=hData)\n",
    "df1.set_index(pd.DatetimeIndex(df1['dt']), inplace=True)\n",
    "del df1['dt']\n",
    " \n",
    "df1.to_csv(data_file)\n",
    "print(df1.head())\n",
    "print(\"count=%s\" % (len(df1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Data Preparation Locally in a Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (3/3)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.4s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.5s\n",
      "\u001b[2m => => # Collecting flask                                                      \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.6s\n",
      "\u001b[2m => => # Collecting flask                                                      \n",
      "\u001b[0m\u001b[2m => => #   Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)          \n",
      "\u001b[0m\u001b[2m => => # Collecting blinker>=1.9.0 (from flask)                                \n",
      "\u001b[0m\u001b[2m => => #   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)        \n",
      "\u001b[0m\u001b[2m => => # Collecting click>=8.1.3 (from flask)                                  \n",
      "\u001b[0m\u001b[2m => => #   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)          \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.8s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.7s\n",
      "\u001b[2m => => # Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/pyt\n",
      "\u001b[0m\u001b[2m => => # hon3.11/dist-packages (from flask) (3.0.2)                            \n",
      "\u001b[0m\u001b[2m => => # Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/pytho\n",
      "\u001b[0m\u001b[2m => => # n3.11/dist-packages (from flask) (3.1.3)                              \n",
      "\u001b[0m\u001b[2m => => # Downloading flask-3.1.1-py3-none-any.whl (103 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.9s\n",
      "\u001b[2m => => # n3.11/dist-packages (from flask) (3.1.3)                              \n",
      "\u001b[0m\u001b[2m => => # Downloading flask-3.1.1-py3-none-any.whl (103 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          2.0s\n",
      "\u001b[2m => => # n3.11/dist-packages (from flask) (3.1.3)                              \n",
      "\u001b[0m\u001b[2m => => # Downloading flask-3.1.1-py3-none-any.whl (103 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.2s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          2.1s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.3s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          2.2s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.4s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          2.3s\n",
      "\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: blinker                                       \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.5s (14/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/16] RUN pip install flask                                    2.4s\n",
      "\u001b[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[5A\u001b[0G\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.6s (14/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 5.85kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/16] RUN pip install flask                                    2.4s\n",
      "\u001b[0m\u001b[?25h------\n",
      " > [10/16] RUN pip install flask:\n",
      "1.501 Collecting flask\n",
      "1.523   Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "1.553 Collecting blinker>=1.9.0 (from flask)\n",
      "1.560   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "1.596 Collecting click>=8.1.3 (from flask)\n",
      "1.604   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "1.627 Collecting itsdangerous>=2.2.0 (from flask)\n",
      "1.635   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "1.669 Collecting jinja2>=3.1.2 (from flask)\n",
      "1.674   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "1.683 Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
      "1.683 Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "1.696 Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "1.709 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "1.723 Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "1.732 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "1.743 Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "2.055 Installing collected packages: jinja2, itsdangerous, click, blinker, flask\n",
      "2.259   Attempting uninstall: blinker\n",
      "2.263     Found existing installation: blinker 1.4\n",
      "2.273 error: uninstall-distutils-installed-package\n",
      "2.273 \n",
      "2.273  Cannot uninstall blinker 1.4\n",
      "2.273 > It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "2.274 \n",
      "------\n",
      "Dockerfile:23\n",
      "--------------------\n",
      "  21 |     RUN pip install scikit-learn\n",
      "  22 |     RUN pip install pandas\n",
      "  23 | >>> RUN pip install flask\n",
      "  24 |     RUN pip install gevent\n",
      "  25 |     RUN pip install gunicorn\n",
      "--------------------\n",
      "ERROR: failed to solve: process \"/bin/sh -c pip install flask\" did not complete successfully: exit code: 1\n",
      "             open   high    low  close         vol\n",
      "dt                                                \n",
      "2012-08-13  26.76  26.83  26.41  26.69  23623918.0\n",
      "2012-08-14  26.80  26.81  26.38  26.48  27477260.0\n",
      "2012-08-15  26.23  26.47  26.19  26.27  26081909.0\n",
      "2012-08-16  26.44  26.65  26.34  26.59  25702363.0\n",
      "2012-08-17  26.57  26.63  26.21  26.33  30379903.0\n",
      "lCount=445,sCount=355\n",
      "            close      sma2      sma3      sma4  ...  roc15  roc16  long  short\n",
      "dt                                               ...                           \n",
      "2012-08-13    0.0  0.000000  0.000000  0.000000  ...    0.0    0.0     0      0\n",
      "2012-08-14    0.0  1.000000  0.000000  0.000000  ...    0.0    0.0     0      0\n",
      "2012-08-15    0.0  0.500000  1.000000  0.000000  ...    0.0    0.0     0      0\n",
      "2012-08-16    1.0  0.000000  0.104167  0.484375  ...    0.0    0.0     0      0\n",
      "2012-08-17    0.0  0.915493  0.469484  0.616197  ...    0.0    0.0     0      1\n",
      "\n",
      "[5 rows x 33 columns]\n",
      "count=1819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (13/22)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/18] RUN pip install flask                                          0.8s\n",
      "\u001b[2m => => # Collecting flask                                                      \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (13/22)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/18] RUN pip install flask                                          0.9s\n",
      "\u001b[2m => => # Collecting blinker>=1.9.0 (from flask)                                \n",
      "\u001b[0m\u001b[2m => => #   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)        \n",
      "\u001b[0m\u001b[2m => => # Collecting click>=8.1.3 (from flask)                                  \n",
      "\u001b[0m\u001b[2m => => #   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)          \n",
      "\u001b[0m\u001b[2m => => # Collecting itsdangerous>=2.2.0 (from flask)                           \n",
      "\u001b[0m\u001b[2m => => #   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)   \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (13/22)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/18] RUN pip install flask                                          1.2s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (13/22)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/18] RUN pip install flask                                          1.3s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (13/22)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/18] RUN pip install flask                                          1.4s\n",
      "\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: blinker                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (14/22)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/18] RUN pip install flask                                    1.6s\n",
      "\u001b[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[5A\u001b[0G\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (14/22)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.44kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/18] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2.92kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/18] RUN apt-get -y update && apt-get install -y --no-insta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/18] RUN wget https://sourceforge.net/projects/ta-lib/files  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/18] WORKDIR /tmp                                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/18] RUN wget https://prdownloads.sourceforge.net/ta-lib/ta  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/18] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/18] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/18] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/18] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/18] RUN pip install flask                                    1.6s\n",
      "\u001b[0m\u001b[?25h------\n",
      " > [10/18] RUN pip install flask:\n",
      "0.830 Collecting flask\n",
      "0.843   Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "0.866 Collecting blinker>=1.9.0 (from flask)\n",
      "0.872   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "0.901 Collecting click>=8.1.3 (from flask)\n",
      "0.906   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "0.926 Collecting itsdangerous>=2.2.0 (from flask)\n",
      "0.930   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "0.955 Collecting jinja2>=3.1.2 (from flask)\n",
      "0.959   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "0.966 Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
      "0.967 Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "0.976 Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "0.986 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "0.995 Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "1.005 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "1.013 Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "1.163 Installing collected packages: jinja2, itsdangerous, click, blinker, flask\n",
      "1.364   Attempting uninstall: blinker\n",
      "1.368     Found existing installation: blinker 1.4\n",
      "1.438 \n",
      "1.438 [notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "1.438 [notice] To update, run: python3 -m pip install --upgrade pip\n",
      "1.443 error: uninstall-distutils-installed-package\n",
      "1.443 \n",
      "1.443  Cannot uninstall blinker 1.4\n",
      "1.443 > It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "------\n",
      "Dockerfile:31\n",
      "--------------------\n",
      "  29 |     RUN pip install scikit-learn\n",
      "  30 |     RUN pip install pandas\n",
      "  31 | >>> RUN pip install flask\n",
      "  32 |     RUN pip install gevent\n",
      "  33 |     RUN pip install gunicorn\n",
      "--------------------\n",
      "ERROR: failed to solve: process \"/bin/sh -c pip install flask\" did not complete successfully: exit code: 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 5, in <module>\n",
      "    import talib as ta\n",
      "ModuleNotFoundError: No module named 'talib'\n"
     ]
    }
   ],
   "source": [
    "!cp model/{model_name}_prep.py model/train\n",
    "!chmod 777 model/train\n",
    "!docker build -t {model_name}_prep .\n",
    "!docker run -v $(pwd)/local/$model_name:/opt/ml --rm {model_name}_prep train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "totalCount=1819\n",
      "trainCount=727\n",
      "testCount=1092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>sma2</th>\n",
       "      <th>sma3</th>\n",
       "      <th>sma4</th>\n",
       "      <th>sma5</th>\n",
       "      <th>sma6</th>\n",
       "      <th>sma7</th>\n",
       "      <th>sma8</th>\n",
       "      <th>sma9</th>\n",
       "      <th>sma10</th>\n",
       "      <th>...</th>\n",
       "      <th>roc9</th>\n",
       "      <th>roc10</th>\n",
       "      <th>roc11</th>\n",
       "      <th>roc12</th>\n",
       "      <th>roc13</th>\n",
       "      <th>roc14</th>\n",
       "      <th>roc15</th>\n",
       "      <th>roc16</th>\n",
       "      <th>long</th>\n",
       "      <th>short</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-08-10</th>\n",
       "      <td>3.797156e-14</td>\n",
       "      <td>2.278293e-14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021376</td>\n",
       "      <td>0.068403</td>\n",
       "      <td>0.096192</td>\n",
       "      <td>0.303846</td>\n",
       "      <td>0.418170</td>\n",
       "      <td>0.507088</td>\n",
       "      <td>0.578223</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.378779</td>\n",
       "      <td>-3.806433</td>\n",
       "      <td>-5.094614</td>\n",
       "      <td>-4.650483</td>\n",
       "      <td>-4.761905</td>\n",
       "      <td>-4.817518</td>\n",
       "      <td>-4.817518</td>\n",
       "      <td>-4.817518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-11</th>\n",
       "      <td>4.217463e-01</td>\n",
       "      <td>1.449753e-01</td>\n",
       "      <td>0.052718</td>\n",
       "      <td>0.006590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030752</td>\n",
       "      <td>0.048953</td>\n",
       "      <td>0.265239</td>\n",
       "      <td>0.388065</td>\n",
       "      <td>0.486326</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.133966</td>\n",
       "      <td>-2.133966</td>\n",
       "      <td>-2.567129</td>\n",
       "      <td>-3.871907</td>\n",
       "      <td>-3.422053</td>\n",
       "      <td>-3.534911</td>\n",
       "      <td>-3.591241</td>\n",
       "      <td>-3.591241</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-12</th>\n",
       "      <td>5.806887e-01</td>\n",
       "      <td>4.915598e-01</td>\n",
       "      <td>0.234976</td>\n",
       "      <td>0.106685</td>\n",
       "      <td>0.029710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015819</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>0.251182</td>\n",
       "      <td>0.382984</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.807943</td>\n",
       "      <td>-1.807943</td>\n",
       "      <td>-1.807943</td>\n",
       "      <td>-2.242549</td>\n",
       "      <td>-3.551674</td>\n",
       "      <td>-3.100322</td>\n",
       "      <td>-3.213555</td>\n",
       "      <td>-3.270073</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-13</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.846813e-01</td>\n",
       "      <td>0.414843</td>\n",
       "      <td>0.240010</td>\n",
       "      <td>0.135109</td>\n",
       "      <td>0.065176</td>\n",
       "      <td>0.025010</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146843</td>\n",
       "      <td>1.066983</td>\n",
       "      <td>1.066983</td>\n",
       "      <td>1.066983</td>\n",
       "      <td>0.619652</td>\n",
       "      <td>-0.727802</td>\n",
       "      <td>-0.263235</td>\n",
       "      <td>-0.379784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-14</th>\n",
       "      <td>9.189463e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.699426</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.329281</td>\n",
       "      <td>0.201283</td>\n",
       "      <td>0.109857</td>\n",
       "      <td>0.051418</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.412553</td>\n",
       "      <td>-0.323054</td>\n",
       "      <td>0.592768</td>\n",
       "      <td>0.592768</td>\n",
       "      <td>0.592768</td>\n",
       "      <td>0.147536</td>\n",
       "      <td>-1.193595</td>\n",
       "      <td>-0.731208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   close          sma2      sma3      sma4      sma5  \\\n",
       "dt                                                                     \n",
       "2014-08-10  3.797156e-14  2.278293e-14  0.000000  0.021376  0.068403   \n",
       "2014-08-11  4.217463e-01  1.449753e-01  0.052718  0.006590  0.000000   \n",
       "2014-08-12  5.806887e-01  4.915598e-01  0.234976  0.106685  0.029710   \n",
       "2014-08-13  1.000000e+00  5.846813e-01  0.414843  0.240010  0.135109   \n",
       "2014-08-14  9.189463e-01  1.000000e+00  0.699426  0.521277  0.329281   \n",
       "\n",
       "                sma6      sma7      sma8      sma9     sma10  ...      roc9  \\\n",
       "dt                                                            ...             \n",
       "2014-08-10  0.096192  0.303846  0.418170  0.507088  0.578223  ... -3.378779   \n",
       "2014-08-11  0.030752  0.048953  0.265239  0.388065  0.486326  ... -2.133966   \n",
       "2014-08-12  0.000000  0.015819  0.023633  0.251182  0.382984  ... -1.807943   \n",
       "2014-08-13  0.065176  0.025010  0.012012  0.000000  0.095718  ...  0.146843   \n",
       "2014-08-14  0.201283  0.109857  0.051418  0.023978  0.000000  ...  3.412553   \n",
       "\n",
       "               roc10     roc11     roc12     roc13     roc14     roc15  \\\n",
       "dt                                                                       \n",
       "2014-08-10 -3.806433 -5.094614 -4.650483 -4.761905 -4.817518 -4.817518   \n",
       "2014-08-11 -2.133966 -2.567129 -3.871907 -3.422053 -3.534911 -3.591241   \n",
       "2014-08-12 -1.807943 -1.807943 -2.242549 -3.551674 -3.100322 -3.213555   \n",
       "2014-08-13  1.066983  1.066983  1.066983  0.619652 -0.727802 -0.263235   \n",
       "2014-08-14 -0.323054  0.592768  0.592768  0.592768  0.147536 -1.193595   \n",
       "\n",
       "               roc16  long  short  \n",
       "dt                                 \n",
       "2014-08-10 -4.817518     1      0  \n",
       "2014-08-11 -3.591241     1      0  \n",
       "2014-08-12 -3.270073     1      0  \n",
       "2014-08-13 -0.379784     0      0  \n",
       "2014-08-14 -0.731208     0      0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"local/\"+model_name+\"/input/data/training/data.csv\", parse_dates=['dt'], index_col=['dt'])\n",
    "print(\"totalCount=%s\" % len(df))\n",
    "\n",
    "trainCount=int(len(df)*0.4)\n",
    "dfTrain = df.iloc[:trainCount]\n",
    "dfTrain.to_csv(\"local/\"+model_name+\"/input/data/training/data_train.csv\")\n",
    "print(\"trainCount=%s\" % len(dfTrain))\n",
    "\n",
    "dfTest = df.iloc[trainCount:]\n",
    "dfTest.to_csv(\"local/\"+model_name+\"/input/data/training/data_test.csv\")\n",
    "print(\"testCount=%s\" % len(dfTest))\n",
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3) Train the Model\n",
    "\n",
    "In the following cell, you can modify the model training code or leave it as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model/model_long_short_predict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/{model_name}.py\n",
    "#!/usr/bin/env python\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Dropout, Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "yLen=2\n",
    "b=0\n",
    "\n",
    "# Optional\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# These are the paths to where SageMaker mounts interesting things in your\n",
    "# container.\n",
    "prefix = '/opt/ml/'\n",
    "\n",
    "input_path = prefix + 'input/data/training/data_train.csv'\n",
    "test_path = prefix + 'input/data/training/data_test.csv'\n",
    "\n",
    "output_path = os.path.join(prefix, 'output')\n",
    "model_path = os.path.join(prefix, 'model')\n",
    "\n",
    "# Process and prepare the data\n",
    "def data_process(df):\n",
    "    global yLen\n",
    "    global b\n",
    "    dataX=[]\n",
    "    dataY=[]\n",
    "    for idx,row in df.iterrows():\n",
    "        row1=[]\n",
    "        r=row[1:len(row)-yLen]\n",
    "        for a in r:\n",
    "            row1.append(a)\n",
    "        x=np.array(row1)\n",
    "        y=np.array(row[len(row)-yLen:])\n",
    "        b=len(x)\n",
    "        dataX.append(x)\n",
    "        dataY.append(y)\n",
    "    dataX=np.array(dataX).astype(np.float32)\n",
    "    dataY=np.array(dataY).astype(np.float32)\n",
    "    return dataX,dataY,b\n",
    "\n",
    "def build_classifier():\n",
    "    global b\n",
    "    global yLen\n",
    "    print(\"build_classifier:b=%s,yLen=%s\" % (b,yLen))\n",
    "    model = Sequential()\n",
    "    model.add(Dense(b, input_dim=b, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(int(b/2), kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(yLen,kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def generate_model(dataX, dataY, b):\n",
    "    model=build_classifier()\n",
    "    model.fit(dataX, dataY, epochs=100, batch_size=1)\n",
    "    scores = model.evaluate(dataX, dataY, verbose=0)\n",
    "    print(\"Training Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    return model\n",
    "        \n",
    "def train():\n",
    "    print('Starting the training.')\n",
    "    try:\n",
    "        raw_data = pd.read_csv(input_path)\n",
    "        #print(raw_data)\n",
    "        X, y, b = data_process(raw_data)\n",
    "        model = generate_model(X, y, b)\n",
    "        model.save(os.path.join(model_path, 'model.h5'))\n",
    "        \n",
    "        print('Training is complete. Model saved.')\n",
    "        \n",
    "        raw_data = pd.read_csv(test_path)\n",
    "        testX, testY, b = data_process(raw_data)\n",
    "        scores = model.evaluate(testX, testY, verbose=0)\n",
    "        print(\"Test Data %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Write out an error file. This will be returned as the failure\n",
    "        # Reason in the DescribeTrainingJob result.\n",
    "        trc = traceback.format_exc()\n",
    "        with open(os.path.join(output_path, 'failure'), 'w') as s:\n",
    "            s.write('Exception during training: ' + str(e) + '\\n' + trc)\n",
    "        # Printing this causes the exception to be in the training job logs\n",
    "        print(\n",
    "            'Exception during training: ' + str(e) + '\\n' + trc,\n",
    "            file=sys.stderr)\n",
    "        # A non-zero exit code causes the training job to be marked as Failed.\n",
    "        sys.exit(255)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "    # A zero exit code causes the job to be marked a Succeeded.\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Train Locally\n",
    "\n",
    "You can choose if you want to do the training locally (Option 1) or remote via SageMaker (Option 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (1/1)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (3/18)                                         docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.8s\n",
      "\u001b[2m => => # Collecting flask                                                      \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.9s\n",
      "\u001b[2m => => # Collecting blinker>=1.9.0 (from flask)                                \n",
      "\u001b[0m\u001b[2m => => #   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)        \n",
      "\u001b[0m\u001b[2m => => # Collecting click>=8.1.3 (from flask)                                  \n",
      "\u001b[0m\u001b[2m => => #   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)          \n",
      "\u001b[0m\u001b[2m => => # Collecting itsdangerous>=2.2.0 (from flask)                           \n",
      "\u001b[0m\u001b[2m => => #   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)   \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.2s\n",
      "\u001b[2m => => # n3.11/dist-packages (from flask) (3.1.3)                              \n",
      "\u001b[0m\u001b[2m => => # Downloading flask-3.1.1-py3-none-any.whl (103 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.2s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.3s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.4s\n",
      "\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: blinker                                       \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (14/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/16] RUN pip install flask                                    1.5s\n",
      "\u001b[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[5A\u001b[0G\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.6s (14/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 7.23kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/16] RUN pip install flask                                    1.5s\n",
      "\u001b[0m\u001b[?25h------\n",
      " > [10/16] RUN pip install flask:\n",
      "0.816 Collecting flask\n",
      "0.828   Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "0.853 Collecting blinker>=1.9.0 (from flask)\n",
      "0.857   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "0.885 Collecting click>=8.1.3 (from flask)\n",
      "0.888   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "0.912 Collecting itsdangerous>=2.2.0 (from flask)\n",
      "0.917   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "0.941 Collecting jinja2>=3.1.2 (from flask)\n",
      "0.947   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "0.954 Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
      "0.955 Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "0.963 Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "0.975 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "0.984 Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "0.996 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "1.006 Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "1.162 Installing collected packages: jinja2, itsdangerous, click, blinker, flask\n",
      "1.369   Attempting uninstall: blinker\n",
      "1.373     Found existing installation: blinker 1.4\n",
      "1.380 error: uninstall-distutils-installed-package\n",
      "1.380 \n",
      "1.380  Cannot uninstall blinker 1.4\n",
      "1.380 > It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "1.381 \n",
      "------\n",
      "Dockerfile:23\n",
      "--------------------\n",
      "  21 |     RUN pip install scikit-learn\n",
      "  22 |     RUN pip install pandas\n",
      "  23 | >>> RUN pip install flask\n",
      "  24 |     RUN pip install gevent\n",
      "  25 |     RUN pip install gunicorn\n",
      "--------------------\n",
      "ERROR: failed to solve: process \"/bin/sh -c pip install flask\" did not complete successfully: exit code: 1\n",
      "Using TensorFlow backend.\n",
      "Starting the training.\n",
      "build_classifier:b=31,yLen=2\n",
      "2025-06-12 16:26:33.941628: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "Epoch 1/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 4:24 - loss: 0.7096 - accuracy: 0.0000e+00\n",
      " 43/727 [>.............................] - ETA: 6s - loss: 0.6755 - accuracy: 0.8023      \n",
      " 88/727 [==>...........................] - ETA: 3s - loss: 0.6545 - accuracy: 0.7955\n",
      "134/727 [====>.........................] - ETA: 2s - loss: 0.6329 - accuracy: 0.7836\n",
      "181/727 [======>.......................] - ETA: 1s - loss: 0.6054 - accuracy: 0.7845\n",
      "226/727 [========>.....................] - ETA: 1s - loss: 0.6149 - accuracy: 0.7721\n",
      "273/727 [==========>...................] - ETA: 1s - loss: 0.6165 - accuracy: 0.7619\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.6066 - accuracy: 0.7594\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.5981 - accuracy: 0.7609\n",
      "412/727 [================>.............] - ETA: 0s - loss: 0.5896 - accuracy: 0.7658\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.5841 - accuracy: 0.7669\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.5832 - accuracy: 0.7639\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.5825 - accuracy: 0.7650\n",
      "597/727 [=======================>......] - ETA: 0s - loss: 0.5823 - accuracy: 0.7621\n",
      "645/727 [=========================>....] - ETA: 0s - loss: 0.5820 - accuracy: 0.7628\n",
      "691/727 [===========================>..] - ETA: 0s - loss: 0.5741 - accuracy: 0.7670\n",
      "727/727 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7724\n",
      "Epoch 2/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.8912 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.5216 - accuracy: 0.7812\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.5269 - accuracy: 0.7842\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.5146 - accuracy: 0.7914\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4916 - accuracy: 0.8065\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.5059 - accuracy: 0.7965\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.5249 - accuracy: 0.7852\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.5257 - accuracy: 0.7855\n",
      "370/727 [==============>...............] - ETA: 0s - loss: 0.5258 - accuracy: 0.7851\n",
      "416/727 [================>.............] - ETA: 0s - loss: 0.5260 - accuracy: 0.7861\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.5217 - accuracy: 0.7868\n",
      "507/727 [===================>..........] - ETA: 0s - loss: 0.5344 - accuracy: 0.7771\n",
      "551/727 [=====================>........] - ETA: 0s - loss: 0.5354 - accuracy: 0.7768\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.5391 - accuracy: 0.7723\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.5418 - accuracy: 0.7695\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.5393 - accuracy: 0.7733\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7772\n",
      "Epoch 3/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2422 - accuracy: 1.0000\n",
      " 44/727 [>.............................] - ETA: 0s - loss: 0.5568 - accuracy: 0.7500\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.5467 - accuracy: 0.7611\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.5314 - accuracy: 0.7794\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.5425 - accuracy: 0.7678\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.5513 - accuracy: 0.7576\n",
      "273/727 [==========>...................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7674\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.5508 - accuracy: 0.7656\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.5510 - accuracy: 0.7663\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.5586 - accuracy: 0.7591\n",
      "458/727 [=================>............] - ETA: 0s - loss: 0.5518 - accuracy: 0.7653\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.5428 - accuracy: 0.7734\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.5413 - accuracy: 0.7737\n",
      "593/727 [=======================>......] - ETA: 0s - loss: 0.5405 - accuracy: 0.7740\n",
      "638/727 [=========================>....] - ETA: 0s - loss: 0.5381 - accuracy: 0.7751\n",
      "685/727 [===========================>..] - ETA: 0s - loss: 0.5386 - accuracy: 0.7752\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7772\n",
      "Epoch 4/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1828 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4232 - accuracy: 0.8469\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.5151 - accuracy: 0.7979\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.5377 - accuracy: 0.7750\n",
      "187/727 [======>.......................] - ETA: 0s - loss: 0.5112 - accuracy: 0.7941\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.5256 - accuracy: 0.7879\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.5202 - accuracy: 0.7932\n",
      "323/727 [============>.................] - ETA: 0s - loss: 0.5251 - accuracy: 0.7895\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.5286 - accuracy: 0.7840\n",
      "415/727 [================>.............] - ETA: 0s - loss: 0.5272 - accuracy: 0.7855\n",
      "461/727 [==================>...........] - ETA: 0s - loss: 0.5258 - accuracy: 0.7852\n",
      "508/727 [===================>..........] - ETA: 0s - loss: 0.5224 - accuracy: 0.7844\n",
      "555/727 [=====================>........] - ETA: 0s - loss: 0.5229 - accuracy: 0.7829\n",
      "602/727 [=======================>......] - ETA: 0s - loss: 0.5285 - accuracy: 0.7791\n",
      "646/727 [=========================>....] - ETA: 0s - loss: 0.5261 - accuracy: 0.7794\n",
      "691/727 [===========================>..] - ETA: 0s - loss: 0.5298 - accuracy: 0.7771\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5306 - accuracy: 0.7772\n",
      "Epoch 5/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.7021 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5911 - accuracy: 0.7234\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.5444 - accuracy: 0.7606\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.5224 - accuracy: 0.7750\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.5119 - accuracy: 0.7811\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.5025 - accuracy: 0.7900\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.4965 - accuracy: 0.7950\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.5077 - accuracy: 0.7917\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.5075 - accuracy: 0.7927\n",
      "416/727 [================>.............] - ETA: 0s - loss: 0.5092 - accuracy: 0.7921\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.5166 - accuracy: 0.7857\n",
      "508/727 [===================>..........] - ETA: 0s - loss: 0.5136 - accuracy: 0.7884\n",
      "552/727 [=====================>........] - ETA: 0s - loss: 0.5127 - accuracy: 0.7899\n",
      "598/727 [=======================>......] - ETA: 0s - loss: 0.5129 - accuracy: 0.7901\n",
      "644/727 [=========================>....] - ETA: 0s - loss: 0.5168 - accuracy: 0.7865\n",
      "688/727 [===========================>..] - ETA: 0s - loss: 0.5194 - accuracy: 0.7834\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5260 - accuracy: 0.7772\n",
      "Epoch 6/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3055 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.5961 - accuracy: 0.7444\n",
      " 89/727 [==>...........................] - ETA: 0s - loss: 0.5756 - accuracy: 0.7528\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.5584 - accuracy: 0.7612\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.5604 - accuracy: 0.7598\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.5417 - accuracy: 0.7746\n",
      "270/727 [==========>...................] - ETA: 0s - loss: 0.5249 - accuracy: 0.7833\n",
      "317/727 [============>.................] - ETA: 0s - loss: 0.5231 - accuracy: 0.7823\n",
      "363/727 [=============>................] - ETA: 0s - loss: 0.5172 - accuracy: 0.7824\n",
      "403/727 [===============>..............] - ETA: 0s - loss: 0.5204 - accuracy: 0.7804\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.5266 - accuracy: 0.7789\n",
      "495/727 [===================>..........] - ETA: 0s - loss: 0.5286 - accuracy: 0.7768\n",
      "540/727 [=====================>........] - ETA: 0s - loss: 0.5284 - accuracy: 0.7787\n",
      "585/727 [=======================>......] - ETA: 0s - loss: 0.5286 - accuracy: 0.7769\n",
      "630/727 [========================>.....] - ETA: 0s - loss: 0.5283 - accuracy: 0.7754\n",
      "675/727 [==========================>...] - ETA: 0s - loss: 0.5261 - accuracy: 0.7770\n",
      "721/727 [============================>.] - ETA: 0s - loss: 0.5245 - accuracy: 0.7788\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5265 - accuracy: 0.7772\n",
      "Epoch 7/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2625 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4277 - accuracy: 0.8438\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4862 - accuracy: 0.8172\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.5138 - accuracy: 0.7914\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.5459 - accuracy: 0.7609\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.5326 - accuracy: 0.7739\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.5355 - accuracy: 0.7699\n",
      "316/727 [============>.................] - ETA: 0s - loss: 0.5423 - accuracy: 0.7690\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.5385 - accuracy: 0.7742\n",
      "407/727 [===============>..............] - ETA: 0s - loss: 0.5360 - accuracy: 0.7740\n",
      "451/727 [=================>............] - ETA: 0s - loss: 0.5304 - accuracy: 0.7772\n",
      "496/727 [===================>..........] - ETA: 0s - loss: 0.5285 - accuracy: 0.7772\n",
      "542/727 [=====================>........] - ETA: 0s - loss: 0.5279 - accuracy: 0.7786\n",
      "587/727 [=======================>......] - ETA: 0s - loss: 0.5261 - accuracy: 0.7794\n",
      "632/727 [=========================>....] - ETA: 0s - loss: 0.5289 - accuracy: 0.7777\n",
      "679/727 [===========================>..] - ETA: 0s - loss: 0.5308 - accuracy: 0.7754\n",
      "724/727 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.7769\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5284 - accuracy: 0.7772\n",
      "Epoch 8/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7920 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4898 - accuracy: 0.8125\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.4588 - accuracy: 0.8316\n",
      "141/727 [====>.........................] - ETA: 0s - loss: 0.4995 - accuracy: 0.7908\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4883 - accuracy: 0.8027\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.4919 - accuracy: 0.7974\n",
      "279/727 [==========>...................] - ETA: 0s - loss: 0.4991 - accuracy: 0.7921\n",
      "325/727 [============>.................] - ETA: 0s - loss: 0.5165 - accuracy: 0.7846\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.5230 - accuracy: 0.7778\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.5216 - accuracy: 0.7772\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.5236 - accuracy: 0.7763\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.5220 - accuracy: 0.7783\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.5218 - accuracy: 0.7783\n",
      "590/727 [=======================>......] - ETA: 0s - loss: 0.5210 - accuracy: 0.7805\n",
      "631/727 [=========================>....] - ETA: 0s - loss: 0.5237 - accuracy: 0.7797\n",
      "677/727 [==========================>...] - ETA: 0s - loss: 0.5266 - accuracy: 0.7777\n",
      "722/727 [============================>.] - ETA: 0s - loss: 0.5262 - accuracy: 0.7777\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5271 - accuracy: 0.7772\n",
      "Epoch 9/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6185 - accuracy: 0.5000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.5564 - accuracy: 0.7556\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.5646 - accuracy: 0.7391\n",
      "141/727 [====>.........................] - ETA: 0s - loss: 0.5632 - accuracy: 0.7447\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.5462 - accuracy: 0.7634\n",
      "233/727 [========>.....................] - ETA: 0s - loss: 0.5296 - accuracy: 0.7747\n",
      "279/727 [==========>...................] - ETA: 0s - loss: 0.5254 - accuracy: 0.7742\n",
      "327/727 [============>.................] - ETA: 0s - loss: 0.5313 - accuracy: 0.7737\n",
      "372/727 [==============>...............] - ETA: 0s - loss: 0.5280 - accuracy: 0.7742\n",
      "418/727 [================>.............] - ETA: 0s - loss: 0.5287 - accuracy: 0.7727\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.5304 - accuracy: 0.7727\n",
      "509/727 [====================>.........] - ETA: 0s - loss: 0.5270 - accuracy: 0.7760\n",
      "554/727 [=====================>........] - ETA: 0s - loss: 0.5276 - accuracy: 0.7717\n",
      "599/727 [=======================>......] - ETA: 0s - loss: 0.5259 - accuracy: 0.7746\n",
      "644/727 [=========================>....] - ETA: 0s - loss: 0.5222 - accuracy: 0.7772\n",
      "688/727 [===========================>..] - ETA: 0s - loss: 0.5204 - accuracy: 0.7783\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5222 - accuracy: 0.7772\n",
      "Epoch 10/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2034 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4309 - accuracy: 0.8333\n",
      " 89/727 [==>...........................] - ETA: 0s - loss: 0.4938 - accuracy: 0.7921\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.4734 - accuracy: 0.8088\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4761 - accuracy: 0.8049\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.4991 - accuracy: 0.8013\n",
      "272/727 [==========>...................] - ETA: 0s - loss: 0.5098 - accuracy: 0.7923\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.5182 - accuracy: 0.7875\n",
      "366/727 [==============>...............] - ETA: 0s - loss: 0.5213 - accuracy: 0.7814\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.5198 - accuracy: 0.7809\n",
      "460/727 [=================>............] - ETA: 0s - loss: 0.5229 - accuracy: 0.7793\n",
      "506/727 [===================>..........] - ETA: 0s - loss: 0.5248 - accuracy: 0.7787\n",
      "552/727 [=====================>........] - ETA: 0s - loss: 0.5251 - accuracy: 0.7763\n",
      "598/727 [=======================>......] - ETA: 0s - loss: 0.5188 - accuracy: 0.7793\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.5248 - accuracy: 0.7749\n",
      "687/727 [===========================>..] - ETA: 0s - loss: 0.5242 - accuracy: 0.7758\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5242 - accuracy: 0.7772\n",
      "Epoch 11/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6784 - accuracy: 0.5000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.5569 - accuracy: 0.7444\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.5057 - accuracy: 0.7857\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.5232 - accuracy: 0.7741\n",
      "177/727 [======>.......................] - ETA: 0s - loss: 0.5210 - accuracy: 0.7768\n",
      "222/727 [========>.....................] - ETA: 0s - loss: 0.5214 - accuracy: 0.7748\n",
      "268/727 [==========>...................] - ETA: 0s - loss: 0.5301 - accuracy: 0.7687\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.5255 - accuracy: 0.7746\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.5255 - accuracy: 0.7729\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.5256 - accuracy: 0.7728\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.5155 - accuracy: 0.7811\n",
      "495/727 [===================>..........] - ETA: 0s - loss: 0.5139 - accuracy: 0.7818\n",
      "539/727 [=====================>........] - ETA: 0s - loss: 0.5082 - accuracy: 0.7885\n",
      "584/727 [=======================>......] - ETA: 0s - loss: 0.5143 - accuracy: 0.7860\n",
      "630/727 [========================>.....] - ETA: 0s - loss: 0.5231 - accuracy: 0.7762\n",
      "677/727 [==========================>...] - ETA: 0s - loss: 0.5218 - accuracy: 0.7784\n",
      "724/727 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7769\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5245 - accuracy: 0.7772\n",
      "Epoch 12/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3684 - accuracy: 1.0000\n",
      " 39/727 [>.............................] - ETA: 0s - loss: 0.4575 - accuracy: 0.8205\n",
      " 86/727 [==>...........................] - ETA: 0s - loss: 0.5399 - accuracy: 0.7674\n",
      "133/727 [====>.........................] - ETA: 0s - loss: 0.5020 - accuracy: 0.8045\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.5197 - accuracy: 0.7905\n",
      "223/727 [========>.....................] - ETA: 0s - loss: 0.5348 - accuracy: 0.7758\n",
      "271/727 [==========>...................] - ETA: 0s - loss: 0.5352 - accuracy: 0.7731\n",
      "316/727 [============>.................] - ETA: 0s - loss: 0.5292 - accuracy: 0.7785\n",
      "363/727 [=============>................] - ETA: 0s - loss: 0.5250 - accuracy: 0.7796\n",
      "409/727 [===============>..............] - ETA: 0s - loss: 0.5267 - accuracy: 0.7738\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.5259 - accuracy: 0.7730\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.5257 - accuracy: 0.7724\n",
      "550/727 [=====================>........] - ETA: 0s - loss: 0.5320 - accuracy: 0.7682\n",
      "594/727 [=======================>......] - ETA: 0s - loss: 0.5270 - accuracy: 0.7753\n",
      "641/727 [=========================>....] - ETA: 0s - loss: 0.5253 - accuracy: 0.7777\n",
      "687/727 [===========================>..] - ETA: 0s - loss: 0.5212 - accuracy: 0.7802\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5235 - accuracy: 0.7772\n",
      "Epoch 13/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2806 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.5296 - accuracy: 0.7708\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.5310 - accuracy: 0.7632\n",
      "141/727 [====>.........................] - ETA: 0s - loss: 0.5108 - accuracy: 0.7730\n",
      "188/727 [======>.......................] - ETA: 0s - loss: 0.5054 - accuracy: 0.7793\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.5052 - accuracy: 0.7773\n",
      "275/727 [==========>...................] - ETA: 0s - loss: 0.4954 - accuracy: 0.7855\n",
      "321/727 [============>.................] - ETA: 0s - loss: 0.5128 - accuracy: 0.7788\n",
      "366/727 [==============>...............] - ETA: 0s - loss: 0.5147 - accuracy: 0.7787\n",
      "409/727 [===============>..............] - ETA: 0s - loss: 0.5199 - accuracy: 0.7738\n",
      "454/727 [=================>............] - ETA: 0s - loss: 0.5235 - accuracy: 0.7742\n",
      "501/727 [===================>..........] - ETA: 0s - loss: 0.5252 - accuracy: 0.7735\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.5210 - accuracy: 0.7750\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.5201 - accuracy: 0.7731\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.5165 - accuracy: 0.7766\n",
      "687/727 [===========================>..] - ETA: 0s - loss: 0.5167 - accuracy: 0.7751\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5155 - accuracy: 0.7772\n",
      "Epoch 14/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1965 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4952 - accuracy: 0.7959\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.4628 - accuracy: 0.8158\n",
      "142/727 [====>.........................] - ETA: 0s - loss: 0.4846 - accuracy: 0.7958\n",
      "190/727 [======>.......................] - ETA: 0s - loss: 0.4756 - accuracy: 0.8000\n",
      "236/727 [========>.....................] - ETA: 0s - loss: 0.4809 - accuracy: 0.7987\n",
      "284/727 [==========>...................] - ETA: 0s - loss: 0.4918 - accuracy: 0.7940\n",
      "332/727 [============>.................] - ETA: 0s - loss: 0.4943 - accuracy: 0.7907\n",
      "378/727 [==============>...............] - ETA: 0s - loss: 0.4925 - accuracy: 0.7937\n",
      "424/727 [================>.............] - ETA: 0s - loss: 0.4928 - accuracy: 0.7925\n",
      "471/727 [==================>...........] - ETA: 0s - loss: 0.4893 - accuracy: 0.7941\n",
      "515/727 [====================>.........] - ETA: 0s - loss: 0.4954 - accuracy: 0.7913\n",
      "559/727 [======================>.......] - ETA: 0s - loss: 0.4993 - accuracy: 0.7880\n",
      "603/727 [=======================>......] - ETA: 0s - loss: 0.5009 - accuracy: 0.7869\n",
      "651/727 [=========================>....] - ETA: 0s - loss: 0.5099 - accuracy: 0.7788\n",
      "696/727 [===========================>..] - ETA: 0s - loss: 0.5104 - accuracy: 0.7795\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5127 - accuracy: 0.7779\n",
      "Epoch 15/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2045 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5141 - accuracy: 0.7766\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.5120 - accuracy: 0.7857\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.5124 - accuracy: 0.7815\n",
      "181/727 [======>.......................] - ETA: 0s - loss: 0.5135 - accuracy: 0.7762\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.5204 - accuracy: 0.7775\n",
      "272/727 [==========>...................] - ETA: 0s - loss: 0.5287 - accuracy: 0.7684\n",
      "319/727 [============>.................] - ETA: 0s - loss: 0.5161 - accuracy: 0.7790\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.5149 - accuracy: 0.7781\n",
      "410/727 [===============>..............] - ETA: 0s - loss: 0.5203 - accuracy: 0.7695\n",
      "454/727 [=================>............] - ETA: 0s - loss: 0.5233 - accuracy: 0.7698\n",
      "498/727 [===================>..........] - ETA: 0s - loss: 0.5221 - accuracy: 0.7721\n",
      "544/727 [=====================>........] - ETA: 0s - loss: 0.5154 - accuracy: 0.7767\n",
      "590/727 [=======================>......] - ETA: 0s - loss: 0.5155 - accuracy: 0.7754\n",
      "635/727 [=========================>....] - ETA: 0s - loss: 0.5166 - accuracy: 0.7740\n",
      "682/727 [===========================>..] - ETA: 0s - loss: 0.5152 - accuracy: 0.7771\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5147 - accuracy: 0.7765\n",
      "Epoch 16/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2125 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5340 - accuracy: 0.7447\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.5322 - accuracy: 0.7634\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.5417 - accuracy: 0.7464\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.5400 - accuracy: 0.7527\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.5509 - accuracy: 0.7435\n",
      "279/727 [==========>...................] - ETA: 0s - loss: 0.5430 - accuracy: 0.7545\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.5416 - accuracy: 0.7562\n",
      "372/727 [==============>...............] - ETA: 0s - loss: 0.5343 - accuracy: 0.7608\n",
      "416/727 [================>.............] - ETA: 0s - loss: 0.5381 - accuracy: 0.7560\n",
      "463/727 [==================>...........] - ETA: 0s - loss: 0.5334 - accuracy: 0.7635\n",
      "509/727 [====================>.........] - ETA: 0s - loss: 0.5323 - accuracy: 0.7642\n",
      "555/727 [=====================>........] - ETA: 0s - loss: 0.5299 - accuracy: 0.7667\n",
      "601/727 [=======================>......] - ETA: 0s - loss: 0.5274 - accuracy: 0.7671\n",
      "647/727 [=========================>....] - ETA: 0s - loss: 0.5200 - accuracy: 0.7728\n",
      "694/727 [===========================>..] - ETA: 0s - loss: 0.5175 - accuracy: 0.7767\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5146 - accuracy: 0.7772\n",
      "Epoch 17/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1775 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5103 - accuracy: 0.7766\n",
      " 96/727 [==>...........................] - ETA: 0s - loss: 0.4960 - accuracy: 0.7812\n",
      "142/727 [====>.........................] - ETA: 0s - loss: 0.4730 - accuracy: 0.7993\n",
      "188/727 [======>.......................] - ETA: 0s - loss: 0.5024 - accuracy: 0.7872\n",
      "233/727 [========>.....................] - ETA: 0s - loss: 0.5000 - accuracy: 0.7897\n",
      "280/727 [==========>...................] - ETA: 0s - loss: 0.5009 - accuracy: 0.7893\n",
      "326/727 [============>.................] - ETA: 0s - loss: 0.4968 - accuracy: 0.7883\n",
      "372/727 [==============>...............] - ETA: 0s - loss: 0.5100 - accuracy: 0.7728\n",
      "417/727 [================>.............] - ETA: 0s - loss: 0.5149 - accuracy: 0.7722\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.5118 - accuracy: 0.7749\n",
      "506/727 [===================>..........] - ETA: 0s - loss: 0.5111 - accuracy: 0.7747\n",
      "553/727 [=====================>........] - ETA: 0s - loss: 0.5132 - accuracy: 0.7740\n",
      "599/727 [=======================>......] - ETA: 0s - loss: 0.5072 - accuracy: 0.7796\n",
      "643/727 [=========================>....] - ETA: 0s - loss: 0.5044 - accuracy: 0.7807\n",
      "690/727 [===========================>..] - ETA: 0s - loss: 0.5092 - accuracy: 0.7754\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5100 - accuracy: 0.7758\n",
      "Epoch 18/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6809 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4972 - accuracy: 0.7609\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.5241 - accuracy: 0.7363\n",
      "137/727 [====>.........................] - ETA: 0s - loss: 0.5080 - accuracy: 0.7445\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.4986 - accuracy: 0.7500\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4831 - accuracy: 0.7686\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.4863 - accuracy: 0.7726\n",
      "323/727 [============>.................] - ETA: 0s - loss: 0.4941 - accuracy: 0.7740\n",
      "367/727 [==============>...............] - ETA: 0s - loss: 0.4958 - accuracy: 0.7752\n",
      "410/727 [===============>..............] - ETA: 0s - loss: 0.4950 - accuracy: 0.7744\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.4909 - accuracy: 0.7807\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.4907 - accuracy: 0.7833\n",
      "550/727 [=====================>........] - ETA: 0s - loss: 0.4916 - accuracy: 0.7845\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.4977 - accuracy: 0.7827\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.5030 - accuracy: 0.7780\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.5037 - accuracy: 0.7777\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5047 - accuracy: 0.7779\n",
      "Epoch 19/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.5991 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4441 - accuracy: 0.8298\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.4974 - accuracy: 0.7979\n",
      "141/727 [====>.........................] - ETA: 0s - loss: 0.4884 - accuracy: 0.8014\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4929 - accuracy: 0.7930\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4934 - accuracy: 0.7900\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.4978 - accuracy: 0.7824\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.5010 - accuracy: 0.7793\n",
      "370/727 [==============>...............] - ETA: 0s - loss: 0.5099 - accuracy: 0.7743\n",
      "416/727 [================>.............] - ETA: 0s - loss: 0.5101 - accuracy: 0.7704\n",
      "461/727 [==================>...........] - ETA: 0s - loss: 0.5096 - accuracy: 0.7722\n",
      "507/727 [===================>..........] - ETA: 0s - loss: 0.5042 - accuracy: 0.7771\n",
      "554/727 [=====================>........] - ETA: 0s - loss: 0.5068 - accuracy: 0.7771\n",
      "599/727 [=======================>......] - ETA: 0s - loss: 0.5091 - accuracy: 0.7763\n",
      "645/727 [=========================>....] - ETA: 0s - loss: 0.5065 - accuracy: 0.7791\n",
      "690/727 [===========================>..] - ETA: 0s - loss: 0.5096 - accuracy: 0.7768\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5098 - accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6254 - accuracy: 0.5000\n",
      " 40/727 [>.............................] - ETA: 0s - loss: 0.4418 - accuracy: 0.8000\n",
      " 87/727 [==>...........................] - ETA: 0s - loss: 0.4552 - accuracy: 0.7989\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.4333 - accuracy: 0.8209\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4554 - accuracy: 0.8139\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.4719 - accuracy: 0.8036\n",
      "269/727 [==========>...................] - ETA: 0s - loss: 0.4810 - accuracy: 0.7993\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4883 - accuracy: 0.7914\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.4932 - accuracy: 0.7841\n",
      "406/727 [===============>..............] - ETA: 0s - loss: 0.5087 - accuracy: 0.7783\n",
      "453/727 [=================>............] - ETA: 0s - loss: 0.5072 - accuracy: 0.7815\n",
      "500/727 [===================>..........] - ETA: 0s - loss: 0.5046 - accuracy: 0.7810\n",
      "546/727 [=====================>........] - ETA: 0s - loss: 0.5036 - accuracy: 0.7821\n",
      "591/727 [=======================>......] - ETA: 0s - loss: 0.5109 - accuracy: 0.7766\n",
      "637/727 [=========================>....] - ETA: 0s - loss: 0.5109 - accuracy: 0.7771\n",
      "682/727 [===========================>..] - ETA: 0s - loss: 0.5115 - accuracy: 0.7771\n",
      "725/727 [============================>.] - ETA: 0s - loss: 0.5118 - accuracy: 0.7745\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5111 - accuracy: 0.7751\n",
      "Epoch 21/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2879 - accuracy: 1.0000\n",
      " 42/727 [>.............................] - ETA: 0s - loss: 0.5566 - accuracy: 0.7381\n",
      " 87/727 [==>...........................] - ETA: 0s - loss: 0.5197 - accuracy: 0.7816\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.5065 - accuracy: 0.8000\n",
      "178/727 [======>.......................] - ETA: 0s - loss: 0.4998 - accuracy: 0.7978\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.5040 - accuracy: 0.7902\n",
      "270/727 [==========>...................] - ETA: 0s - loss: 0.4946 - accuracy: 0.7944\n",
      "317/727 [============>.................] - ETA: 0s - loss: 0.4958 - accuracy: 0.7934\n",
      "364/727 [==============>...............] - ETA: 0s - loss: 0.4959 - accuracy: 0.7912\n",
      "406/727 [===============>..............] - ETA: 0s - loss: 0.4879 - accuracy: 0.7956\n",
      "452/727 [=================>............] - ETA: 0s - loss: 0.4958 - accuracy: 0.7887\n",
      "497/727 [===================>..........] - ETA: 0s - loss: 0.4960 - accuracy: 0.7877\n",
      "542/727 [=====================>........] - ETA: 0s - loss: 0.4979 - accuracy: 0.7878\n",
      "587/727 [=======================>......] - ETA: 0s - loss: 0.4969 - accuracy: 0.7905\n",
      "633/727 [=========================>....] - ETA: 0s - loss: 0.5001 - accuracy: 0.7852\n",
      "678/727 [==========================>...] - ETA: 0s - loss: 0.5040 - accuracy: 0.7817\n",
      "723/727 [============================>.] - ETA: 0s - loss: 0.5044 - accuracy: 0.7801\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5055 - accuracy: 0.7792\n",
      "Epoch 22/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2968 - accuracy: 1.0000\n",
      " 41/727 [>.............................] - ETA: 0s - loss: 0.5398 - accuracy: 0.7317\n",
      " 86/727 [==>...........................] - ETA: 0s - loss: 0.5520 - accuracy: 0.7209\n",
      "130/727 [====>.........................] - ETA: 0s - loss: 0.5427 - accuracy: 0.7346\n",
      "174/727 [======>.......................] - ETA: 0s - loss: 0.5267 - accuracy: 0.7500\n",
      "219/727 [========>.....................] - ETA: 0s - loss: 0.5259 - accuracy: 0.7557\n",
      "265/727 [=========>....................] - ETA: 0s - loss: 0.5221 - accuracy: 0.7585\n",
      "311/727 [===========>..................] - ETA: 0s - loss: 0.5076 - accuracy: 0.7717\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.5015 - accuracy: 0.7772\n",
      "404/727 [===============>..............] - ETA: 0s - loss: 0.5012 - accuracy: 0.7735\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.5004 - accuracy: 0.7756\n",
      "498/727 [===================>..........] - ETA: 0s - loss: 0.5033 - accuracy: 0.7731\n",
      "545/727 [=====================>........] - ETA: 0s - loss: 0.5054 - accuracy: 0.7743\n",
      "590/727 [=======================>......] - ETA: 0s - loss: 0.5046 - accuracy: 0.7763\n",
      "635/727 [=========================>....] - ETA: 0s - loss: 0.5026 - accuracy: 0.7772\n",
      "681/727 [===========================>..] - ETA: 0s - loss: 0.5081 - accuracy: 0.7753\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7765\n",
      "Epoch 23/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 1.2503 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.5264 - accuracy: 0.7604\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.4920 - accuracy: 0.7819\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4995 - accuracy: 0.7754\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.4991 - accuracy: 0.7826\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4876 - accuracy: 0.7904\n",
      "275/727 [==========>...................] - ETA: 0s - loss: 0.4914 - accuracy: 0.7909\n",
      "321/727 [============>.................] - ETA: 0s - loss: 0.5013 - accuracy: 0.7773\n",
      "367/727 [==============>...............] - ETA: 0s - loss: 0.5052 - accuracy: 0.7752\n",
      "414/727 [================>.............] - ETA: 0s - loss: 0.5002 - accuracy: 0.7814\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.5015 - accuracy: 0.7803\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.5029 - accuracy: 0.7788\n",
      "547/727 [=====================>........] - ETA: 0s - loss: 0.5090 - accuracy: 0.7733\n",
      "594/727 [=======================>......] - ETA: 0s - loss: 0.5073 - accuracy: 0.7761\n",
      "641/727 [=========================>....] - ETA: 0s - loss: 0.5052 - accuracy: 0.7777\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.5078 - accuracy: 0.7755\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5084 - accuracy: 0.7758\n",
      "Epoch 24/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1818 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4905 - accuracy: 0.7444\n",
      " 85/727 [==>...........................] - ETA: 0s - loss: 0.4625 - accuracy: 0.7941\n",
      "125/727 [====>.........................] - ETA: 0s - loss: 0.4781 - accuracy: 0.7840\n",
      "168/727 [=====>........................] - ETA: 0s - loss: 0.4913 - accuracy: 0.7708\n",
      "214/727 [=======>......................] - ETA: 0s - loss: 0.4961 - accuracy: 0.7664\n",
      "261/727 [=========>....................] - ETA: 0s - loss: 0.5163 - accuracy: 0.7567\n",
      "307/727 [===========>..................] - ETA: 0s - loss: 0.5097 - accuracy: 0.7638\n",
      "353/727 [=============>................] - ETA: 0s - loss: 0.5119 - accuracy: 0.7606\n",
      "399/727 [===============>..............] - ETA: 0s - loss: 0.5164 - accuracy: 0.7607\n",
      "444/727 [=================>............] - ETA: 0s - loss: 0.5178 - accuracy: 0.7613\n",
      "489/727 [===================>..........] - ETA: 0s - loss: 0.5156 - accuracy: 0.7618\n",
      "537/727 [=====================>........] - ETA: 0s - loss: 0.5137 - accuracy: 0.7644\n",
      "583/727 [=======================>......] - ETA: 0s - loss: 0.5155 - accuracy: 0.7624\n",
      "629/727 [========================>.....] - ETA: 0s - loss: 0.5150 - accuracy: 0.7639\n",
      "675/727 [==========================>...] - ETA: 0s - loss: 0.5135 - accuracy: 0.7659\n",
      "721/727 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.7732\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5048 - accuracy: 0.7744\n",
      "Epoch 25/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.7937 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4616 - accuracy: 0.8229\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.4736 - accuracy: 0.8053\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.4717 - accuracy: 0.7986\n",
      "188/727 [======>.......................] - ETA: 0s - loss: 0.4902 - accuracy: 0.7872\n",
      "235/727 [========>.....................] - ETA: 0s - loss: 0.4981 - accuracy: 0.7787\n",
      "280/727 [==========>...................] - ETA: 0s - loss: 0.5253 - accuracy: 0.7607\n",
      "325/727 [============>.................] - ETA: 0s - loss: 0.5244 - accuracy: 0.7646\n",
      "371/727 [==============>...............] - ETA: 0s - loss: 0.5153 - accuracy: 0.7668\n",
      "417/727 [================>.............] - ETA: 0s - loss: 0.5158 - accuracy: 0.7638\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.5148 - accuracy: 0.7652\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.5080 - accuracy: 0.7724\n",
      "547/727 [=====================>........] - ETA: 0s - loss: 0.5098 - accuracy: 0.7724\n",
      "594/727 [=======================>......] - ETA: 0s - loss: 0.5074 - accuracy: 0.7744\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.5062 - accuracy: 0.7742\n",
      "688/727 [===========================>..] - ETA: 0s - loss: 0.5041 - accuracy: 0.7733\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4982 - accuracy: 0.7758\n",
      "Epoch 26/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2388 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.5393 - accuracy: 0.7653\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.4797 - accuracy: 0.7872\n",
      "141/727 [====>.........................] - ETA: 0s - loss: 0.4956 - accuracy: 0.7766\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4984 - accuracy: 0.7769\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.5026 - accuracy: 0.7694\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.5009 - accuracy: 0.7734\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.4992 - accuracy: 0.7824\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4989 - accuracy: 0.7846\n",
      "414/727 [================>.............] - ETA: 0s - loss: 0.4961 - accuracy: 0.7838\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4979 - accuracy: 0.7832\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.5003 - accuracy: 0.7798\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.5061 - accuracy: 0.7750\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.5000 - accuracy: 0.7798\n",
      "641/727 [=========================>....] - ETA: 0s - loss: 0.5024 - accuracy: 0.7746\n",
      "689/727 [===========================>..] - ETA: 0s - loss: 0.5037 - accuracy: 0.7758\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5032 - accuracy: 0.7765\n",
      "Epoch 27/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2033 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5202 - accuracy: 0.7500\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4977 - accuracy: 0.7637\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.5109 - accuracy: 0.7390\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4944 - accuracy: 0.7610\n",
      "228/727 [========>.....................] - ETA: 0s - loss: 0.4950 - accuracy: 0.7675\n",
      "273/727 [==========>...................] - ETA: 0s - loss: 0.4849 - accuracy: 0.7802\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4912 - accuracy: 0.7781\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.4887 - accuracy: 0.7808\n",
      "411/727 [===============>..............] - ETA: 0s - loss: 0.4936 - accuracy: 0.7786\n",
      "457/727 [=================>............] - ETA: 0s - loss: 0.4969 - accuracy: 0.7757\n",
      "493/727 [===================>..........] - ETA: 0s - loss: 0.4998 - accuracy: 0.7728\n",
      "535/727 [=====================>........] - ETA: 0s - loss: 0.5049 - accuracy: 0.7720\n",
      "579/727 [======================>.......] - ETA: 0s - loss: 0.5010 - accuracy: 0.7737\n",
      "621/727 [========================>.....] - ETA: 0s - loss: 0.4974 - accuracy: 0.7778\n",
      "666/727 [==========================>...] - ETA: 0s - loss: 0.4955 - accuracy: 0.7800\n",
      "712/727 [============================>.] - ETA: 0s - loss: 0.4947 - accuracy: 0.7809\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4951 - accuracy: 0.7813\n",
      "Epoch 28/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7436 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5193 - accuracy: 0.7717\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4843 - accuracy: 0.7935\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.5033 - accuracy: 0.7754\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.5056 - accuracy: 0.7690\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.5061 - accuracy: 0.7739\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4975 - accuracy: 0.7790\n",
      "323/727 [============>.................] - ETA: 0s - loss: 0.4939 - accuracy: 0.7817\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4947 - accuracy: 0.7778\n",
      "414/727 [================>.............] - ETA: 0s - loss: 0.4916 - accuracy: 0.7802\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4986 - accuracy: 0.7723\n",
      "506/727 [===================>..........] - ETA: 0s - loss: 0.5004 - accuracy: 0.7708\n",
      "552/727 [=====================>........] - ETA: 0s - loss: 0.5039 - accuracy: 0.7717\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.5006 - accuracy: 0.7743\n",
      "641/727 [=========================>....] - ETA: 0s - loss: 0.4966 - accuracy: 0.7761\n",
      "688/727 [===========================>..] - ETA: 0s - loss: 0.5018 - accuracy: 0.7754\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5011 - accuracy: 0.7758\n",
      "Epoch 29/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2779 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4470 - accuracy: 0.8111\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4931 - accuracy: 0.7717\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4914 - accuracy: 0.7681\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.4873 - accuracy: 0.7717\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4806 - accuracy: 0.7792\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4893 - accuracy: 0.7790\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4839 - accuracy: 0.7811\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.4781 - accuracy: 0.7853\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.4791 - accuracy: 0.7821\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4756 - accuracy: 0.7810\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4758 - accuracy: 0.7789\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.4794 - accuracy: 0.7792\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.4824 - accuracy: 0.7785\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.4879 - accuracy: 0.7796\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.4921 - accuracy: 0.7777\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4936 - accuracy: 0.7765\n",
      "Epoch 30/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.7841 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5333 - accuracy: 0.6957\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4964 - accuracy: 0.7418\n",
      "137/727 [====>.........................] - ETA: 0s - loss: 0.4843 - accuracy: 0.7555\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4822 - accuracy: 0.7665\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4763 - accuracy: 0.7731\n",
      "267/727 [==========>...................] - ETA: 0s - loss: 0.4788 - accuracy: 0.7772\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4786 - accuracy: 0.7803\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.4921 - accuracy: 0.7702\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.4878 - accuracy: 0.7765\n",
      "449/727 [=================>............] - ETA: 0s - loss: 0.4839 - accuracy: 0.7829\n",
      "494/727 [===================>..........] - ETA: 0s - loss: 0.4804 - accuracy: 0.7844\n",
      "539/727 [=====================>........] - ETA: 0s - loss: 0.4844 - accuracy: 0.7829\n",
      "584/727 [=======================>......] - ETA: 0s - loss: 0.4849 - accuracy: 0.7834\n",
      "628/727 [========================>.....] - ETA: 0s - loss: 0.4887 - accuracy: 0.7826\n",
      "674/727 [==========================>...] - ETA: 0s - loss: 0.4877 - accuracy: 0.7797\n",
      "718/727 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.7792\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4909 - accuracy: 0.7785\n",
      "Epoch 31/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3188 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4689 - accuracy: 0.8125\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.5093 - accuracy: 0.7660\n",
      "143/727 [====>.........................] - ETA: 0s - loss: 0.5200 - accuracy: 0.7622\n",
      "191/727 [======>.......................] - ETA: 0s - loss: 0.5264 - accuracy: 0.7513\n",
      "238/727 [========>.....................] - ETA: 0s - loss: 0.5092 - accuracy: 0.7584\n",
      "283/727 [==========>...................] - ETA: 0s - loss: 0.5070 - accuracy: 0.7703\n",
      "327/727 [============>.................] - ETA: 0s - loss: 0.5006 - accuracy: 0.7691\n",
      "373/727 [==============>...............] - ETA: 0s - loss: 0.4899 - accuracy: 0.7761\n",
      "415/727 [================>.............] - ETA: 0s - loss: 0.4909 - accuracy: 0.7771\n",
      "462/727 [==================>...........] - ETA: 0s - loss: 0.4889 - accuracy: 0.7792\n",
      "510/727 [====================>.........] - ETA: 0s - loss: 0.4852 - accuracy: 0.7843\n",
      "556/727 [=====================>........] - ETA: 0s - loss: 0.4878 - accuracy: 0.7842\n",
      "603/727 [=======================>......] - ETA: 0s - loss: 0.4886 - accuracy: 0.7819\n",
      "648/727 [=========================>....] - ETA: 0s - loss: 0.4916 - accuracy: 0.7809\n",
      "693/727 [===========================>..] - ETA: 0s - loss: 0.4900 - accuracy: 0.7843\n",
      "725/727 [============================>.] - ETA: 0s - loss: 0.4892 - accuracy: 0.7821\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4908 - accuracy: 0.7813\n",
      "Epoch 32/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8450 - accuracy: 0.5000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4696 - accuracy: 0.7778\n",
      " 89/727 [==>...........................] - ETA: 0s - loss: 0.5055 - accuracy: 0.7528\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4970 - accuracy: 0.7667\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4820 - accuracy: 0.7806\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4771 - accuracy: 0.7788\n",
      "267/727 [==========>...................] - ETA: 0s - loss: 0.4664 - accuracy: 0.7903\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.4801 - accuracy: 0.7810\n",
      "362/727 [=============>................] - ETA: 0s - loss: 0.4802 - accuracy: 0.7790\n",
      "409/727 [===============>..............] - ETA: 0s - loss: 0.4825 - accuracy: 0.7775\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.4789 - accuracy: 0.7829\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.4772 - accuracy: 0.7827\n",
      "551/727 [=====================>........] - ETA: 0s - loss: 0.4769 - accuracy: 0.7813\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.4853 - accuracy: 0.7777\n",
      "644/727 [=========================>....] - ETA: 0s - loss: 0.4843 - accuracy: 0.7772\n",
      "691/727 [===========================>..] - ETA: 0s - loss: 0.4833 - accuracy: 0.7786\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4869 - accuracy: 0.7758\n",
      "Epoch 33/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2964 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4835 - accuracy: 0.7653\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.5161 - accuracy: 0.7581\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.5239 - accuracy: 0.7610\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.5298 - accuracy: 0.7583\n",
      "225/727 [========>.....................] - ETA: 0s - loss: 0.5127 - accuracy: 0.7689\n",
      "266/727 [=========>....................] - ETA: 0s - loss: 0.5055 - accuracy: 0.7707\n",
      "312/727 [===========>..................] - ETA: 0s - loss: 0.5068 - accuracy: 0.7660\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.5064 - accuracy: 0.7646\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.5041 - accuracy: 0.7691\n",
      "451/727 [=================>............] - ETA: 0s - loss: 0.4985 - accuracy: 0.7749\n",
      "492/727 [===================>..........] - ETA: 0s - loss: 0.4974 - accuracy: 0.7764\n",
      "535/727 [=====================>........] - ETA: 0s - loss: 0.5003 - accuracy: 0.7729\n",
      "579/727 [======================>.......] - ETA: 0s - loss: 0.5039 - accuracy: 0.7694\n",
      "625/727 [========================>.....] - ETA: 0s - loss: 0.4964 - accuracy: 0.7760\n",
      "672/727 [==========================>...] - ETA: 0s - loss: 0.5067 - accuracy: 0.7708\n",
      "718/727 [============================>.] - ETA: 0s - loss: 0.5009 - accuracy: 0.7758\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.5003 - accuracy: 0.7758\n",
      "Epoch 34/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8775 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4955 - accuracy: 0.7609\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4475 - accuracy: 0.7903\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.4635 - accuracy: 0.7786\n",
      "187/727 [======>.......................] - ETA: 0s - loss: 0.4773 - accuracy: 0.7781\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.4897 - accuracy: 0.7737\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.4956 - accuracy: 0.7671\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4984 - accuracy: 0.7671\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4974 - accuracy: 0.7696\n",
      "415/727 [================>.............] - ETA: 0s - loss: 0.5005 - accuracy: 0.7675\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4936 - accuracy: 0.7691\n",
      "505/727 [===================>..........] - ETA: 0s - loss: 0.4870 - accuracy: 0.7733\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4852 - accuracy: 0.7741\n",
      "594/727 [=======================>......] - ETA: 0s - loss: 0.4890 - accuracy: 0.7727\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.4908 - accuracy: 0.7719\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.4863 - accuracy: 0.7755\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4893 - accuracy: 0.7758\n",
      "Epoch 35/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.7634 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.5120 - accuracy: 0.7812\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4763 - accuracy: 0.8011\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.5003 - accuracy: 0.7717\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.5014 - accuracy: 0.7661\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.4957 - accuracy: 0.7608\n",
      "280/727 [==========>...................] - ETA: 0s - loss: 0.4983 - accuracy: 0.7554\n",
      "326/727 [============>.................] - ETA: 0s - loss: 0.5031 - accuracy: 0.7546\n",
      "373/727 [==============>...............] - ETA: 0s - loss: 0.5043 - accuracy: 0.7547\n",
      "417/727 [================>.............] - ETA: 0s - loss: 0.4949 - accuracy: 0.7638\n",
      "463/727 [==================>...........] - ETA: 0s - loss: 0.4922 - accuracy: 0.7667\n",
      "510/727 [====================>.........] - ETA: 0s - loss: 0.4884 - accuracy: 0.7735\n",
      "556/727 [=====================>........] - ETA: 0s - loss: 0.4861 - accuracy: 0.7752\n",
      "600/727 [=======================>......] - ETA: 0s - loss: 0.4886 - accuracy: 0.7767\n",
      "645/727 [=========================>....] - ETA: 0s - loss: 0.4883 - accuracy: 0.7775\n",
      "690/727 [===========================>..] - ETA: 0s - loss: 0.4916 - accuracy: 0.7761\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4926 - accuracy: 0.7730\n",
      "Epoch 36/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.9030 - accuracy: 0.5000\n",
      " 42/727 [>.............................] - ETA: 0s - loss: 0.4732 - accuracy: 0.8214\n",
      " 87/727 [==>...........................] - ETA: 0s - loss: 0.4802 - accuracy: 0.7989\n",
      "124/727 [====>.........................] - ETA: 0s - loss: 0.5104 - accuracy: 0.7621\n",
      "169/727 [=====>........................] - ETA: 0s - loss: 0.5215 - accuracy: 0.7544\n",
      "215/727 [=======>......................] - ETA: 0s - loss: 0.5183 - accuracy: 0.7558\n",
      "263/727 [=========>....................] - ETA: 0s - loss: 0.5118 - accuracy: 0.7624\n",
      "310/727 [===========>..................] - ETA: 0s - loss: 0.5101 - accuracy: 0.7661\n",
      "356/727 [=============>................] - ETA: 0s - loss: 0.5044 - accuracy: 0.7725\n",
      "395/727 [===============>..............] - ETA: 0s - loss: 0.5006 - accuracy: 0.7759\n",
      "442/727 [=================>............] - ETA: 0s - loss: 0.5009 - accuracy: 0.7749\n",
      "487/727 [===================>..........] - ETA: 0s - loss: 0.4979 - accuracy: 0.7772\n",
      "532/727 [====================>.........] - ETA: 0s - loss: 0.4926 - accuracy: 0.7810\n",
      "576/727 [======================>.......] - ETA: 0s - loss: 0.4890 - accuracy: 0.7830\n",
      "622/727 [========================>.....] - ETA: 0s - loss: 0.4886 - accuracy: 0.7814\n",
      "668/727 [==========================>...] - ETA: 0s - loss: 0.4957 - accuracy: 0.7799\n",
      "714/727 [============================>.] - ETA: 0s - loss: 0.4891 - accuracy: 0.7843\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4912 - accuracy: 0.7847\n",
      "Epoch 37/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2567 - accuracy: 1.0000\n",
      " 44/727 [>.............................] - ETA: 0s - loss: 0.4616 - accuracy: 0.7955\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4748 - accuracy: 0.8022\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.4763 - accuracy: 0.7842\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4768 - accuracy: 0.7865\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4760 - accuracy: 0.7857\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.4829 - accuracy: 0.7824\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.4860 - accuracy: 0.7809\n",
      "370/727 [==============>...............] - ETA: 0s - loss: 0.4906 - accuracy: 0.7784\n",
      "417/727 [================>.............] - ETA: 0s - loss: 0.4836 - accuracy: 0.7830\n",
      "463/727 [==================>...........] - ETA: 0s - loss: 0.4830 - accuracy: 0.7819\n",
      "508/727 [===================>..........] - ETA: 0s - loss: 0.4858 - accuracy: 0.7835\n",
      "552/727 [=====================>........] - ETA: 0s - loss: 0.4920 - accuracy: 0.7772\n",
      "597/727 [=======================>......] - ETA: 0s - loss: 0.4919 - accuracy: 0.7772\n",
      "643/727 [=========================>....] - ETA: 0s - loss: 0.4879 - accuracy: 0.7768\n",
      "689/727 [===========================>..] - ETA: 0s - loss: 0.4885 - accuracy: 0.7779\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4903 - accuracy: 0.7765\n",
      "Epoch 38/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6662 - accuracy: 0.5000\n",
      " 44/727 [>.............................] - ETA: 0s - loss: 0.5492 - accuracy: 0.7500\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4996 - accuracy: 0.7912\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4670 - accuracy: 0.8080\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4719 - accuracy: 0.8011\n",
      "235/727 [========>.....................] - ETA: 0s - loss: 0.4760 - accuracy: 0.7957\n",
      "282/727 [==========>...................] - ETA: 0s - loss: 0.4723 - accuracy: 0.7996\n",
      "329/727 [============>.................] - ETA: 0s - loss: 0.4721 - accuracy: 0.7979\n",
      "375/727 [==============>...............] - ETA: 0s - loss: 0.4745 - accuracy: 0.7933\n",
      "422/727 [================>.............] - ETA: 0s - loss: 0.4694 - accuracy: 0.7927\n",
      "468/727 [==================>...........] - ETA: 0s - loss: 0.4705 - accuracy: 0.7885\n",
      "514/727 [====================>.........] - ETA: 0s - loss: 0.4727 - accuracy: 0.7850\n",
      "561/727 [======================>.......] - ETA: 0s - loss: 0.4707 - accuracy: 0.7843\n",
      "606/727 [========================>.....] - ETA: 0s - loss: 0.4776 - accuracy: 0.7781\n",
      "652/727 [=========================>....] - ETA: 0s - loss: 0.4780 - accuracy: 0.7791\n",
      "696/727 [===========================>..] - ETA: 0s - loss: 0.4824 - accuracy: 0.7744\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4830 - accuracy: 0.7744\n",
      "Epoch 39/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 3s - loss: 0.7654 - accuracy: 0.5000\n",
      " 42/727 [>.............................] - ETA: 0s - loss: 0.5435 - accuracy: 0.7738\n",
      " 88/727 [==>...........................] - ETA: 0s - loss: 0.5197 - accuracy: 0.7727\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.5137 - accuracy: 0.7687\n",
      "178/727 [======>.......................] - ETA: 0s - loss: 0.5120 - accuracy: 0.7697\n",
      "223/727 [========>.....................] - ETA: 0s - loss: 0.5012 - accuracy: 0.7758\n",
      "268/727 [==========>...................] - ETA: 0s - loss: 0.5033 - accuracy: 0.7705\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4951 - accuracy: 0.7755\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.5050 - accuracy: 0.7715\n",
      "407/727 [===============>..............] - ETA: 0s - loss: 0.5076 - accuracy: 0.7629\n",
      "455/727 [=================>............] - ETA: 0s - loss: 0.5013 - accuracy: 0.7692\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4945 - accuracy: 0.7729\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4894 - accuracy: 0.7741\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.4898 - accuracy: 0.7756\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.4940 - accuracy: 0.7741\n",
      "691/727 [===========================>..] - ETA: 0s - loss: 0.4919 - accuracy: 0.7728\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4853 - accuracy: 0.7772\n",
      "Epoch 40/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6583 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4802 - accuracy: 0.7826\n",
      " 88/727 [==>...........................] - ETA: 0s - loss: 0.4867 - accuracy: 0.7557\n",
      "132/727 [====>.........................] - ETA: 0s - loss: 0.5043 - accuracy: 0.7614\n",
      "176/727 [======>.......................] - ETA: 0s - loss: 0.4814 - accuracy: 0.7841\n",
      "221/727 [========>.....................] - ETA: 0s - loss: 0.4766 - accuracy: 0.7851\n",
      "265/727 [=========>....................] - ETA: 0s - loss: 0.4841 - accuracy: 0.7774\n",
      "310/727 [===========>..................] - ETA: 0s - loss: 0.4869 - accuracy: 0.7758\n",
      "354/727 [=============>................] - ETA: 0s - loss: 0.4844 - accuracy: 0.7754\n",
      "401/727 [===============>..............] - ETA: 0s - loss: 0.4867 - accuracy: 0.7731\n",
      "447/727 [=================>............] - ETA: 0s - loss: 0.4897 - accuracy: 0.7718\n",
      "494/727 [===================>..........] - ETA: 0s - loss: 0.4907 - accuracy: 0.7713\n",
      "540/727 [=====================>........] - ETA: 0s - loss: 0.4873 - accuracy: 0.7731\n",
      "586/727 [=======================>......] - ETA: 0s - loss: 0.4867 - accuracy: 0.7730\n",
      "631/727 [=========================>....] - ETA: 0s - loss: 0.4911 - accuracy: 0.7686\n",
      "677/727 [==========================>...] - ETA: 0s - loss: 0.4892 - accuracy: 0.7725\n",
      "722/727 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.7749\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.7744\n",
      "Epoch 41/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 1.0485 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5216 - accuracy: 0.7447\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.5004 - accuracy: 0.7579\n",
      "143/727 [====>.........................] - ETA: 0s - loss: 0.4793 - accuracy: 0.7762\n",
      "191/727 [======>.......................] - ETA: 0s - loss: 0.4748 - accuracy: 0.7723\n",
      "236/727 [========>.....................] - ETA: 0s - loss: 0.4674 - accuracy: 0.7691\n",
      "280/727 [==========>...................] - ETA: 0s - loss: 0.4799 - accuracy: 0.7661\n",
      "327/727 [============>.................] - ETA: 0s - loss: 0.4847 - accuracy: 0.7661\n",
      "373/727 [==============>...............] - ETA: 0s - loss: 0.4964 - accuracy: 0.7560\n",
      "421/727 [================>.............] - ETA: 0s - loss: 0.4916 - accuracy: 0.7625\n",
      "467/727 [==================>...........] - ETA: 0s - loss: 0.4908 - accuracy: 0.7645\n",
      "512/727 [====================>.........] - ETA: 0s - loss: 0.4962 - accuracy: 0.7627\n",
      "559/727 [======================>.......] - ETA: 0s - loss: 0.4928 - accuracy: 0.7665\n",
      "607/727 [========================>.....] - ETA: 0s - loss: 0.4919 - accuracy: 0.7702\n",
      "653/727 [=========================>....] - ETA: 0s - loss: 0.4912 - accuracy: 0.7726\n",
      "700/727 [===========================>..] - ETA: 0s - loss: 0.4889 - accuracy: 0.7736\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.7779\n",
      "Epoch 42/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1986 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4925 - accuracy: 0.7717\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.5003 - accuracy: 0.7796\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.5030 - accuracy: 0.7714\n",
      "188/727 [======>.......................] - ETA: 0s - loss: 0.4800 - accuracy: 0.7899\n",
      "234/727 [========>.....................] - ETA: 0s - loss: 0.4725 - accuracy: 0.7949\n",
      "279/727 [==========>...................] - ETA: 0s - loss: 0.4712 - accuracy: 0.7921\n",
      "326/727 [============>.................] - ETA: 0s - loss: 0.4739 - accuracy: 0.7868\n",
      "373/727 [==============>...............] - ETA: 0s - loss: 0.4863 - accuracy: 0.7761\n",
      "421/727 [================>.............] - ETA: 0s - loss: 0.4883 - accuracy: 0.7767\n",
      "466/727 [==================>...........] - ETA: 0s - loss: 0.4827 - accuracy: 0.7800\n",
      "513/727 [====================>.........] - ETA: 0s - loss: 0.4844 - accuracy: 0.7778\n",
      "560/727 [======================>.......] - ETA: 0s - loss: 0.4820 - accuracy: 0.7768\n",
      "603/727 [=======================>......] - ETA: 0s - loss: 0.4772 - accuracy: 0.7819\n",
      "648/727 [=========================>....] - ETA: 0s - loss: 0.4782 - accuracy: 0.7816\n",
      "697/727 [===========================>..] - ETA: 0s - loss: 0.4812 - accuracy: 0.7819\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4802 - accuracy: 0.7806\n",
      "Epoch 43/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2093 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5159 - accuracy: 0.7609\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.5002 - accuracy: 0.7692\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4735 - accuracy: 0.7790\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4642 - accuracy: 0.7892\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4579 - accuracy: 0.7832\n",
      "270/727 [==========>...................] - ETA: 0s - loss: 0.4551 - accuracy: 0.7852\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4477 - accuracy: 0.7898\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.4506 - accuracy: 0.7895\n",
      "402/727 [===============>..............] - ETA: 0s - loss: 0.4543 - accuracy: 0.7910\n",
      "447/727 [=================>............] - ETA: 0s - loss: 0.4584 - accuracy: 0.7852\n",
      "493/727 [===================>..........] - ETA: 0s - loss: 0.4645 - accuracy: 0.7840\n",
      "539/727 [=====================>........] - ETA: 0s - loss: 0.4664 - accuracy: 0.7839\n",
      "585/727 [=======================>......] - ETA: 0s - loss: 0.4658 - accuracy: 0.7846\n",
      "631/727 [=========================>....] - ETA: 0s - loss: 0.4645 - accuracy: 0.7853\n",
      "675/727 [==========================>...] - ETA: 0s - loss: 0.4695 - accuracy: 0.7844\n",
      "718/727 [============================>.] - ETA: 0s - loss: 0.4714 - accuracy: 0.7827\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4707 - accuracy: 0.7834\n",
      "Epoch 44/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.5806 - accuracy: 0.5000\n",
      " 42/727 [>.............................] - ETA: 0s - loss: 0.4577 - accuracy: 0.7857\n",
      " 87/727 [==>...........................] - ETA: 0s - loss: 0.4936 - accuracy: 0.7644\n",
      "132/727 [====>.........................] - ETA: 0s - loss: 0.4735 - accuracy: 0.7727\n",
      "176/727 [======>.......................] - ETA: 0s - loss: 0.4728 - accuracy: 0.7699\n",
      "221/727 [========>.....................] - ETA: 0s - loss: 0.4801 - accuracy: 0.7738\n",
      "266/727 [=========>....................] - ETA: 0s - loss: 0.4732 - accuracy: 0.7801\n",
      "312/727 [===========>..................] - ETA: 0s - loss: 0.4686 - accuracy: 0.7885\n",
      "358/727 [=============>................] - ETA: 0s - loss: 0.4690 - accuracy: 0.7891\n",
      "398/727 [===============>..............] - ETA: 0s - loss: 0.4675 - accuracy: 0.7889\n",
      "445/727 [=================>............] - ETA: 0s - loss: 0.4715 - accuracy: 0.7843\n",
      "488/727 [===================>..........] - ETA: 0s - loss: 0.4757 - accuracy: 0.7838\n",
      "531/727 [====================>.........] - ETA: 0s - loss: 0.4873 - accuracy: 0.7787\n",
      "574/727 [======================>.......] - ETA: 0s - loss: 0.4861 - accuracy: 0.7770\n",
      "618/727 [========================>.....] - ETA: 0s - loss: 0.4852 - accuracy: 0.7759\n",
      "665/727 [==========================>...] - ETA: 0s - loss: 0.4870 - accuracy: 0.7744\n",
      "710/727 [============================>.] - ETA: 0s - loss: 0.4858 - accuracy: 0.7746\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4845 - accuracy: 0.7751\n",
      "Epoch 45/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3019 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4426 - accuracy: 0.7604\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4440 - accuracy: 0.7688\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.4728 - accuracy: 0.7500\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4790 - accuracy: 0.7554\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.4712 - accuracy: 0.7630\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4783 - accuracy: 0.7591\n",
      "321/727 [============>.................] - ETA: 0s - loss: 0.4767 - accuracy: 0.7632\n",
      "366/727 [==============>...............] - ETA: 0s - loss: 0.4702 - accuracy: 0.7691\n",
      "411/727 [===============>..............] - ETA: 0s - loss: 0.4756 - accuracy: 0.7725\n",
      "458/727 [=================>............] - ETA: 0s - loss: 0.4713 - accuracy: 0.7751\n",
      "505/727 [===================>..........] - ETA: 0s - loss: 0.4682 - accuracy: 0.7762\n",
      "550/727 [=====================>........] - ETA: 0s - loss: 0.4801 - accuracy: 0.7745\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.4854 - accuracy: 0.7723\n",
      "639/727 [=========================>....] - ETA: 0s - loss: 0.4806 - accuracy: 0.7754\n",
      "685/727 [===========================>..] - ETA: 0s - loss: 0.4801 - accuracy: 0.7752\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4791 - accuracy: 0.7765\n",
      "Epoch 46/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6738 - accuracy: 0.5000\n",
      " 43/727 [>.............................] - ETA: 0s - loss: 0.4539 - accuracy: 0.7791\n",
      " 89/727 [==>...........................] - ETA: 0s - loss: 0.4792 - accuracy: 0.7584\n",
      "133/727 [====>.........................] - ETA: 0s - loss: 0.4650 - accuracy: 0.7857\n",
      "171/727 [======>.......................] - ETA: 0s - loss: 0.4490 - accuracy: 0.7982\n",
      "216/727 [=======>......................] - ETA: 0s - loss: 0.4713 - accuracy: 0.7894\n",
      "261/727 [=========>....................] - ETA: 0s - loss: 0.4777 - accuracy: 0.7759\n",
      "305/727 [===========>..................] - ETA: 0s - loss: 0.4828 - accuracy: 0.7754\n",
      "350/727 [=============>................] - ETA: 0s - loss: 0.4820 - accuracy: 0.7729\n",
      "393/727 [===============>..............] - ETA: 0s - loss: 0.4840 - accuracy: 0.7723\n",
      "439/727 [=================>............] - ETA: 0s - loss: 0.4913 - accuracy: 0.7665\n",
      "485/727 [===================>..........] - ETA: 0s - loss: 0.5016 - accuracy: 0.7598\n",
      "531/727 [====================>.........] - ETA: 0s - loss: 0.4952 - accuracy: 0.7646\n",
      "575/727 [======================>.......] - ETA: 0s - loss: 0.4861 - accuracy: 0.7704\n",
      "620/727 [========================>.....] - ETA: 0s - loss: 0.4836 - accuracy: 0.7710\n",
      "666/727 [==========================>...] - ETA: 0s - loss: 0.4752 - accuracy: 0.7755\n",
      "710/727 [============================>.] - ETA: 0s - loss: 0.4729 - accuracy: 0.7782\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4728 - accuracy: 0.7779\n",
      "Epoch 47/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1233 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4575 - accuracy: 0.8043\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4641 - accuracy: 0.7912\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.4698 - accuracy: 0.7794\n",
      "181/727 [======>.......................] - ETA: 0s - loss: 0.4670 - accuracy: 0.7707\n",
      "225/727 [========>.....................] - ETA: 0s - loss: 0.4680 - accuracy: 0.7711\n",
      "271/727 [==========>...................] - ETA: 0s - loss: 0.4659 - accuracy: 0.7712\n",
      "317/727 [============>.................] - ETA: 0s - loss: 0.4624 - accuracy: 0.7760\n",
      "362/727 [=============>................] - ETA: 0s - loss: 0.4577 - accuracy: 0.7790\n",
      "406/727 [===============>..............] - ETA: 0s - loss: 0.4659 - accuracy: 0.7771\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.4624 - accuracy: 0.7800\n",
      "495/727 [===================>..........] - ETA: 0s - loss: 0.4656 - accuracy: 0.7808\n",
      "541/727 [=====================>........] - ETA: 0s - loss: 0.4788 - accuracy: 0.7754\n",
      "587/727 [=======================>......] - ETA: 0s - loss: 0.4714 - accuracy: 0.7794\n",
      "632/727 [=========================>....] - ETA: 0s - loss: 0.4765 - accuracy: 0.7793\n",
      "678/727 [==========================>...] - ETA: 0s - loss: 0.4775 - accuracy: 0.7773\n",
      "725/727 [============================>.] - ETA: 0s - loss: 0.4761 - accuracy: 0.7786\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4754 - accuracy: 0.7792\n",
      "Epoch 48/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2929 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4021 - accuracy: 0.8152\n",
      " 89/727 [==>...........................] - ETA: 0s - loss: 0.4285 - accuracy: 0.8202\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.4401 - accuracy: 0.8015\n",
      "181/727 [======>.......................] - ETA: 0s - loss: 0.4441 - accuracy: 0.7983\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4433 - accuracy: 0.7991\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4456 - accuracy: 0.7971\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4453 - accuracy: 0.8000\n",
      "358/727 [=============>................] - ETA: 0s - loss: 0.4514 - accuracy: 0.7989\n",
      "401/727 [===============>..............] - ETA: 0s - loss: 0.4467 - accuracy: 0.8005\n",
      "446/727 [=================>............] - ETA: 0s - loss: 0.4486 - accuracy: 0.7948\n",
      "491/727 [===================>..........] - ETA: 0s - loss: 0.4515 - accuracy: 0.7943\n",
      "535/727 [=====================>........] - ETA: 0s - loss: 0.4652 - accuracy: 0.7841\n",
      "581/727 [======================>.......] - ETA: 0s - loss: 0.4660 - accuracy: 0.7840\n",
      "626/727 [========================>.....] - ETA: 0s - loss: 0.4674 - accuracy: 0.7827\n",
      "672/727 [==========================>...] - ETA: 0s - loss: 0.4695 - accuracy: 0.7805\n",
      "716/727 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.7786\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4687 - accuracy: 0.7792\n",
      "Epoch 49/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1752 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4765 - accuracy: 0.7889\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4611 - accuracy: 0.7722\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4825 - accuracy: 0.7667\n",
      "181/727 [======>.......................] - ETA: 0s - loss: 0.4788 - accuracy: 0.7707\n",
      "228/727 [========>.....................] - ETA: 0s - loss: 0.4724 - accuracy: 0.7697\n",
      "275/727 [==========>...................] - ETA: 0s - loss: 0.4603 - accuracy: 0.7818\n",
      "319/727 [============>.................] - ETA: 0s - loss: 0.4564 - accuracy: 0.7821\n",
      "366/727 [==============>...............] - ETA: 0s - loss: 0.4663 - accuracy: 0.7773\n",
      "411/727 [===============>..............] - ETA: 0s - loss: 0.4730 - accuracy: 0.7786\n",
      "457/727 [=================>............] - ETA: 0s - loss: 0.4708 - accuracy: 0.7801\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.4626 - accuracy: 0.7837\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.4672 - accuracy: 0.7801\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.4712 - accuracy: 0.7798\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.4664 - accuracy: 0.7844\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.4655 - accuracy: 0.7857\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4652 - accuracy: 0.7847\n",
      "Epoch 50/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1819 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5222 - accuracy: 0.7021\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4949 - accuracy: 0.7554\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4906 - accuracy: 0.7645\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.4698 - accuracy: 0.7908\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.4648 - accuracy: 0.7957\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4605 - accuracy: 0.7989\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4658 - accuracy: 0.7950\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4707 - accuracy: 0.7873\n",
      "416/727 [================>.............] - ETA: 0s - loss: 0.4668 - accuracy: 0.7873\n",
      "463/727 [==================>...........] - ETA: 0s - loss: 0.4609 - accuracy: 0.7894\n",
      "506/727 [===================>..........] - ETA: 0s - loss: 0.4577 - accuracy: 0.7925\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4599 - accuracy: 0.7923\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.4637 - accuracy: 0.7924\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.4664 - accuracy: 0.7891\n",
      "684/727 [===========================>..] - ETA: 0s - loss: 0.4639 - accuracy: 0.7909\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4676 - accuracy: 0.7875\n",
      "Epoch 51/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3356 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4404 - accuracy: 0.7979\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4547 - accuracy: 0.7849\n",
      "141/727 [====>.........................] - ETA: 0s - loss: 0.4391 - accuracy: 0.7872\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4586 - accuracy: 0.7823\n",
      "234/727 [========>.....................] - ETA: 0s - loss: 0.4502 - accuracy: 0.7885\n",
      "279/727 [==========>...................] - ETA: 0s - loss: 0.4516 - accuracy: 0.7867\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.4609 - accuracy: 0.7824\n",
      "364/727 [==============>...............] - ETA: 0s - loss: 0.4583 - accuracy: 0.7843\n",
      "408/727 [===============>..............] - ETA: 0s - loss: 0.4625 - accuracy: 0.7855\n",
      "454/727 [=================>............] - ETA: 0s - loss: 0.4614 - accuracy: 0.7863\n",
      "501/727 [===================>..........] - ETA: 0s - loss: 0.4626 - accuracy: 0.7834\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.4565 - accuracy: 0.7883\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.4600 - accuracy: 0.7866\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.4642 - accuracy: 0.7827\n",
      "688/727 [===========================>..] - ETA: 0s - loss: 0.4638 - accuracy: 0.7849\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4673 - accuracy: 0.7827\n",
      "Epoch 52/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 1.7731 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.5014 - accuracy: 0.7447\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4880 - accuracy: 0.7581\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4972 - accuracy: 0.7593\n",
      "166/727 [=====>........................] - ETA: 0s - loss: 0.4837 - accuracy: 0.7771\n",
      "213/727 [=======>......................] - ETA: 0s - loss: 0.4741 - accuracy: 0.7770\n",
      "259/727 [=========>....................] - ETA: 0s - loss: 0.4713 - accuracy: 0.7838\n",
      "305/727 [===========>..................] - ETA: 0s - loss: 0.4721 - accuracy: 0.7820\n",
      "351/727 [=============>................] - ETA: 0s - loss: 0.4649 - accuracy: 0.7877\n",
      "397/727 [===============>..............] - ETA: 0s - loss: 0.4685 - accuracy: 0.7859\n",
      "443/727 [=================>............] - ETA: 0s - loss: 0.4799 - accuracy: 0.7822\n",
      "489/727 [===================>..........] - ETA: 0s - loss: 0.4695 - accuracy: 0.7883\n",
      "533/727 [====================>.........] - ETA: 0s - loss: 0.4673 - accuracy: 0.7899\n",
      "579/727 [======================>.......] - ETA: 0s - loss: 0.4664 - accuracy: 0.7893\n",
      "625/727 [========================>.....] - ETA: 0s - loss: 0.4683 - accuracy: 0.7872\n",
      "671/727 [==========================>...] - ETA: 0s - loss: 0.4705 - accuracy: 0.7869\n",
      "717/727 [============================>.] - ETA: 0s - loss: 0.4717 - accuracy: 0.7838\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4705 - accuracy: 0.7847\n",
      "Epoch 53/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1696 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4979 - accuracy: 0.7604\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.4249 - accuracy: 0.8032\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.4368 - accuracy: 0.8036\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4521 - accuracy: 0.7984\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.4602 - accuracy: 0.7931\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.4730 - accuracy: 0.7932\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.4638 - accuracy: 0.7932\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4499 - accuracy: 0.7995\n",
      "415/727 [================>.............] - ETA: 0s - loss: 0.4554 - accuracy: 0.7964\n",
      "461/727 [==================>...........] - ETA: 0s - loss: 0.4684 - accuracy: 0.7907\n",
      "508/727 [===================>..........] - ETA: 0s - loss: 0.4670 - accuracy: 0.7904\n",
      "554/727 [=====================>........] - ETA: 0s - loss: 0.4667 - accuracy: 0.7906\n",
      "600/727 [=======================>......] - ETA: 0s - loss: 0.4689 - accuracy: 0.7892\n",
      "645/727 [=========================>....] - ETA: 0s - loss: 0.4683 - accuracy: 0.7891\n",
      "687/727 [===========================>..] - ETA: 0s - loss: 0.4695 - accuracy: 0.7868\n",
      "723/727 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.7842\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4716 - accuracy: 0.7840\n",
      "Epoch 54/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3080 - accuracy: 1.0000\n",
      " 38/727 [>.............................] - ETA: 0s - loss: 0.4424 - accuracy: 0.7895\n",
      " 83/727 [==>...........................] - ETA: 0s - loss: 0.4009 - accuracy: 0.8434\n",
      "125/727 [====>.........................] - ETA: 0s - loss: 0.4049 - accuracy: 0.8360\n",
      "169/727 [=====>........................] - ETA: 0s - loss: 0.4137 - accuracy: 0.8195\n",
      "215/727 [=======>......................] - ETA: 0s - loss: 0.4358 - accuracy: 0.8093\n",
      "260/727 [=========>....................] - ETA: 0s - loss: 0.4298 - accuracy: 0.8115\n",
      "306/727 [===========>..................] - ETA: 0s - loss: 0.4353 - accuracy: 0.8121\n",
      "345/727 [=============>................] - ETA: 0s - loss: 0.4526 - accuracy: 0.8014\n",
      "381/727 [==============>...............] - ETA: 0s - loss: 0.4477 - accuracy: 0.8045\n",
      "416/727 [================>.............] - ETA: 0s - loss: 0.4506 - accuracy: 0.8005\n",
      "457/727 [=================>............] - ETA: 0s - loss: 0.4509 - accuracy: 0.7987\n",
      "495/727 [===================>..........] - ETA: 0s - loss: 0.4521 - accuracy: 0.7980\n",
      "529/727 [====================>.........] - ETA: 0s - loss: 0.4549 - accuracy: 0.7949\n",
      "562/727 [======================>.......] - ETA: 0s - loss: 0.4520 - accuracy: 0.7963\n",
      "600/727 [=======================>......] - ETA: 0s - loss: 0.4575 - accuracy: 0.7917\n",
      "646/727 [=========================>....] - ETA: 0s - loss: 0.4569 - accuracy: 0.7941\n",
      "692/727 [===========================>..] - ETA: 0s - loss: 0.4594 - accuracy: 0.7905\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4589 - accuracy: 0.7895\n",
      "Epoch 55/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2588 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4811 - accuracy: 0.7500\n",
      " 87/727 [==>...........................] - ETA: 0s - loss: 0.4694 - accuracy: 0.7586\n",
      "120/727 [===>..........................] - ETA: 0s - loss: 0.4754 - accuracy: 0.7542\n",
      "158/727 [=====>........................] - ETA: 0s - loss: 0.4759 - accuracy: 0.7563\n",
      "194/727 [=======>......................] - ETA: 0s - loss: 0.4683 - accuracy: 0.7680\n",
      "233/727 [========>.....................] - ETA: 0s - loss: 0.4581 - accuracy: 0.7768\n",
      "269/727 [==========>...................] - ETA: 0s - loss: 0.4667 - accuracy: 0.7751\n",
      "300/727 [===========>..................] - ETA: 0s - loss: 0.4693 - accuracy: 0.7767\n",
      "341/727 [=============>................] - ETA: 0s - loss: 0.4657 - accuracy: 0.7757\n",
      "384/727 [==============>...............] - ETA: 0s - loss: 0.4650 - accuracy: 0.7786\n",
      "428/727 [================>.............] - ETA: 0s - loss: 0.4657 - accuracy: 0.7804\n",
      "471/727 [==================>...........] - ETA: 0s - loss: 0.4660 - accuracy: 0.7781\n",
      "515/727 [====================>.........] - ETA: 0s - loss: 0.4715 - accuracy: 0.7777\n",
      "557/727 [=====================>........] - ETA: 0s - loss: 0.4677 - accuracy: 0.7801\n",
      "593/727 [=======================>......] - ETA: 0s - loss: 0.4675 - accuracy: 0.7791\n",
      "635/727 [=========================>....] - ETA: 0s - loss: 0.4623 - accuracy: 0.7827\n",
      "672/727 [==========================>...] - ETA: 0s - loss: 0.4661 - accuracy: 0.7850\n",
      "708/727 [============================>.] - ETA: 0s - loss: 0.4681 - accuracy: 0.7825\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4695 - accuracy: 0.7840\n",
      "Epoch 56/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2357 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4486 - accuracy: 0.7857\n",
      " 96/727 [==>...........................] - ETA: 0s - loss: 0.4400 - accuracy: 0.8125\n",
      "143/727 [====>.........................] - ETA: 0s - loss: 0.4349 - accuracy: 0.8147\n",
      "188/727 [======>.......................] - ETA: 0s - loss: 0.4436 - accuracy: 0.8138\n",
      "236/727 [========>.....................] - ETA: 0s - loss: 0.4427 - accuracy: 0.8072\n",
      "284/727 [==========>...................] - ETA: 0s - loss: 0.4552 - accuracy: 0.8011\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4590 - accuracy: 0.7981\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.4538 - accuracy: 0.8006\n",
      "399/727 [===============>..............] - ETA: 0s - loss: 0.4628 - accuracy: 0.7920\n",
      "445/727 [=================>............] - ETA: 0s - loss: 0.4692 - accuracy: 0.7899\n",
      "492/727 [===================>..........] - ETA: 0s - loss: 0.4696 - accuracy: 0.7886\n",
      "530/727 [====================>.........] - ETA: 0s - loss: 0.4706 - accuracy: 0.7896\n",
      "574/727 [======================>.......] - ETA: 0s - loss: 0.4734 - accuracy: 0.7875\n",
      "616/727 [========================>.....] - ETA: 0s - loss: 0.4678 - accuracy: 0.7873\n",
      "663/727 [==========================>...] - ETA: 0s - loss: 0.4698 - accuracy: 0.7858\n",
      "710/727 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.7831\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4703 - accuracy: 0.7834\n",
      "Epoch 57/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3366 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4733 - accuracy: 0.7812\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4384 - accuracy: 0.7989\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.4924 - accuracy: 0.7554\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4863 - accuracy: 0.7581\n",
      "232/727 [========>.....................] - ETA: 0s - loss: 0.4735 - accuracy: 0.7651\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.4728 - accuracy: 0.7690\n",
      "323/727 [============>.................] - ETA: 0s - loss: 0.4659 - accuracy: 0.7802\n",
      "370/727 [==============>...............] - ETA: 0s - loss: 0.4694 - accuracy: 0.7770\n",
      "415/727 [================>.............] - ETA: 0s - loss: 0.4698 - accuracy: 0.7795\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4740 - accuracy: 0.7745\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.4775 - accuracy: 0.7718\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.4787 - accuracy: 0.7710\n",
      "591/727 [=======================>......] - ETA: 0s - loss: 0.4769 - accuracy: 0.7724\n",
      "636/727 [=========================>....] - ETA: 0s - loss: 0.4772 - accuracy: 0.7752\n",
      "681/727 [===========================>..] - ETA: 0s - loss: 0.4751 - accuracy: 0.7753\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4717 - accuracy: 0.7765\n",
      "Epoch 58/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1517 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.3770 - accuracy: 0.8333\n",
      " 89/727 [==>...........................] - ETA: 0s - loss: 0.4172 - accuracy: 0.8090\n",
      "137/727 [====>.........................] - ETA: 0s - loss: 0.4321 - accuracy: 0.7847\n",
      "177/727 [======>.......................] - ETA: 0s - loss: 0.4224 - accuracy: 0.7994\n",
      "221/727 [========>.....................] - ETA: 0s - loss: 0.4430 - accuracy: 0.7941\n",
      "266/727 [=========>....................] - ETA: 0s - loss: 0.4437 - accuracy: 0.7932\n",
      "312/727 [===========>..................] - ETA: 0s - loss: 0.4451 - accuracy: 0.7965\n",
      "357/727 [=============>................] - ETA: 0s - loss: 0.4476 - accuracy: 0.7983\n",
      "404/727 [===============>..............] - ETA: 0s - loss: 0.4621 - accuracy: 0.7884\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.4611 - accuracy: 0.7878\n",
      "493/727 [===================>..........] - ETA: 0s - loss: 0.4597 - accuracy: 0.7870\n",
      "539/727 [=====================>........] - ETA: 0s - loss: 0.4573 - accuracy: 0.7913\n",
      "584/727 [=======================>......] - ETA: 0s - loss: 0.4565 - accuracy: 0.7894\n",
      "630/727 [========================>.....] - ETA: 0s - loss: 0.4545 - accuracy: 0.7913\n",
      "677/727 [==========================>...] - ETA: 0s - loss: 0.4631 - accuracy: 0.7843\n",
      "722/727 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.7853\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4621 - accuracy: 0.7847\n",
      "Epoch 59/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3212 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5005 - accuracy: 0.7391\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4842 - accuracy: 0.7692\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4763 - accuracy: 0.7778\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.4703 - accuracy: 0.7821\n",
      "223/727 [========>.....................] - ETA: 0s - loss: 0.4675 - accuracy: 0.7803\n",
      "269/727 [==========>...................] - ETA: 0s - loss: 0.4662 - accuracy: 0.7844\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.4615 - accuracy: 0.7825\n",
      "358/727 [=============>................] - ETA: 0s - loss: 0.4507 - accuracy: 0.7863\n",
      "404/727 [===============>..............] - ETA: 0s - loss: 0.4621 - accuracy: 0.7809\n",
      "448/727 [=================>............] - ETA: 0s - loss: 0.4603 - accuracy: 0.7801\n",
      "494/727 [===================>..........] - ETA: 0s - loss: 0.4603 - accuracy: 0.7763\n",
      "538/727 [=====================>........] - ETA: 0s - loss: 0.4537 - accuracy: 0.7788\n",
      "582/727 [=======================>......] - ETA: 0s - loss: 0.4532 - accuracy: 0.7801\n",
      "629/727 [========================>.....] - ETA: 0s - loss: 0.4541 - accuracy: 0.7822\n",
      "673/727 [==========================>...] - ETA: 0s - loss: 0.4555 - accuracy: 0.7808\n",
      "718/727 [============================>.] - ETA: 0s - loss: 0.4541 - accuracy: 0.7827\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4536 - accuracy: 0.7834\n",
      "Epoch 60/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1560 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4829 - accuracy: 0.7717\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4884 - accuracy: 0.7849\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4580 - accuracy: 0.8007\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4432 - accuracy: 0.8104\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4492 - accuracy: 0.8040\n",
      "273/727 [==========>...................] - ETA: 0s - loss: 0.4546 - accuracy: 0.7985\n",
      "321/727 [============>.................] - ETA: 0s - loss: 0.4462 - accuracy: 0.8053\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.4532 - accuracy: 0.8022\n",
      "399/727 [===============>..............] - ETA: 0s - loss: 0.4597 - accuracy: 0.7995\n",
      "440/727 [=================>............] - ETA: 0s - loss: 0.4592 - accuracy: 0.8000\n",
      "481/727 [==================>...........] - ETA: 0s - loss: 0.4529 - accuracy: 0.8015\n",
      "525/727 [====================>.........] - ETA: 0s - loss: 0.4519 - accuracy: 0.8019\n",
      "569/727 [======================>.......] - ETA: 0s - loss: 0.4507 - accuracy: 0.8032\n",
      "613/727 [========================>.....] - ETA: 0s - loss: 0.4553 - accuracy: 0.7985\n",
      "657/727 [==========================>...] - ETA: 0s - loss: 0.4630 - accuracy: 0.7915\n",
      "702/727 [===========================>..] - ETA: 0s - loss: 0.4644 - accuracy: 0.7906\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4609 - accuracy: 0.7916\n",
      "Epoch 61/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3917 - accuracy: 0.5000\n",
      " 44/727 [>.............................] - ETA: 0s - loss: 0.4073 - accuracy: 0.7955\n",
      " 83/727 [==>...........................] - ETA: 0s - loss: 0.4372 - accuracy: 0.7771\n",
      "128/727 [====>.........................] - ETA: 0s - loss: 0.4300 - accuracy: 0.7891\n",
      "173/727 [======>.......................] - ETA: 0s - loss: 0.4410 - accuracy: 0.7832\n",
      "218/727 [=======>......................] - ETA: 0s - loss: 0.4328 - accuracy: 0.7959\n",
      "262/727 [=========>....................] - ETA: 0s - loss: 0.4259 - accuracy: 0.8015\n",
      "305/727 [===========>..................] - ETA: 0s - loss: 0.4339 - accuracy: 0.8016\n",
      "351/727 [=============>................] - ETA: 0s - loss: 0.4435 - accuracy: 0.8034\n",
      "398/727 [===============>..............] - ETA: 0s - loss: 0.4382 - accuracy: 0.8028\n",
      "445/727 [=================>............] - ETA: 0s - loss: 0.4336 - accuracy: 0.8034\n",
      "492/727 [===================>..........] - ETA: 0s - loss: 0.4450 - accuracy: 0.7988\n",
      "537/727 [=====================>........] - ETA: 0s - loss: 0.4496 - accuracy: 0.7970\n",
      "582/727 [=======================>......] - ETA: 0s - loss: 0.4500 - accuracy: 0.7964\n",
      "625/727 [========================>.....] - ETA: 0s - loss: 0.4562 - accuracy: 0.7912\n",
      "669/727 [==========================>...] - ETA: 0s - loss: 0.4606 - accuracy: 0.7877\n",
      "713/727 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.7875\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4617 - accuracy: 0.7882\n",
      "Epoch 62/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6188 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4827 - accuracy: 0.7660\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4833 - accuracy: 0.7692\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.4609 - accuracy: 0.7836\n",
      "177/727 [======>.......................] - ETA: 0s - loss: 0.4650 - accuracy: 0.7853\n",
      "221/727 [========>.....................] - ETA: 0s - loss: 0.4694 - accuracy: 0.7873\n",
      "266/727 [=========>....................] - ETA: 0s - loss: 0.4837 - accuracy: 0.7801\n",
      "313/727 [===========>..................] - ETA: 0s - loss: 0.4703 - accuracy: 0.7843\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.4623 - accuracy: 0.7883\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.4544 - accuracy: 0.7914\n",
      "449/727 [=================>............] - ETA: 0s - loss: 0.4552 - accuracy: 0.7895\n",
      "485/727 [===================>..........] - ETA: 0s - loss: 0.4557 - accuracy: 0.7918\n",
      "514/727 [====================>.........] - ETA: 0s - loss: 0.4592 - accuracy: 0.7879\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4552 - accuracy: 0.7905\n",
      "581/727 [======================>.......] - ETA: 0s - loss: 0.4558 - accuracy: 0.7917\n",
      "620/727 [========================>.....] - ETA: 0s - loss: 0.4539 - accuracy: 0.7944\n",
      "663/727 [==========================>...] - ETA: 0s - loss: 0.4537 - accuracy: 0.7949\n",
      "704/727 [============================>.] - ETA: 0s - loss: 0.4576 - accuracy: 0.7912\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4586 - accuracy: 0.7902\n",
      "Epoch 63/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.4647 - accuracy: 0.5000\n",
      " 40/727 [>.............................] - ETA: 0s - loss: 0.4369 - accuracy: 0.8000\n",
      " 81/727 [==>...........................] - ETA: 0s - loss: 0.4612 - accuracy: 0.7716\n",
      "119/727 [===>..........................] - ETA: 0s - loss: 0.4508 - accuracy: 0.7731\n",
      "162/727 [=====>........................] - ETA: 0s - loss: 0.4419 - accuracy: 0.7809\n",
      "207/727 [=======>......................] - ETA: 0s - loss: 0.4369 - accuracy: 0.7899\n",
      "252/727 [=========>....................] - ETA: 0s - loss: 0.4546 - accuracy: 0.7897\n",
      "294/727 [===========>..................] - ETA: 0s - loss: 0.4565 - accuracy: 0.7925\n",
      "329/727 [============>.................] - ETA: 0s - loss: 0.4540 - accuracy: 0.7903\n",
      "366/727 [==============>...............] - ETA: 0s - loss: 0.4595 - accuracy: 0.7910\n",
      "406/727 [===============>..............] - ETA: 0s - loss: 0.4636 - accuracy: 0.7894\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.4640 - accuracy: 0.7856\n",
      "482/727 [==================>...........] - ETA: 0s - loss: 0.4620 - accuracy: 0.7863\n",
      "521/727 [====================>.........] - ETA: 0s - loss: 0.4566 - accuracy: 0.7898\n",
      "564/727 [======================>.......] - ETA: 0s - loss: 0.4635 - accuracy: 0.7855\n",
      "602/727 [=======================>......] - ETA: 0s - loss: 0.4634 - accuracy: 0.7841\n",
      "641/727 [=========================>....] - ETA: 0s - loss: 0.4619 - accuracy: 0.7832\n",
      "678/727 [==========================>...] - ETA: 0s - loss: 0.4592 - accuracy: 0.7854\n",
      "719/727 [============================>.] - ETA: 0s - loss: 0.4624 - accuracy: 0.7858\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4626 - accuracy: 0.7854\n",
      "Epoch 64/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2428 - accuracy: 1.0000\n",
      " 38/727 [>.............................] - ETA: 0s - loss: 0.4017 - accuracy: 0.8289\n",
      " 82/727 [==>...........................] - ETA: 0s - loss: 0.4679 - accuracy: 0.7866\n",
      "127/727 [====>.........................] - ETA: 0s - loss: 0.4770 - accuracy: 0.7835\n",
      "173/727 [======>.......................] - ETA: 0s - loss: 0.4786 - accuracy: 0.7746\n",
      "218/727 [=======>......................] - ETA: 0s - loss: 0.4776 - accuracy: 0.7729\n",
      "263/727 [=========>....................] - ETA: 0s - loss: 0.4695 - accuracy: 0.7776\n",
      "300/727 [===========>..................] - ETA: 0s - loss: 0.4667 - accuracy: 0.7783\n",
      "346/727 [=============>................] - ETA: 0s - loss: 0.4543 - accuracy: 0.7861\n",
      "388/727 [===============>..............] - ETA: 0s - loss: 0.4511 - accuracy: 0.7835\n",
      "435/727 [================>.............] - ETA: 0s - loss: 0.4488 - accuracy: 0.7851\n",
      "480/727 [==================>...........] - ETA: 0s - loss: 0.4449 - accuracy: 0.7906\n",
      "525/727 [====================>.........] - ETA: 0s - loss: 0.4498 - accuracy: 0.7876\n",
      "570/727 [======================>.......] - ETA: 0s - loss: 0.4517 - accuracy: 0.7816\n",
      "612/727 [========================>.....] - ETA: 0s - loss: 0.4472 - accuracy: 0.7827\n",
      "656/727 [==========================>...] - ETA: 0s - loss: 0.4481 - accuracy: 0.7835\n",
      "701/727 [===========================>..] - ETA: 0s - loss: 0.4498 - accuracy: 0.7846\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4506 - accuracy: 0.7840\n",
      "Epoch 65/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2991 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.3917 - accuracy: 0.8511\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4190 - accuracy: 0.8152\n",
      "133/727 [====>.........................] - ETA: 0s - loss: 0.4038 - accuracy: 0.8158\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.4295 - accuracy: 0.8017\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4474 - accuracy: 0.7920\n",
      "270/727 [==========>...................] - ETA: 0s - loss: 0.4572 - accuracy: 0.7852\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4587 - accuracy: 0.7787\n",
      "360/727 [=============>................] - ETA: 0s - loss: 0.4573 - accuracy: 0.7792\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.4518 - accuracy: 0.7802\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.4568 - accuracy: 0.7800\n",
      "495/727 [===================>..........] - ETA: 0s - loss: 0.4557 - accuracy: 0.7788\n",
      "540/727 [=====================>........] - ETA: 0s - loss: 0.4555 - accuracy: 0.7815\n",
      "586/727 [=======================>......] - ETA: 0s - loss: 0.4625 - accuracy: 0.7799\n",
      "631/727 [=========================>....] - ETA: 0s - loss: 0.4610 - accuracy: 0.7805\n",
      "676/727 [==========================>...] - ETA: 0s - loss: 0.4548 - accuracy: 0.7825\n",
      "721/727 [============================>.] - ETA: 0s - loss: 0.4552 - accuracy: 0.7829\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4535 - accuracy: 0.7840\n",
      "Epoch 66/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.4867 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4303 - accuracy: 0.8043\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.3997 - accuracy: 0.8297\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.4511 - accuracy: 0.7868\n",
      "181/727 [======>.......................] - ETA: 0s - loss: 0.4376 - accuracy: 0.7956\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4383 - accuracy: 0.7974\n",
      "272/727 [==========>...................] - ETA: 0s - loss: 0.4363 - accuracy: 0.7978\n",
      "319/727 [============>.................] - ETA: 0s - loss: 0.4391 - accuracy: 0.7900\n",
      "364/727 [==============>...............] - ETA: 0s - loss: 0.4389 - accuracy: 0.7940\n",
      "409/727 [===============>..............] - ETA: 0s - loss: 0.4461 - accuracy: 0.7958\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.4541 - accuracy: 0.7928\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4581 - accuracy: 0.7878\n",
      "547/727 [=====================>........] - ETA: 0s - loss: 0.4559 - accuracy: 0.7879\n",
      "593/727 [=======================>......] - ETA: 0s - loss: 0.4556 - accuracy: 0.7901\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.4539 - accuracy: 0.7906\n",
      "685/727 [===========================>..] - ETA: 0s - loss: 0.4534 - accuracy: 0.7898\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4568 - accuracy: 0.7875\n",
      "Epoch 67/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2272 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.5353 - accuracy: 0.7188\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4660 - accuracy: 0.7802\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4548 - accuracy: 0.7852\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4410 - accuracy: 0.7940\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4292 - accuracy: 0.8009\n",
      "271/727 [==========>...................] - ETA: 0s - loss: 0.4227 - accuracy: 0.8044\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.4265 - accuracy: 0.8016\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.4280 - accuracy: 0.8019\n",
      "407/727 [===============>..............] - ETA: 0s - loss: 0.4339 - accuracy: 0.7998\n",
      "451/727 [=================>............] - ETA: 0s - loss: 0.4303 - accuracy: 0.8016\n",
      "497/727 [===================>..........] - ETA: 0s - loss: 0.4372 - accuracy: 0.7988\n",
      "542/727 [=====================>........] - ETA: 0s - loss: 0.4380 - accuracy: 0.7970\n",
      "588/727 [=======================>......] - ETA: 0s - loss: 0.4387 - accuracy: 0.7959\n",
      "633/727 [=========================>....] - ETA: 0s - loss: 0.4435 - accuracy: 0.7930\n",
      "679/727 [===========================>..] - ETA: 0s - loss: 0.4442 - accuracy: 0.7923\n",
      "724/727 [============================>.] - ETA: 0s - loss: 0.4456 - accuracy: 0.7928\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4462 - accuracy: 0.7923\n",
      "Epoch 68/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3669 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4148 - accuracy: 0.8043\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4295 - accuracy: 0.7944\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4414 - accuracy: 0.7935\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4435 - accuracy: 0.7995\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4492 - accuracy: 0.7965\n",
      "271/727 [==========>...................] - ETA: 0s - loss: 0.4585 - accuracy: 0.7897\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.4495 - accuracy: 0.7873\n",
      "360/727 [=============>................] - ETA: 0s - loss: 0.4462 - accuracy: 0.7764\n",
      "403/727 [===============>..............] - ETA: 0s - loss: 0.4520 - accuracy: 0.7742\n",
      "449/727 [=================>............] - ETA: 0s - loss: 0.4529 - accuracy: 0.7762\n",
      "494/727 [===================>..........] - ETA: 0s - loss: 0.4586 - accuracy: 0.7692\n",
      "541/727 [=====================>........] - ETA: 0s - loss: 0.4544 - accuracy: 0.7699\n",
      "587/727 [=======================>......] - ETA: 0s - loss: 0.4590 - accuracy: 0.7666\n",
      "633/727 [=========================>....] - ETA: 0s - loss: 0.4557 - accuracy: 0.7709\n",
      "679/727 [===========================>..] - ETA: 0s - loss: 0.4531 - accuracy: 0.7732\n",
      "721/727 [============================>.] - ETA: 0s - loss: 0.4530 - accuracy: 0.7739\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4533 - accuracy: 0.7737\n",
      "Epoch 69/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3638 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4729 - accuracy: 0.8043\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4361 - accuracy: 0.8167\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4422 - accuracy: 0.7963\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.4404 - accuracy: 0.8060\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4368 - accuracy: 0.8030\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.4310 - accuracy: 0.8032\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4326 - accuracy: 0.7953\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.4360 - accuracy: 0.7890\n",
      "411/727 [===============>..............] - ETA: 0s - loss: 0.4423 - accuracy: 0.7920\n",
      "457/727 [=================>............] - ETA: 0s - loss: 0.4454 - accuracy: 0.7877\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.4380 - accuracy: 0.7966\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4368 - accuracy: 0.7960\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.4435 - accuracy: 0.7945\n",
      "638/727 [=========================>....] - ETA: 0s - loss: 0.4414 - accuracy: 0.7947\n",
      "683/727 [===========================>..] - ETA: 0s - loss: 0.4453 - accuracy: 0.7906\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4446 - accuracy: 0.7916\n",
      "Epoch 70/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7917 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.3985 - accuracy: 0.8191\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4192 - accuracy: 0.8043\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4407 - accuracy: 0.7899\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4307 - accuracy: 0.8081\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4273 - accuracy: 0.8052\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.4328 - accuracy: 0.8058\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.4404 - accuracy: 0.8025\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4421 - accuracy: 0.7995\n",
      "414/727 [================>.............] - ETA: 0s - loss: 0.4464 - accuracy: 0.7935\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4405 - accuracy: 0.7974\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.4369 - accuracy: 0.7992\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.4418 - accuracy: 0.7965\n",
      "593/727 [=======================>......] - ETA: 0s - loss: 0.4454 - accuracy: 0.7968\n",
      "639/727 [=========================>....] - ETA: 0s - loss: 0.4475 - accuracy: 0.7958\n",
      "687/727 [===========================>..] - ETA: 0s - loss: 0.4455 - accuracy: 0.7962\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4503 - accuracy: 0.7916\n",
      "Epoch 71/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.5230 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4637 - accuracy: 0.7708\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4402 - accuracy: 0.8011\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.4331 - accuracy: 0.7964\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4444 - accuracy: 0.8011\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4520 - accuracy: 0.7944\n",
      "278/727 [==========>...................] - ETA: 0s - loss: 0.4586 - accuracy: 0.7860\n",
      "323/727 [============>.................] - ETA: 0s - loss: 0.4571 - accuracy: 0.7910\n",
      "370/727 [==============>...............] - ETA: 0s - loss: 0.4544 - accuracy: 0.7905\n",
      "415/727 [================>.............] - ETA: 0s - loss: 0.4542 - accuracy: 0.7880\n",
      "461/727 [==================>...........] - ETA: 0s - loss: 0.4623 - accuracy: 0.7831\n",
      "505/727 [===================>..........] - ETA: 0s - loss: 0.4627 - accuracy: 0.7832\n",
      "552/727 [=====================>........] - ETA: 0s - loss: 0.4565 - accuracy: 0.7853\n",
      "598/727 [=======================>......] - ETA: 0s - loss: 0.4571 - accuracy: 0.7843\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.4567 - accuracy: 0.7858\n",
      "689/727 [===========================>..] - ETA: 0s - loss: 0.4524 - accuracy: 0.7910\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4582 - accuracy: 0.7875\n",
      "Epoch 72/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.5002 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5017 - accuracy: 0.7609\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4884 - accuracy: 0.7826\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.4728 - accuracy: 0.7878\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.4800 - accuracy: 0.7842\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.4684 - accuracy: 0.7891\n",
      "275/727 [==========>...................] - ETA: 0s - loss: 0.4682 - accuracy: 0.7855\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4669 - accuracy: 0.7826\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7880\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.4679 - accuracy: 0.7845\n",
      "458/727 [=================>............] - ETA: 0s - loss: 0.4654 - accuracy: 0.7871\n",
      "505/727 [===================>..........] - ETA: 0s - loss: 0.4667 - accuracy: 0.7842\n",
      "553/727 [=====================>........] - ETA: 0s - loss: 0.4642 - accuracy: 0.7893\n",
      "599/727 [=======================>......] - ETA: 0s - loss: 0.4608 - accuracy: 0.7880\n",
      "645/727 [=========================>....] - ETA: 0s - loss: 0.4615 - accuracy: 0.7868\n",
      "692/727 [===========================>..] - ETA: 0s - loss: 0.4583 - accuracy: 0.7883\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4547 - accuracy: 0.7895\n",
      "Epoch 73/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1260 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4756 - accuracy: 0.7500\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4311 - accuracy: 0.8022\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4244 - accuracy: 0.8111\n",
      "181/727 [======>.......................] - ETA: 0s - loss: 0.4322 - accuracy: 0.8066\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4312 - accuracy: 0.8062\n",
      "271/727 [==========>...................] - ETA: 0s - loss: 0.4351 - accuracy: 0.8044\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.4441 - accuracy: 0.7968\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.4448 - accuracy: 0.7964\n",
      "408/727 [===============>..............] - ETA: 0s - loss: 0.4472 - accuracy: 0.7880\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.4434 - accuracy: 0.7895\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4419 - accuracy: 0.7908\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4442 - accuracy: 0.7914\n",
      "594/727 [=======================>......] - ETA: 0s - loss: 0.4449 - accuracy: 0.7904\n",
      "639/727 [=========================>....] - ETA: 0s - loss: 0.4488 - accuracy: 0.7911\n",
      "687/727 [===========================>..] - ETA: 0s - loss: 0.4495 - accuracy: 0.7918\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4489 - accuracy: 0.7909\n",
      "Epoch 74/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1622 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4047 - accuracy: 0.8152\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4479 - accuracy: 0.7796\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.4572 - accuracy: 0.7786\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4616 - accuracy: 0.7730\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.4579 - accuracy: 0.7826\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4509 - accuracy: 0.7844\n",
      "321/727 [============>.................] - ETA: 0s - loss: 0.4506 - accuracy: 0.7850\n",
      "366/727 [==============>...............] - ETA: 0s - loss: 0.4430 - accuracy: 0.7923\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.4415 - accuracy: 0.7966\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4386 - accuracy: 0.7996\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.4318 - accuracy: 0.8006\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4301 - accuracy: 0.8024\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.4319 - accuracy: 0.7995\n",
      "640/727 [=========================>....] - ETA: 0s - loss: 0.4332 - accuracy: 0.7945\n",
      "684/727 [===========================>..] - ETA: 0s - loss: 0.4285 - accuracy: 0.7968\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4387 - accuracy: 0.7909\n",
      "Epoch 75/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3570 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4971 - accuracy: 0.7234\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4871 - accuracy: 0.7609\n",
      "137/727 [====>.........................] - ETA: 0s - loss: 0.4518 - accuracy: 0.7920\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.4776 - accuracy: 0.7732\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.4750 - accuracy: 0.7783\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4665 - accuracy: 0.7808\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4618 - accuracy: 0.7795\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.4524 - accuracy: 0.7812\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.4489 - accuracy: 0.7833\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4484 - accuracy: 0.7821\n",
      "504/727 [===================>..........] - ETA: 0s - loss: 0.4587 - accuracy: 0.7768\n",
      "550/727 [=====================>........] - ETA: 0s - loss: 0.4550 - accuracy: 0.7782\n",
      "589/727 [=======================>......] - ETA: 0s - loss: 0.4565 - accuracy: 0.7776\n",
      "637/727 [=========================>....] - ETA: 0s - loss: 0.4517 - accuracy: 0.7834\n",
      "683/727 [===========================>..] - ETA: 0s - loss: 0.4535 - accuracy: 0.7811\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4522 - accuracy: 0.7813\n",
      "Epoch 76/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1604 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4745 - accuracy: 0.7872\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4423 - accuracy: 0.8043\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.4587 - accuracy: 0.7868\n",
      "184/727 [======>.......................] - ETA: 0s - loss: 0.4416 - accuracy: 0.7908\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4409 - accuracy: 0.7926\n",
      "274/727 [==========>...................] - ETA: 0s - loss: 0.4472 - accuracy: 0.7901\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4553 - accuracy: 0.7891\n",
      "363/727 [=============>................] - ETA: 0s - loss: 0.4548 - accuracy: 0.7893\n",
      "406/727 [===============>..............] - ETA: 0s - loss: 0.4496 - accuracy: 0.7956\n",
      "451/727 [=================>............] - ETA: 0s - loss: 0.4488 - accuracy: 0.7971\n",
      "498/727 [===================>..........] - ETA: 0s - loss: 0.4449 - accuracy: 0.7972\n",
      "545/727 [=====================>........] - ETA: 0s - loss: 0.4394 - accuracy: 0.8009\n",
      "590/727 [=======================>......] - ETA: 0s - loss: 0.4426 - accuracy: 0.7949\n",
      "638/727 [=========================>....] - ETA: 0s - loss: 0.4407 - accuracy: 0.7947\n",
      "682/727 [===========================>..] - ETA: 0s - loss: 0.4436 - accuracy: 0.7925\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4404 - accuracy: 0.7957\n",
      "Epoch 77/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6035 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4360 - accuracy: 0.8043\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.4729 - accuracy: 0.7872\n",
      "142/727 [====>.........................] - ETA: 0s - loss: 0.4297 - accuracy: 0.8134\n",
      "186/727 [======>.......................] - ETA: 0s - loss: 0.4578 - accuracy: 0.7903\n",
      "233/727 [========>.....................] - ETA: 0s - loss: 0.4512 - accuracy: 0.7940\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.4363 - accuracy: 0.7996\n",
      "324/727 [============>.................] - ETA: 0s - loss: 0.4432 - accuracy: 0.7932\n",
      "367/727 [==============>...............] - ETA: 0s - loss: 0.4522 - accuracy: 0.7916\n",
      "412/727 [================>.............] - ETA: 0s - loss: 0.4539 - accuracy: 0.7888\n",
      "456/727 [=================>............] - ETA: 0s - loss: 0.4563 - accuracy: 0.7851\n",
      "500/727 [===================>..........] - ETA: 0s - loss: 0.4538 - accuracy: 0.7880\n",
      "545/727 [=====================>........] - ETA: 0s - loss: 0.4494 - accuracy: 0.7927\n",
      "590/727 [=======================>......] - ETA: 0s - loss: 0.4521 - accuracy: 0.7898\n",
      "635/727 [=========================>....] - ETA: 0s - loss: 0.4546 - accuracy: 0.7858\n",
      "680/727 [===========================>..] - ETA: 0s - loss: 0.4494 - accuracy: 0.7860\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4437 - accuracy: 0.7889\n",
      "Epoch 78/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1136 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.3724 - accuracy: 0.8333\n",
      " 85/727 [==>...........................] - ETA: 0s - loss: 0.3510 - accuracy: 0.8588\n",
      "123/727 [====>.........................] - ETA: 0s - loss: 0.4228 - accuracy: 0.8252\n",
      "166/727 [=====>........................] - ETA: 0s - loss: 0.4341 - accuracy: 0.8072\n",
      "213/727 [=======>......................] - ETA: 0s - loss: 0.4284 - accuracy: 0.8169\n",
      "257/727 [=========>....................] - ETA: 0s - loss: 0.4414 - accuracy: 0.8016\n",
      "299/727 [===========>..................] - ETA: 0s - loss: 0.4419 - accuracy: 0.8027\n",
      "340/727 [=============>................] - ETA: 0s - loss: 0.4393 - accuracy: 0.8044\n",
      "385/727 [==============>...............] - ETA: 0s - loss: 0.4356 - accuracy: 0.8026\n",
      "430/727 [================>.............] - ETA: 0s - loss: 0.4395 - accuracy: 0.7977\n",
      "474/727 [==================>...........] - ETA: 0s - loss: 0.4390 - accuracy: 0.7985\n",
      "519/727 [====================>.........] - ETA: 0s - loss: 0.4404 - accuracy: 0.7948\n",
      "560/727 [======================>.......] - ETA: 0s - loss: 0.4371 - accuracy: 0.7946\n",
      "596/727 [=======================>......] - ETA: 0s - loss: 0.4359 - accuracy: 0.7945\n",
      "635/727 [=========================>....] - ETA: 0s - loss: 0.4361 - accuracy: 0.7953\n",
      "678/727 [==========================>...] - ETA: 0s - loss: 0.4442 - accuracy: 0.7891\n",
      "722/727 [============================>.] - ETA: 0s - loss: 0.4415 - accuracy: 0.7902\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4419 - accuracy: 0.7902\n",
      "Epoch 79/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3634 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4726 - accuracy: 0.7826\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4502 - accuracy: 0.7802\n",
      "137/727 [====>.........................] - ETA: 0s - loss: 0.4300 - accuracy: 0.8066\n",
      "182/727 [======>.......................] - ETA: 0s - loss: 0.4464 - accuracy: 0.7857\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4416 - accuracy: 0.7930\n",
      "274/727 [==========>...................] - ETA: 0s - loss: 0.4508 - accuracy: 0.7810\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4443 - accuracy: 0.7844\n",
      "364/727 [==============>...............] - ETA: 0s - loss: 0.4378 - accuracy: 0.7871\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.4352 - accuracy: 0.7877\n",
      "448/727 [=================>............] - ETA: 0s - loss: 0.4422 - accuracy: 0.7824\n",
      "492/727 [===================>..........] - ETA: 0s - loss: 0.4481 - accuracy: 0.7795\n",
      "538/727 [=====================>........] - ETA: 0s - loss: 0.4442 - accuracy: 0.7844\n",
      "584/727 [=======================>......] - ETA: 0s - loss: 0.4422 - accuracy: 0.7860\n",
      "630/727 [========================>.....] - ETA: 0s - loss: 0.4364 - accuracy: 0.7905\n",
      "676/727 [==========================>...] - ETA: 0s - loss: 0.4408 - accuracy: 0.7899\n",
      "720/727 [============================>.] - ETA: 0s - loss: 0.4454 - accuracy: 0.7917\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4463 - accuracy: 0.7909\n",
      "Epoch 80/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2311 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4117 - accuracy: 0.7660\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4252 - accuracy: 0.8011\n",
      "140/727 [====>.........................] - ETA: 0s - loss: 0.4213 - accuracy: 0.8000\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4307 - accuracy: 0.7973\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4236 - accuracy: 0.8057\n",
      "274/727 [==========>...................] - ETA: 0s - loss: 0.4331 - accuracy: 0.7993\n",
      "319/727 [============>.................] - ETA: 0s - loss: 0.4408 - accuracy: 0.7947\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.4401 - accuracy: 0.7973\n",
      "412/727 [================>.............] - ETA: 0s - loss: 0.4488 - accuracy: 0.7937\n",
      "458/727 [=================>............] - ETA: 0s - loss: 0.4457 - accuracy: 0.7937\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4387 - accuracy: 0.7998\n",
      "549/727 [=====================>........] - ETA: 0s - loss: 0.4419 - accuracy: 0.7978\n",
      "594/727 [=======================>......] - ETA: 0s - loss: 0.4430 - accuracy: 0.7971\n",
      "639/727 [=========================>....] - ETA: 0s - loss: 0.4460 - accuracy: 0.7942\n",
      "684/727 [===========================>..] - ETA: 0s - loss: 0.4426 - accuracy: 0.7975\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4428 - accuracy: 0.7937\n",
      "Epoch 81/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3252 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.6073 - accuracy: 0.6444\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4956 - accuracy: 0.7333\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.4690 - accuracy: 0.7575\n",
      "178/727 [======>.......................] - ETA: 0s - loss: 0.4660 - accuracy: 0.7640\n",
      "211/727 [=======>......................] - ETA: 0s - loss: 0.4594 - accuracy: 0.7725\n",
      "254/727 [=========>....................] - ETA: 0s - loss: 0.4636 - accuracy: 0.7717\n",
      "299/727 [===========>..................] - ETA: 0s - loss: 0.4553 - accuracy: 0.7742\n",
      "338/727 [============>.................] - ETA: 0s - loss: 0.4511 - accuracy: 0.7766\n",
      "381/727 [==============>...............] - ETA: 0s - loss: 0.4392 - accuracy: 0.7874\n",
      "426/727 [================>.............] - ETA: 0s - loss: 0.4365 - accuracy: 0.7876\n",
      "472/727 [==================>...........] - ETA: 0s - loss: 0.4449 - accuracy: 0.7797\n",
      "517/727 [====================>.........] - ETA: 0s - loss: 0.4463 - accuracy: 0.7814\n",
      "563/727 [======================>.......] - ETA: 0s - loss: 0.4465 - accuracy: 0.7806\n",
      "609/727 [========================>.....] - ETA: 0s - loss: 0.4433 - accuracy: 0.7833\n",
      "655/727 [==========================>...] - ETA: 0s - loss: 0.4425 - accuracy: 0.7817\n",
      "697/727 [===========================>..] - ETA: 0s - loss: 0.4385 - accuracy: 0.7848\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4353 - accuracy: 0.7854\n",
      "Epoch 82/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1386 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.3109 - accuracy: 0.8830\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.3575 - accuracy: 0.8478\n",
      "129/727 [====>.........................] - ETA: 0s - loss: 0.3779 - accuracy: 0.8333\n",
      "172/727 [======>.......................] - ETA: 0s - loss: 0.4102 - accuracy: 0.8227\n",
      "215/727 [=======>......................] - ETA: 0s - loss: 0.4154 - accuracy: 0.7977\n",
      "262/727 [=========>....................] - ETA: 0s - loss: 0.4141 - accuracy: 0.8034\n",
      "306/727 [===========>..................] - ETA: 0s - loss: 0.4205 - accuracy: 0.8023\n",
      "349/727 [=============>................] - ETA: 0s - loss: 0.4191 - accuracy: 0.8009\n",
      "390/727 [===============>..............] - ETA: 0s - loss: 0.4220 - accuracy: 0.7987\n",
      "435/727 [================>.............] - ETA: 0s - loss: 0.4231 - accuracy: 0.8000\n",
      "482/727 [==================>...........] - ETA: 0s - loss: 0.4305 - accuracy: 0.7956\n",
      "527/727 [====================>.........] - ETA: 0s - loss: 0.4332 - accuracy: 0.7951\n",
      "573/727 [======================>.......] - ETA: 0s - loss: 0.4268 - accuracy: 0.7976\n",
      "620/727 [========================>.....] - ETA: 0s - loss: 0.4316 - accuracy: 0.7935\n",
      "665/727 [==========================>...] - ETA: 0s - loss: 0.4377 - accuracy: 0.7887\n",
      "708/727 [============================>.] - ETA: 0s - loss: 0.4353 - accuracy: 0.7903\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4357 - accuracy: 0.7902\n",
      "Epoch 83/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.5324 - accuracy: 0.5000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4556 - accuracy: 0.7444\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4445 - accuracy: 0.7692\n",
      "137/727 [====>.........................] - ETA: 0s - loss: 0.4238 - accuracy: 0.7847\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4341 - accuracy: 0.7778\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.4506 - accuracy: 0.7656\n",
      "267/727 [==========>...................] - ETA: 0s - loss: 0.4423 - accuracy: 0.7678\n",
      "312/727 [===========>..................] - ETA: 0s - loss: 0.4391 - accuracy: 0.7708\n",
      "358/727 [=============>................] - ETA: 0s - loss: 0.4347 - accuracy: 0.7765\n",
      "403/727 [===============>..............] - ETA: 0s - loss: 0.4398 - accuracy: 0.7792\n",
      "448/727 [=================>............] - ETA: 0s - loss: 0.4376 - accuracy: 0.7824\n",
      "492/727 [===================>..........] - ETA: 0s - loss: 0.4395 - accuracy: 0.7835\n",
      "535/727 [=====================>........] - ETA: 0s - loss: 0.4340 - accuracy: 0.7879\n",
      "581/727 [======================>.......] - ETA: 0s - loss: 0.4386 - accuracy: 0.7874\n",
      "626/727 [========================>.....] - ETA: 0s - loss: 0.4396 - accuracy: 0.7899\n",
      "670/727 [==========================>...] - ETA: 0s - loss: 0.4411 - accuracy: 0.7910\n",
      "713/727 [============================>.] - ETA: 0s - loss: 0.4385 - accuracy: 0.7945\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4405 - accuracy: 0.7930\n",
      "Epoch 84/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3423 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4144 - accuracy: 0.8043\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4098 - accuracy: 0.8167\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.4361 - accuracy: 0.7948\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.4518 - accuracy: 0.7849\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.4582 - accuracy: 0.7879\n",
      "269/727 [==========>...................] - ETA: 0s - loss: 0.4698 - accuracy: 0.7844\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4671 - accuracy: 0.7882\n",
      "357/727 [=============>................] - ETA: 0s - loss: 0.4673 - accuracy: 0.7815\n",
      "403/727 [===============>..............] - ETA: 0s - loss: 0.4649 - accuracy: 0.7816\n",
      "449/727 [=================>............] - ETA: 0s - loss: 0.4644 - accuracy: 0.7806\n",
      "496/727 [===================>..........] - ETA: 0s - loss: 0.4652 - accuracy: 0.7802\n",
      "544/727 [=====================>........] - ETA: 0s - loss: 0.4614 - accuracy: 0.7794\n",
      "589/727 [=======================>......] - ETA: 0s - loss: 0.4549 - accuracy: 0.7827\n",
      "634/727 [=========================>....] - ETA: 0s - loss: 0.4530 - accuracy: 0.7831\n",
      "670/727 [==========================>...] - ETA: 0s - loss: 0.4498 - accuracy: 0.7858\n",
      "714/727 [============================>.] - ETA: 0s - loss: 0.4487 - accuracy: 0.7864\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4474 - accuracy: 0.7875\n",
      "Epoch 85/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2192 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4414 - accuracy: 0.7979\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4474 - accuracy: 0.8000\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4488 - accuracy: 0.7926\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4498 - accuracy: 0.7917\n",
      "225/727 [========>.....................] - ETA: 0s - loss: 0.4511 - accuracy: 0.7889\n",
      "269/727 [==========>...................] - ETA: 0s - loss: 0.4532 - accuracy: 0.7881\n",
      "317/727 [============>.................] - ETA: 0s - loss: 0.4444 - accuracy: 0.7918\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.4402 - accuracy: 0.7918\n",
      "411/727 [===============>..............] - ETA: 0s - loss: 0.4292 - accuracy: 0.7993\n",
      "458/727 [=================>............] - ETA: 0s - loss: 0.4318 - accuracy: 0.8013\n",
      "503/727 [===================>..........] - ETA: 0s - loss: 0.4413 - accuracy: 0.7982\n",
      "548/727 [=====================>........] - ETA: 0s - loss: 0.4406 - accuracy: 0.7984\n",
      "595/727 [=======================>......] - ETA: 0s - loss: 0.4374 - accuracy: 0.8025\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.4369 - accuracy: 0.8030\n",
      "688/727 [===========================>..] - ETA: 0s - loss: 0.4365 - accuracy: 0.8016\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4394 - accuracy: 0.7985\n",
      "Epoch 86/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1860 - accuracy: 1.0000\n",
      " 50/727 [=>............................] - ETA: 0s - loss: 0.4058 - accuracy: 0.8200\n",
      " 97/727 [===>..........................] - ETA: 0s - loss: 0.4190 - accuracy: 0.8196\n",
      "143/727 [====>.........................] - ETA: 0s - loss: 0.4333 - accuracy: 0.8042\n",
      "188/727 [======>.......................] - ETA: 0s - loss: 0.4006 - accuracy: 0.8245\n",
      "233/727 [========>.....................] - ETA: 0s - loss: 0.4059 - accuracy: 0.8176\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4340 - accuracy: 0.7989\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4224 - accuracy: 0.8078\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.4246 - accuracy: 0.8041\n",
      "413/727 [================>.............] - ETA: 0s - loss: 0.4300 - accuracy: 0.7990\n",
      "457/727 [=================>............] - ETA: 0s - loss: 0.4357 - accuracy: 0.7932\n",
      "501/727 [===================>..........] - ETA: 0s - loss: 0.4379 - accuracy: 0.7914\n",
      "546/727 [=====================>........] - ETA: 0s - loss: 0.4404 - accuracy: 0.7930\n",
      "591/727 [=======================>......] - ETA: 0s - loss: 0.4476 - accuracy: 0.7885\n",
      "635/727 [=========================>....] - ETA: 0s - loss: 0.4456 - accuracy: 0.7898\n",
      "679/727 [===========================>..] - ETA: 0s - loss: 0.4528 - accuracy: 0.7879\n",
      "722/727 [============================>.] - ETA: 0s - loss: 0.4522 - accuracy: 0.7881\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4528 - accuracy: 0.7882\n",
      "Epoch 87/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.4521 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4417 - accuracy: 0.7979\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4281 - accuracy: 0.8022\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4684 - accuracy: 0.7963\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4540 - accuracy: 0.7917\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4420 - accuracy: 0.7952\n",
      "274/727 [==========>...................] - ETA: 0s - loss: 0.4511 - accuracy: 0.7956\n",
      "315/727 [===========>..................] - ETA: 0s - loss: 0.4533 - accuracy: 0.7921\n",
      "361/727 [=============>................] - ETA: 0s - loss: 0.4454 - accuracy: 0.7992\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.4548 - accuracy: 0.7889\n",
      "452/727 [=================>............] - ETA: 0s - loss: 0.4494 - accuracy: 0.7909\n",
      "498/727 [===================>..........] - ETA: 0s - loss: 0.4515 - accuracy: 0.7871\n",
      "544/727 [=====================>........] - ETA: 0s - loss: 0.4455 - accuracy: 0.7904\n",
      "588/727 [=======================>......] - ETA: 0s - loss: 0.4514 - accuracy: 0.7891\n",
      "633/727 [=========================>....] - ETA: 0s - loss: 0.4512 - accuracy: 0.7891\n",
      "680/727 [===========================>..] - ETA: 0s - loss: 0.4488 - accuracy: 0.7897\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4477 - accuracy: 0.7909\n",
      "Epoch 88/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.0324 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.5323 - accuracy: 0.7917\n",
      " 95/727 [==>...........................] - ETA: 0s - loss: 0.4713 - accuracy: 0.7895\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.4401 - accuracy: 0.7950\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4369 - accuracy: 0.8054\n",
      "230/727 [========>.....................] - ETA: 0s - loss: 0.4577 - accuracy: 0.7891\n",
      "275/727 [==========>...................] - ETA: 0s - loss: 0.4582 - accuracy: 0.7873\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4679 - accuracy: 0.7766\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.4529 - accuracy: 0.7812\n",
      "412/727 [================>.............] - ETA: 0s - loss: 0.4597 - accuracy: 0.7791\n",
      "459/727 [=================>............] - ETA: 0s - loss: 0.4509 - accuracy: 0.7821\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4386 - accuracy: 0.7928\n",
      "547/727 [=====================>........] - ETA: 0s - loss: 0.4338 - accuracy: 0.7971\n",
      "588/727 [=======================>......] - ETA: 0s - loss: 0.4367 - accuracy: 0.7951\n",
      "634/727 [=========================>....] - ETA: 0s - loss: 0.4358 - accuracy: 0.7934\n",
      "677/727 [==========================>...] - ETA: 0s - loss: 0.4399 - accuracy: 0.7917\n",
      "714/727 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.7899\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4388 - accuracy: 0.7895\n",
      "Epoch 89/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1777 - accuracy: 1.0000\n",
      " 42/727 [>.............................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8571\n",
      " 79/727 [==>...........................] - ETA: 0s - loss: 0.3544 - accuracy: 0.8544\n",
      "126/727 [====>.........................] - ETA: 0s - loss: 0.3679 - accuracy: 0.8294\n",
      "173/727 [======>.......................] - ETA: 0s - loss: 0.3901 - accuracy: 0.8150\n",
      "220/727 [========>.....................] - ETA: 0s - loss: 0.4042 - accuracy: 0.8136\n",
      "264/727 [=========>....................] - ETA: 0s - loss: 0.4190 - accuracy: 0.8087\n",
      "308/727 [===========>..................] - ETA: 0s - loss: 0.4112 - accuracy: 0.8166\n",
      "346/727 [=============>................] - ETA: 0s - loss: 0.4174 - accuracy: 0.8049\n",
      "385/727 [==============>...............] - ETA: 0s - loss: 0.4162 - accuracy: 0.8026\n",
      "430/727 [================>.............] - ETA: 0s - loss: 0.4166 - accuracy: 0.8000\n",
      "477/727 [==================>...........] - ETA: 0s - loss: 0.4125 - accuracy: 0.8061\n",
      "524/727 [====================>.........] - ETA: 0s - loss: 0.4099 - accuracy: 0.8063\n",
      "571/727 [======================>.......] - ETA: 0s - loss: 0.4088 - accuracy: 0.8056\n",
      "614/727 [========================>.....] - ETA: 0s - loss: 0.4126 - accuracy: 0.8046\n",
      "659/727 [==========================>...] - ETA: 0s - loss: 0.4158 - accuracy: 0.8035\n",
      "695/727 [===========================>..] - ETA: 0s - loss: 0.4205 - accuracy: 0.8050\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4265 - accuracy: 0.8026\n",
      "Epoch 90/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3438 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4285 - accuracy: 0.8125\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.3848 - accuracy: 0.8280\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.3935 - accuracy: 0.8165\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.3926 - accuracy: 0.8135\n",
      "231/727 [========>.....................] - ETA: 0s - loss: 0.4111 - accuracy: 0.8052\n",
      "277/727 [==========>...................] - ETA: 0s - loss: 0.4199 - accuracy: 0.7978\n",
      "323/727 [============>.................] - ETA: 0s - loss: 0.4219 - accuracy: 0.7941\n",
      "369/727 [==============>...............] - ETA: 0s - loss: 0.4187 - accuracy: 0.7981\n",
      "414/727 [================>.............] - ETA: 0s - loss: 0.4214 - accuracy: 0.7959\n",
      "460/727 [=================>............] - ETA: 0s - loss: 0.4317 - accuracy: 0.7880\n",
      "502/727 [===================>..........] - ETA: 0s - loss: 0.4309 - accuracy: 0.7878\n",
      "546/727 [=====================>........] - ETA: 0s - loss: 0.4343 - accuracy: 0.7857\n",
      "589/727 [=======================>......] - ETA: 0s - loss: 0.4302 - accuracy: 0.7869\n",
      "636/727 [=========================>....] - ETA: 0s - loss: 0.4283 - accuracy: 0.7925\n",
      "681/727 [===========================>..] - ETA: 0s - loss: 0.4322 - accuracy: 0.7930\n",
      "725/727 [============================>.] - ETA: 0s - loss: 0.4298 - accuracy: 0.7938\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4292 - accuracy: 0.7944\n",
      "Epoch 91/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2817 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4546 - accuracy: 0.7245\n",
      " 92/727 [==>...........................] - ETA: 0s - loss: 0.4203 - accuracy: 0.7772\n",
      "136/727 [====>.........................] - ETA: 0s - loss: 0.4139 - accuracy: 0.8015\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.4172 - accuracy: 0.7923\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4072 - accuracy: 0.7991\n",
      "274/727 [==========>...................] - ETA: 0s - loss: 0.4120 - accuracy: 0.7956\n",
      "321/727 [============>.................] - ETA: 0s - loss: 0.4135 - accuracy: 0.7991\n",
      "365/727 [==============>...............] - ETA: 0s - loss: 0.4105 - accuracy: 0.8096\n",
      "409/727 [===============>..............] - ETA: 0s - loss: 0.4197 - accuracy: 0.8007\n",
      "453/727 [=================>............] - ETA: 0s - loss: 0.4183 - accuracy: 0.8024\n",
      "497/727 [===================>..........] - ETA: 0s - loss: 0.4254 - accuracy: 0.8008\n",
      "543/727 [=====================>........] - ETA: 0s - loss: 0.4257 - accuracy: 0.7993\n",
      "589/727 [=======================>......] - ETA: 0s - loss: 0.4253 - accuracy: 0.7980\n",
      "637/727 [=========================>....] - ETA: 0s - loss: 0.4286 - accuracy: 0.7943\n",
      "684/727 [===========================>..] - ETA: 0s - loss: 0.4276 - accuracy: 0.7946\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4278 - accuracy: 0.7937\n",
      "Epoch 92/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3466 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.4286 - accuracy: 0.8261\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.3936 - accuracy: 0.8444\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.3895 - accuracy: 0.8284\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4031 - accuracy: 0.8167\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4201 - accuracy: 0.8053\n",
      "270/727 [==========>...................] - ETA: 0s - loss: 0.4210 - accuracy: 0.7963\n",
      "314/727 [===========>..................] - ETA: 0s - loss: 0.4309 - accuracy: 0.7978\n",
      "359/727 [=============>................] - ETA: 0s - loss: 0.4242 - accuracy: 0.7994\n",
      "405/727 [===============>..............] - ETA: 0s - loss: 0.4202 - accuracy: 0.7988\n",
      "448/727 [=================>............] - ETA: 0s - loss: 0.4239 - accuracy: 0.7935\n",
      "494/727 [===================>..........] - ETA: 0s - loss: 0.4260 - accuracy: 0.7945\n",
      "539/727 [=====================>........] - ETA: 0s - loss: 0.4230 - accuracy: 0.7959\n",
      "583/727 [=======================>......] - ETA: 0s - loss: 0.4268 - accuracy: 0.7993\n",
      "627/727 [========================>.....] - ETA: 0s - loss: 0.4296 - accuracy: 0.7974\n",
      "673/727 [==========================>...] - ETA: 0s - loss: 0.4272 - accuracy: 0.7994\n",
      "718/727 [============================>.] - ETA: 0s - loss: 0.4281 - accuracy: 0.8001\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4303 - accuracy: 0.7992\n",
      "Epoch 93/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1532 - accuracy: 1.0000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.3984 - accuracy: 0.8043\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4275 - accuracy: 0.7667\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.4308 - accuracy: 0.7873\n",
      "178/727 [======>.......................] - ETA: 0s - loss: 0.4256 - accuracy: 0.7809\n",
      "221/727 [========>.....................] - ETA: 0s - loss: 0.4349 - accuracy: 0.7783\n",
      "264/727 [=========>....................] - ETA: 0s - loss: 0.4225 - accuracy: 0.7860\n",
      "308/727 [===========>..................] - ETA: 0s - loss: 0.4201 - accuracy: 0.7938\n",
      "351/727 [=============>................] - ETA: 0s - loss: 0.4204 - accuracy: 0.8020\n",
      "391/727 [===============>..............] - ETA: 0s - loss: 0.4311 - accuracy: 0.7954\n",
      "432/727 [================>.............] - ETA: 0s - loss: 0.4257 - accuracy: 0.7963\n",
      "476/727 [==================>...........] - ETA: 0s - loss: 0.4232 - accuracy: 0.7994\n",
      "522/727 [====================>.........] - ETA: 0s - loss: 0.4207 - accuracy: 0.8017\n",
      "568/727 [======================>.......] - ETA: 0s - loss: 0.4247 - accuracy: 0.7993\n",
      "613/727 [========================>.....] - ETA: 0s - loss: 0.4247 - accuracy: 0.7985\n",
      "660/727 [==========================>...] - ETA: 0s - loss: 0.4315 - accuracy: 0.7924\n",
      "706/727 [============================>.] - ETA: 0s - loss: 0.4272 - accuracy: 0.7939\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4265 - accuracy: 0.7937\n",
      "Epoch 94/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2981 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4276 - accuracy: 0.8163\n",
      " 96/727 [==>...........................] - ETA: 0s - loss: 0.4469 - accuracy: 0.7812\n",
      "139/727 [====>.........................] - ETA: 0s - loss: 0.4154 - accuracy: 0.8094\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.4129 - accuracy: 0.8169\n",
      "227/727 [========>.....................] - ETA: 0s - loss: 0.4227 - accuracy: 0.8062\n",
      "274/727 [==========>...................] - ETA: 0s - loss: 0.4199 - accuracy: 0.8066\n",
      "319/727 [============>.................] - ETA: 0s - loss: 0.4164 - accuracy: 0.8072\n",
      "363/727 [=============>................] - ETA: 0s - loss: 0.4214 - accuracy: 0.7975\n",
      "410/727 [===============>..............] - ETA: 0s - loss: 0.4204 - accuracy: 0.7963\n",
      "455/727 [=================>............] - ETA: 0s - loss: 0.4120 - accuracy: 0.8011\n",
      "498/727 [===================>..........] - ETA: 0s - loss: 0.4168 - accuracy: 0.8002\n",
      "541/727 [=====================>........] - ETA: 0s - loss: 0.4153 - accuracy: 0.8013\n",
      "586/727 [=======================>......] - ETA: 0s - loss: 0.4110 - accuracy: 0.8020\n",
      "634/727 [=========================>....] - ETA: 0s - loss: 0.4163 - accuracy: 0.7981\n",
      "681/727 [===========================>..] - ETA: 0s - loss: 0.4200 - accuracy: 0.7974\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4208 - accuracy: 0.7957\n",
      "Epoch 95/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3848 - accuracy: 0.5000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4074 - accuracy: 0.7857\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4249 - accuracy: 0.7796\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4066 - accuracy: 0.7971\n",
      "183/727 [======>.......................] - ETA: 0s - loss: 0.4042 - accuracy: 0.8033\n",
      "229/727 [========>.....................] - ETA: 0s - loss: 0.4142 - accuracy: 0.7991\n",
      "276/727 [==========>...................] - ETA: 0s - loss: 0.4300 - accuracy: 0.7989\n",
      "322/727 [============>.................] - ETA: 0s - loss: 0.4364 - accuracy: 0.7888\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.4397 - accuracy: 0.7908\n",
      "414/727 [================>.............] - ETA: 0s - loss: 0.4401 - accuracy: 0.7971\n",
      "460/727 [=================>............] - ETA: 0s - loss: 0.4443 - accuracy: 0.7946\n",
      "499/727 [===================>..........] - ETA: 0s - loss: 0.4403 - accuracy: 0.7966\n",
      "542/727 [=====================>........] - ETA: 0s - loss: 0.4344 - accuracy: 0.7961\n",
      "586/727 [=======================>......] - ETA: 0s - loss: 0.4336 - accuracy: 0.7952\n",
      "630/727 [========================>.....] - ETA: 0s - loss: 0.4312 - accuracy: 0.7976\n",
      "674/727 [==========================>...] - ETA: 0s - loss: 0.4298 - accuracy: 0.7990\n",
      "722/727 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8012\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4279 - accuracy: 0.8012\n",
      "Epoch 96/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2834 - accuracy: 1.0000\n",
      " 44/727 [>.............................] - ETA: 0s - loss: 0.4970 - accuracy: 0.7386\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4572 - accuracy: 0.7802\n",
      "138/727 [====>.........................] - ETA: 0s - loss: 0.4728 - accuracy: 0.7862\n",
      "185/727 [======>.......................] - ETA: 0s - loss: 0.4522 - accuracy: 0.7946\n",
      "228/727 [========>.....................] - ETA: 0s - loss: 0.4432 - accuracy: 0.8026\n",
      "273/727 [==========>...................] - ETA: 0s - loss: 0.4461 - accuracy: 0.8004\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4354 - accuracy: 0.8062\n",
      "368/727 [==============>...............] - ETA: 0s - loss: 0.4336 - accuracy: 0.8098\n",
      "412/727 [================>.............] - ETA: 0s - loss: 0.4302 - accuracy: 0.8119\n",
      "460/727 [=================>............] - ETA: 0s - loss: 0.4237 - accuracy: 0.8141\n",
      "506/727 [===================>..........] - ETA: 0s - loss: 0.4260 - accuracy: 0.8113\n",
      "551/727 [=====================>........] - ETA: 0s - loss: 0.4223 - accuracy: 0.8149\n",
      "598/727 [=======================>......] - ETA: 0s - loss: 0.4261 - accuracy: 0.8110\n",
      "642/727 [=========================>....] - ETA: 0s - loss: 0.4304 - accuracy: 0.8107\n",
      "686/727 [===========================>..] - ETA: 0s - loss: 0.4272 - accuracy: 0.8105\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4298 - accuracy: 0.8081\n",
      "Epoch 97/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1966 - accuracy: 1.0000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4336 - accuracy: 0.7778\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4675 - accuracy: 0.7747\n",
      "133/727 [====>.........................] - ETA: 0s - loss: 0.4580 - accuracy: 0.7707\n",
      "177/727 [======>.......................] - ETA: 0s - loss: 0.4366 - accuracy: 0.7853\n",
      "215/727 [=======>......................] - ETA: 0s - loss: 0.4377 - accuracy: 0.7837\n",
      "261/727 [=========>....................] - ETA: 0s - loss: 0.4261 - accuracy: 0.7989\n",
      "305/727 [===========>..................] - ETA: 0s - loss: 0.4211 - accuracy: 0.8033\n",
      "352/727 [=============>................] - ETA: 0s - loss: 0.4281 - accuracy: 0.7969\n",
      "397/727 [===============>..............] - ETA: 0s - loss: 0.4207 - accuracy: 0.7997\n",
      "443/727 [=================>............] - ETA: 0s - loss: 0.4218 - accuracy: 0.7991\n",
      "489/727 [===================>..........] - ETA: 0s - loss: 0.4238 - accuracy: 0.7965\n",
      "532/727 [====================>.........] - ETA: 0s - loss: 0.4257 - accuracy: 0.7970\n",
      "577/727 [======================>.......] - ETA: 0s - loss: 0.4237 - accuracy: 0.8016\n",
      "623/727 [========================>.....] - ETA: 0s - loss: 0.4197 - accuracy: 0.8034\n",
      "667/727 [==========================>...] - ETA: 0s - loss: 0.4254 - accuracy: 0.8043\n",
      "713/727 [============================>.] - ETA: 0s - loss: 0.4297 - accuracy: 0.8029\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4285 - accuracy: 0.8040\n",
      "Epoch 98/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.9050 - accuracy: 0.5000\n",
      " 45/727 [>.............................] - ETA: 0s - loss: 0.4955 - accuracy: 0.7889\n",
      " 90/727 [==>...........................] - ETA: 0s - loss: 0.4498 - accuracy: 0.7889\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4580 - accuracy: 0.7889\n",
      "180/727 [======>.......................] - ETA: 0s - loss: 0.4493 - accuracy: 0.8000\n",
      "226/727 [========>.....................] - ETA: 0s - loss: 0.4756 - accuracy: 0.7920\n",
      "272/727 [==========>...................] - ETA: 0s - loss: 0.4665 - accuracy: 0.7923\n",
      "320/727 [============>.................] - ETA: 0s - loss: 0.4581 - accuracy: 0.7969\n",
      "364/727 [==============>...............] - ETA: 0s - loss: 0.4484 - accuracy: 0.8036\n",
      "409/727 [===============>..............] - ETA: 0s - loss: 0.4401 - accuracy: 0.8068\n",
      "455/727 [=================>............] - ETA: 0s - loss: 0.4394 - accuracy: 0.8044\n",
      "500/727 [===================>..........] - ETA: 0s - loss: 0.4400 - accuracy: 0.8010\n",
      "547/727 [=====================>........] - ETA: 0s - loss: 0.4391 - accuracy: 0.7971\n",
      "593/727 [=======================>......] - ETA: 0s - loss: 0.4393 - accuracy: 0.7943\n",
      "638/727 [=========================>....] - ETA: 0s - loss: 0.4405 - accuracy: 0.7939\n",
      "684/727 [===========================>..] - ETA: 0s - loss: 0.4395 - accuracy: 0.7909\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4347 - accuracy: 0.7944\n",
      "Epoch 99/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.5174 - accuracy: 0.5000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4356 - accuracy: 0.8229\n",
      " 91/727 [==>...........................] - ETA: 0s - loss: 0.4148 - accuracy: 0.7967\n",
      "135/727 [====>.........................] - ETA: 0s - loss: 0.4093 - accuracy: 0.8148\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.4275 - accuracy: 0.7933\n",
      "224/727 [========>.....................] - ETA: 0s - loss: 0.4350 - accuracy: 0.7879\n",
      "262/727 [=========>....................] - ETA: 0s - loss: 0.4419 - accuracy: 0.7805\n",
      "303/727 [===========>..................] - ETA: 0s - loss: 0.4473 - accuracy: 0.7838\n",
      "346/727 [=============>................] - ETA: 0s - loss: 0.4439 - accuracy: 0.7876\n",
      "378/727 [==============>...............] - ETA: 0s - loss: 0.4474 - accuracy: 0.7897\n",
      "421/727 [================>.............] - ETA: 0s - loss: 0.4381 - accuracy: 0.7933\n",
      "465/727 [==================>...........] - ETA: 0s - loss: 0.4338 - accuracy: 0.7925\n",
      "510/727 [====================>.........] - ETA: 0s - loss: 0.4437 - accuracy: 0.7863\n",
      "555/727 [=====================>........] - ETA: 0s - loss: 0.4432 - accuracy: 0.7856\n",
      "600/727 [=======================>......] - ETA: 0s - loss: 0.4408 - accuracy: 0.7900\n",
      "646/727 [=========================>....] - ETA: 0s - loss: 0.4397 - accuracy: 0.7895\n",
      "693/727 [===========================>..] - ETA: 0s - loss: 0.4367 - accuracy: 0.7922\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4376 - accuracy: 0.7916\n",
      "Epoch 100/100\n",
      "\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6155 - accuracy: 0.5000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.3310 - accuracy: 0.8298\n",
      " 93/727 [==>...........................] - ETA: 0s - loss: 0.4044 - accuracy: 0.8118\n",
      "134/727 [====>.........................] - ETA: 0s - loss: 0.3958 - accuracy: 0.8284\n",
      "179/727 [======>.......................] - ETA: 0s - loss: 0.4036 - accuracy: 0.8240\n",
      "223/727 [========>.....................] - ETA: 0s - loss: 0.4170 - accuracy: 0.8184\n",
      "268/727 [==========>...................] - ETA: 0s - loss: 0.4100 - accuracy: 0.8172\n",
      "312/727 [===========>..................] - ETA: 0s - loss: 0.4125 - accuracy: 0.8141\n",
      "358/727 [=============>................] - ETA: 0s - loss: 0.4314 - accuracy: 0.8031\n",
      "403/727 [===============>..............] - ETA: 0s - loss: 0.4423 - accuracy: 0.8002\n",
      "450/727 [=================>............] - ETA: 0s - loss: 0.4379 - accuracy: 0.8011\n",
      "494/727 [===================>..........] - ETA: 0s - loss: 0.4393 - accuracy: 0.7986\n",
      "539/727 [=====================>........] - ETA: 0s - loss: 0.4408 - accuracy: 0.7959\n",
      "584/727 [=======================>......] - ETA: 0s - loss: 0.4328 - accuracy: 0.8014\n",
      "632/727 [=========================>....] - ETA: 0s - loss: 0.4313 - accuracy: 0.8014\n",
      "676/727 [==========================>...] - ETA: 0s - loss: 0.4288 - accuracy: 0.8025\n",
      "711/727 [============================>.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8031\n",
      "727/727 [==============================] - 1s 1ms/step - loss: 0.4242 - accuracy: 0.8054\n",
      "Training Data accuracy: 80.74%\n",
      "Training is complete. Model saved.\n",
      "Test Data accuracy: 75.73%\n"
     ]
    }
   ],
   "source": [
    "# Build Local ML Image\n",
    "!cp model/{model_name}.py model/train\n",
    "!chmod 777 model/train\n",
    "!docker build -t {model_name} .\n",
    "!docker run -v $(pwd)/local/$model_name:/opt/ml --rm {model_name} train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Model Artifact to Strategies Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 45936 Jun 12 16:27 local/model_long_short_predict/model/model.h5\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 45936 Jun 12 16:27 ../2_Strategies/model/model_long_short_predict.h5\n"
     ]
    }
   ],
   "source": [
    "!ls -la local/{model_name}/model/model.h5\n",
    "!cp local/{model_name}/model/model.h5 ../2_Strategies/model/{model_name}.h5\n",
    "!ls -la ../2_Strategies/model/model_*.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Remote Training via SageMaker\n",
    "\n",
    "You can choose if you want to do the training locally (Option 1) or remote via SageMaker (Option 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.1s (2/2)                                          docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.3s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.4s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.3s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.6s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.5s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.7s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.6s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.9s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.8s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.0s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          0.9s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.2s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.1s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.3s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.2s\n",
      "\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.4s (13/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.3s\n",
      "\u001b[2m => => # Collecting flask                                                      \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.5s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.4s\n",
      "\u001b[2m => => # Collecting blinker>=1.9.0 (from flask)                                \n",
      "\u001b[0m\u001b[2m => => #   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)        \n",
      "\u001b[0m\u001b[2m => => # Collecting click>=8.1.3 (from flask)                                  \n",
      "\u001b[0m\u001b[2m => => #   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)          \n",
      "\u001b[0m\u001b[2m => => # Collecting itsdangerous>=2.2.0 (from flask)                           \n",
      "\u001b[0m\u001b[2m => => #   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)   \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.6s\n",
      "\u001b[2m => => # n3.11/dist-packages (from flask) (3.1.3)                              \n",
      "\u001b[0m\u001b[2m => => # Downloading flask-3.1.1-py3-none-any.whl (103 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.7s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.6s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 1.9s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.8s\n",
      "\u001b[2m => => # Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)                   \n",
      "\u001b[0m\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.0s (13/20)                                        docker:default\n",
      "\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m => [10/16] RUN pip install flask                                          1.8s\n",
      "\u001b[2m => => # Downloading click-8.2.1-py3-none-any.whl (102 kB)                     \n",
      "\u001b[0m\u001b[2m => => # Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)               \n",
      "\u001b[0m\u001b[2m => => # Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)                    \n",
      "\u001b[0m\u001b[2m => => # Installing collected packages: jinja2, itsdangerous, click, blinker, f\n",
      "\u001b[0m\u001b[2m => => # lask                                                                  \n",
      "\u001b[0m\u001b[2m => => #   Attempting uninstall: blinker                                       \n",
      "\u001b[0m\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (14/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/16] RUN pip install flask                                    2.0s\n",
      "\u001b[0m                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "                                                                                \n",
      "\u001b[5A\u001b[0G\u001b[?25h\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[1A\u001b[0G\u001b[?25l[+] Building 2.1s (14/20)                                        docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 1.01kB                                     0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/tensorflow/tensorflow:latest    0.1s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 3.19kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [ 1/16] FROM docker.io/tensorflow/tensorflow:latest@sha256:f24e8494d4  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 2/16] RUN apt-get -y update &&          apt-get install -y -  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 3/16] RUN wget  https://github.com/ta-lib/ta-lib/releases/do  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 4/16] RUN python3 -m pip install --upgrade pip                0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 5/16] RUN pip install numpy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 6/16] RUN pip install ta-lib                                  0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 7/16] RUN pip install scipy                                   0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 8/16] RUN pip install scikit-learn                            0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [ 9/16] RUN pip install pandas                                  0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [10/16] RUN pip install flask                                    2.0s\n",
      "\u001b[0m\u001b[?25h------\n",
      " > [10/16] RUN pip install flask:\n",
      "1.250 Collecting flask\n",
      "1.265   Downloading flask-3.1.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "1.290 Collecting blinker>=1.9.0 (from flask)\n",
      "1.294   Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "1.322 Collecting click>=8.1.3 (from flask)\n",
      "1.327   Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "1.349 Collecting itsdangerous>=2.2.0 (from flask)\n",
      "1.354   Downloading itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "1.381 Collecting jinja2>=3.1.2 (from flask)\n",
      "1.385   Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "1.393 Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
      "1.394 Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "1.405 Downloading flask-3.1.1-py3-none-any.whl (103 kB)\n",
      "1.417 Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "1.427 Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "1.436 Downloading itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "1.447 Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "1.626 Installing collected packages: jinja2, itsdangerous, click, blinker, flask\n",
      "1.830   Attempting uninstall: blinker\n",
      "1.834     Found existing installation: blinker 1.4\n",
      "1.842 error: uninstall-distutils-installed-package\n",
      "1.842 \n",
      "1.842  Cannot uninstall blinker 1.4\n",
      "1.842 > It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
      "1.842 \n",
      "------\n",
      "Dockerfile:23\n",
      "--------------------\n",
      "  21 |     RUN pip install scikit-learn\n",
      "  22 |     RUN pip install pandas\n",
      "  23 | >>> RUN pip install flask\n",
      "  24 |     RUN pip install gevent\n",
      "  25 |     RUN pip install gunicorn\n",
      "--------------------\n",
      "ERROR: failed to solve: process \"/bin/sh -c pip install flask\" did not complete successfully: exit code: 1\n",
      "The push refers to repository [616431823260.dkr.ecr.us-east-1.amazonaws.com/model_long_short_predict]\n",
      "\n",
      "\u001b[1Bbf18a086: Preparing \n",
      "\u001b[1B9f137637: Preparing \n",
      "\u001b[1Bbf4089e6: Preparing \n",
      "\u001b[1Bd37393e4: Preparing \n",
      "\u001b[1B14a7ec68: Preparing \n",
      "\u001b[1B2762df8d: Preparing \n",
      "\u001b[1B4741f385: Preparing \n",
      "\u001b[1B3b07cfc8: Preparing \n",
      "\u001b[1B31842394: Preparing \n",
      "\u001b[1Bd27c87c7: Preparing \n",
      "\u001b[1B2c9ecafe: Preparing \n",
      "\u001b[1B19a049b3: Preparing \n",
      "\u001b[1B74ee02d5: Preparing \n",
      "\u001b[1B76be9372: Preparing \n",
      "\u001b[1B93e0c29d: Preparing \n",
      "\u001b[1B27f89f85: Preparing \n",
      "\u001b[1Bd2b3a8c0: Preparing \n",
      "\u001b[1B7f408ddb: Preparing \n",
      "\u001b[1B8bd7c2a2: Preparing \n",
      "\u001b[1Bbe37ceb9: Preparing \n",
      "\u001b[1B7e49cdd8: Preparing \n",
      "\u001b[1Bfe0f938f: Preparing \n",
      "\u001b[1B71112be5: Preparing \n",
      "\u001b[1Ba0a694d8: Preparing \n",
      "\u001b[1B901684b5: Preparing \n",
      "\u001b[1Bfb8f161b: Preparing \n",
      "\u001b[1B43ea46a8: Preparing \n",
      "\u001b[1Bfcc4a1a8: Preparing \n",
      "\u001b[1Blatest: digest: sha256:1328721bca72fb28754d93263b7e3e2db771ad0c4e75020cba5b84a857e71080 size: 6413\n"
     ]
    }
   ],
   "source": [
    "# Deploy ML Image to ECS\n",
    "!./build_and_push.sh $model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: model-long-short-predict-2025-06-12-16-28-06-135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-616431823260/data\n",
      "{}\n",
      "2025-06-12 16:28:08 Starting - Starting the training job...\n",
      "2025-06-12 16:28:23 Starting - Preparing the instances for training...\n",
      "2025-06-12 16:28:45 Downloading - Downloading input data...\n",
      "2025-06-12 16:29:15 Downloading - Downloading the training image...\n",
      "2025-06-12 16:30:01 Training - Training image download completed. Training in progress..\u001b[34mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mbuild_classifier:b=31,yLen=2\u001b[0m\n",
      "\u001b[34m2025-06-12 16:30:05.006992: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34mEpoch 1/100\n",
      "  1/727 [..............................] - ETA: 2:08 - loss: 0.6943 - accuracy: 0.0000e+00\n",
      " 63/727 [=>............................] - ETA: 2s - loss: 0.6881 - accuracy: 0.6270      \u001b[0m\n",
      "\u001b[34m123/727 [====>.........................] - ETA: 1s - loss: 0.6789 - accuracy: 0.6911\u001b[0m\n",
      "\u001b[34m182/727 [======>.......................] - ETA: 0s - loss: 0.6627 - accuracy: 0.7253\u001b[0m\n",
      "\u001b[34m243/727 [=========>....................] - ETA: 0s - loss: 0.6302 - accuracy: 0.7469\u001b[0m\n",
      "\u001b[34m301/727 [===========>..................] - ETA: 0s - loss: 0.6175 - accuracy: 0.7458\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.6016 - accuracy: 0.7570\u001b[0m\n",
      "\u001b[34m412/727 [================>.............] - ETA: 0s - loss: 0.5843 - accuracy: 0.7670\u001b[0m\n",
      "\u001b[34m470/727 [==================>...........] - ETA: 0s - loss: 0.5946 - accuracy: 0.7564\u001b[0m\n",
      "\u001b[34m528/727 [====================>.........] - ETA: 0s - loss: 0.5958 - accuracy: 0.7585\u001b[0m\n",
      "\u001b[34m591/727 [=======================>......] - ETA: 0s - loss: 0.5878 - accuracy: 0.7614\u001b[0m\n",
      "\u001b[34m653/727 [=========================>....] - ETA: 0s - loss: 0.5868 - accuracy: 0.7611\u001b[0m\n",
      "\u001b[34m713/727 [============================>.] - ETA: 0s - loss: 0.5832 - accuracy: 0.7630\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5835 - accuracy: 0.7620\u001b[0m\n",
      "\u001b[34mEpoch 2/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7800 - accuracy: 0.5000\n",
      " 50/727 [=>............................] - ETA: 0s - loss: 0.5661 - accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m100/727 [===>..........................] - ETA: 0s - loss: 0.5405 - accuracy: 0.7800\u001b[0m\n",
      "\u001b[34m151/727 [=====>........................] - ETA: 0s - loss: 0.5232 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m195/727 [=======>......................] - ETA: 0s - loss: 0.5295 - accuracy: 0.7718\u001b[0m\n",
      "\u001b[34m244/727 [=========>....................] - ETA: 0s - loss: 0.5391 - accuracy: 0.7705\u001b[0m\n",
      "\u001b[34m295/727 [===========>..................] - ETA: 0s - loss: 0.5343 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m326/727 [============>.................] - ETA: 0s - loss: 0.5345 - accuracy: 0.7776\u001b[0m\n",
      "\u001b[34m360/727 [=============>................] - ETA: 0s - loss: 0.5251 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m393/727 [===============>..............] - ETA: 0s - loss: 0.5338 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m424/727 [================>.............] - ETA: 0s - loss: 0.5370 - accuracy: 0.7830\u001b[0m\n",
      "\u001b[34m458/727 [=================>............] - ETA: 0s - loss: 0.5341 - accuracy: 0.7838\u001b[0m\n",
      "\u001b[34m489/727 [===================>..........] - ETA: 0s - loss: 0.5310 - accuracy: 0.7853\u001b[0m\n",
      "\u001b[34m523/727 [====================>.........] - ETA: 0s - loss: 0.5335 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34m560/727 [======================>.......] - ETA: 0s - loss: 0.5385 - accuracy: 0.7750\u001b[0m\n",
      "\u001b[34m614/727 [========================>.....] - ETA: 0s - loss: 0.5436 - accuracy: 0.7736\u001b[0m\n",
      "\u001b[34m674/727 [==========================>...] - ETA: 0s - loss: 0.5377 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 3/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7004 - accuracy: 0.5000\n",
      " 62/727 [=>............................] - ETA: 0s - loss: 0.5691 - accuracy: 0.7661\u001b[0m\n",
      "\u001b[34m123/727 [====>.........................] - ETA: 0s - loss: 0.5581 - accuracy: 0.7602\u001b[0m\n",
      "\u001b[34m184/727 [======>.......................] - ETA: 0s - loss: 0.5645 - accuracy: 0.7527\u001b[0m\n",
      "\u001b[34m244/727 [=========>....................] - ETA: 0s - loss: 0.5390 - accuracy: 0.7766\u001b[0m\n",
      "\u001b[34m290/727 [==========>...................] - ETA: 0s - loss: 0.5243 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m337/727 [============>.................] - ETA: 0s - loss: 0.5261 - accuracy: 0.7849\u001b[0m\n",
      "\u001b[34m396/727 [===============>..............] - ETA: 0s - loss: 0.5319 - accuracy: 0.7803\u001b[0m\n",
      "\u001b[34m445/727 [=================>............] - ETA: 0s - loss: 0.5257 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34m504/727 [===================>..........] - ETA: 0s - loss: 0.5263 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m551/727 [=====================>........] - ETA: 0s - loss: 0.5350 - accuracy: 0.7768\u001b[0m\n",
      "\u001b[34m601/727 [=======================>......] - ETA: 0s - loss: 0.5348 - accuracy: 0.7795\u001b[0m\n",
      "\u001b[34m660/727 [==========================>...] - ETA: 0s - loss: 0.5361 - accuracy: 0.7780\u001b[0m\n",
      "\u001b[34m717/727 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.7775\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 917us/step - loss: 0.5374 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 4/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8848 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.5082 - accuracy: 0.7833\n",
      " 99/727 [===>..........................] - ETA: 0s - loss: 0.5222 - accuracy: 0.7929\u001b[0m\n",
      "\u001b[34m152/727 [=====>........................] - ETA: 0s - loss: 0.5372 - accuracy: 0.7730\u001b[0m\n",
      "\u001b[34m206/727 [=======>......................] - ETA: 0s - loss: 0.5416 - accuracy: 0.7694\u001b[0m\n",
      "\u001b[34m267/727 [==========>...................] - ETA: 0s - loss: 0.5409 - accuracy: 0.7715\u001b[0m\n",
      "\u001b[34m323/727 [============>.................] - ETA: 0s - loss: 0.5394 - accuracy: 0.7709\u001b[0m\n",
      "\u001b[34m369/727 [==============>...............] - ETA: 0s - loss: 0.5393 - accuracy: 0.7683\u001b[0m\n",
      "\u001b[34m429/727 [================>.............] - ETA: 0s - loss: 0.5299 - accuracy: 0.7762\u001b[0m\n",
      "\u001b[34m489/727 [===================>..........] - ETA: 0s - loss: 0.5334 - accuracy: 0.7710\u001b[0m\n",
      "\u001b[34m550/727 [=====================>........] - ETA: 0s - loss: 0.5364 - accuracy: 0.7700\u001b[0m\n",
      "\u001b[34m608/727 [========================>.....] - ETA: 0s - loss: 0.5251 - accuracy: 0.7796\u001b[0m\n",
      "\u001b[34m669/727 [==========================>...] - ETA: 0s - loss: 0.5279 - accuracy: 0.7780\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 907us/step - loss: 0.5283 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 5/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2706 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 55/727 [=>............................] - ETA: 0s - loss: 0.5479 - accuracy: 0.7364\u001b[0m\n",
      "\u001b[34m110/727 [===>..........................] - ETA: 0s - loss: 0.5177 - accuracy: 0.7682\u001b[0m\n",
      "\u001b[34m167/727 [=====>........................] - ETA: 0s - loss: 0.5147 - accuracy: 0.7784\u001b[0m\n",
      "\u001b[34m227/727 [========>.....................] - ETA: 0s - loss: 0.5141 - accuracy: 0.7753\u001b[0m\n",
      "\u001b[34m285/727 [==========>...................] - ETA: 0s - loss: 0.5196 - accuracy: 0.7754\u001b[0m\n",
      "\u001b[34m340/727 [=============>................] - ETA: 0s - loss: 0.5178 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m394/727 [===============>..............] - ETA: 0s - loss: 0.5108 - accuracy: 0.7855\u001b[0m\n",
      "\u001b[34m432/727 [================>.............] - ETA: 0s - loss: 0.5110 - accuracy: 0.7859\u001b[0m\n",
      "\u001b[34m485/727 [===================>..........] - ETA: 0s - loss: 0.5231 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m534/727 [=====================>........] - ETA: 0s - loss: 0.5254 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34m574/727 [======================>.......] - ETA: 0s - loss: 0.5192 - accuracy: 0.7814\u001b[0m\n",
      "\u001b[34m621/727 [========================>.....] - ETA: 0s - loss: 0.5221 - accuracy: 0.7794\u001b[0m\n",
      "\u001b[34m665/727 [==========================>...] - ETA: 0s - loss: 0.5222 - accuracy: 0.7805\u001b[0m\n",
      "\u001b[34m713/727 [============================>.] - ETA: 0s - loss: 0.5259 - accuracy: 0.7770\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 994us/step - loss: 0.5264 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34mEpoch 6/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1904 - accuracy: 1.0000\n",
      " 43/727 [>.............................] - ETA: 0s - loss: 0.5959 - accuracy: 0.7442\n",
      " 82/727 [==>...........................] - ETA: 0s - loss: 0.5595 - accuracy: 0.7683\u001b[0m\n",
      "\u001b[34m126/727 [====>.........................] - ETA: 0s - loss: 0.5528 - accuracy: 0.7659\u001b[0m\n",
      "\u001b[34m162/727 [=====>........................] - ETA: 0s - loss: 0.5296 - accuracy: 0.7809\u001b[0m\n",
      "\u001b[34m203/727 [=======>......................] - ETA: 0s - loss: 0.5353 - accuracy: 0.7759\u001b[0m\n",
      "\u001b[34m255/727 [=========>....................] - ETA: 0s - loss: 0.5260 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m287/727 [==========>...................] - ETA: 0s - loss: 0.5252 - accuracy: 0.7805\u001b[0m\n",
      "\u001b[34m322/727 [============>.................] - ETA: 0s - loss: 0.5276 - accuracy: 0.7795\u001b[0m\n",
      "\u001b[34m367/727 [==============>...............] - ETA: 0s - loss: 0.5286 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m411/727 [===============>..............] - ETA: 0s - loss: 0.5298 - accuracy: 0.7786\u001b[0m\n",
      "\u001b[34m458/727 [=================>............] - ETA: 0s - loss: 0.5232 - accuracy: 0.7838\u001b[0m\n",
      "\u001b[34m504/727 [===================>..........] - ETA: 0s - loss: 0.5187 - accuracy: 0.7857\u001b[0m\n",
      "\u001b[34m562/727 [======================>.......] - ETA: 0s - loss: 0.5213 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m620/727 [========================>.....] - ETA: 0s - loss: 0.5211 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m680/727 [===========================>..] - ETA: 0s - loss: 0.5275 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5269 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 7/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2400 - accuracy: 1.0000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.5072 - accuracy: 0.7931\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.5473 - accuracy: 0.7543\u001b[0m\n",
      "\u001b[34m174/727 [======>.......................] - ETA: 0s - loss: 0.5364 - accuracy: 0.7701\u001b[0m\n",
      "\u001b[34m234/727 [========>.....................] - ETA: 0s - loss: 0.5321 - accuracy: 0.7714\u001b[0m\n",
      "\u001b[34m294/727 [===========>..................] - ETA: 0s - loss: 0.5363 - accuracy: 0.7704\u001b[0m\n",
      "\u001b[34m354/727 [=============>................] - ETA: 0s - loss: 0.5386 - accuracy: 0.7712\u001b[0m\n",
      "\u001b[34m414/727 [================>.............] - ETA: 0s - loss: 0.5353 - accuracy: 0.7705\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.5402 - accuracy: 0.7669\u001b[0m\n",
      "\u001b[34m510/727 [====================>.........] - ETA: 0s - loss: 0.5383 - accuracy: 0.7686\u001b[0m\n",
      "\u001b[34m557/727 [=====================>........] - ETA: 0s - loss: 0.5368 - accuracy: 0.7693\u001b[0m\n",
      "\u001b[34m616/727 [========================>.....] - ETA: 0s - loss: 0.5329 - accuracy: 0.7719\u001b[0m\n",
      "\u001b[34m670/727 [==========================>...] - ETA: 0s - loss: 0.5266 - accuracy: 0.7754\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 905us/step - loss: 0.5283 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 8/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8857 - accuracy: 0.5000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.5095 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m100/727 [===>..........................] - ETA: 0s - loss: 0.5137 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m141/727 [====>.........................] - ETA: 0s - loss: 0.5186 - accuracy: 0.7766\u001b[0m\n",
      "\u001b[34m188/727 [======>.......................] - ETA: 0s - loss: 0.5133 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m225/727 [========>.....................] - ETA: 0s - loss: 0.5007 - accuracy: 0.7867\u001b[0m\n",
      "\u001b[34m258/727 [=========>....................] - ETA: 0s - loss: 0.4975 - accuracy: 0.7907\u001b[0m\n",
      "\u001b[34m283/727 [==========>...................] - ETA: 0s - loss: 0.4984 - accuracy: 0.7933\u001b[0m\n",
      "\u001b[34m313/727 [===========>..................] - ETA: 0s - loss: 0.4921 - accuracy: 0.7939\u001b[0m\n",
      "\u001b[34m339/727 [============>.................] - ETA: 0s - loss: 0.4962 - accuracy: 0.7920\u001b[0m\n",
      "\u001b[34m367/727 [==============>...............] - ETA: 0s - loss: 0.4933 - accuracy: 0.7956\u001b[0m\n",
      "\u001b[34m410/727 [===============>..............] - ETA: 0s - loss: 0.4969 - accuracy: 0.7976\u001b[0m\n",
      "\u001b[34m470/727 [==================>...........] - ETA: 0s - loss: 0.5089 - accuracy: 0.7904\u001b[0m\n",
      "\u001b[34m531/727 [====================>.........] - ETA: 0s - loss: 0.5157 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m571/727 [======================>.......] - ETA: 0s - loss: 0.5176 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m624/727 [========================>.....] - ETA: 0s - loss: 0.5186 - accuracy: 0.7796\u001b[0m\n",
      "\u001b[34m679/727 [===========================>..] - ETA: 0s - loss: 0.5178 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5198 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 9/100\u001b[0m\n",
      "\u001b[34m  1/727 [..............................] - ETA: 0s - loss: 0.7765 - accuracy: 0.5000\n",
      " 46/727 [>.............................] - ETA: 0s - loss: 0.5259 - accuracy: 0.7609\n",
      " 98/727 [===>..........................] - ETA: 0s - loss: 0.5086 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34m143/727 [====>.........................] - ETA: 0s - loss: 0.5226 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m201/727 [=======>......................] - ETA: 0s - loss: 0.5328 - accuracy: 0.7761\u001b[0m\n",
      "\u001b[34m258/727 [=========>....................] - ETA: 0s - loss: 0.5237 - accuracy: 0.7791\u001b[0m\n",
      "\u001b[34m318/727 [============>.................] - ETA: 0s - loss: 0.5103 - accuracy: 0.7877\u001b[0m\n",
      "\u001b[34m365/727 [==============>...............] - ETA: 0s - loss: 0.5145 - accuracy: 0.7849\u001b[0m\n",
      "\u001b[34m423/727 [================>.............] - ETA: 0s - loss: 0.5163 - accuracy: 0.7837\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.5157 - accuracy: 0.7828\u001b[0m\n",
      "\u001b[34m531/727 [====================>.........] - ETA: 0s - loss: 0.5149 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m592/727 [=======================>......] - ETA: 0s - loss: 0.5135 - accuracy: 0.7838\u001b[0m\n",
      "\u001b[34m652/727 [=========================>....] - ETA: 0s - loss: 0.5158 - accuracy: 0.7830\u001b[0m\n",
      "\u001b[34m710/727 [============================>.] - ETA: 0s - loss: 0.5207 - accuracy: 0.7775\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 931us/step - loss: 0.5234 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 10/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 1.1382 - accuracy: 0.5000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.5490 - accuracy: 0.7586\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.5123 - accuracy: 0.7931\u001b[0m\n",
      "\u001b[34m172/727 [======>.......................] - ETA: 0s - loss: 0.5062 - accuracy: 0.7907\u001b[0m\n",
      "\u001b[34m219/727 [========>.....................] - ETA: 0s - loss: 0.5064 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34m270/727 [==========>...................] - ETA: 0s - loss: 0.5095 - accuracy: 0.7852\u001b[0m\n",
      "\u001b[34m322/727 [============>.................] - ETA: 0s - loss: 0.5160 - accuracy: 0.7780\u001b[0m\n",
      "\u001b[34m374/727 [==============>...............] - ETA: 0s - loss: 0.5157 - accuracy: 0.7767\u001b[0m\n",
      "\u001b[34m428/727 [================>.............] - ETA: 0s - loss: 0.5084 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34m483/727 [==================>...........] - ETA: 0s - loss: 0.5054 - accuracy: 0.7878\u001b[0m\n",
      "\u001b[34m524/727 [====================>.........] - ETA: 0s - loss: 0.5098 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m561/727 [======================>.......] - ETA: 0s - loss: 0.5155 - accuracy: 0.7790\u001b[0m\n",
      "\u001b[34m606/727 [========================>.....] - ETA: 0s - loss: 0.5128 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m660/727 [==========================>...] - ETA: 0s - loss: 0.5152 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m703/727 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5173 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34mEpoch 11/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2026 - accuracy: 1.0000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.5117 - accuracy: 0.7759\u001b[0m\n",
      "\u001b[34m115/727 [===>..........................] - ETA: 0s - loss: 0.5323 - accuracy: 0.7696\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 0s - loss: 0.5142 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m224/727 [========>.....................] - ETA: 0s - loss: 0.5110 - accuracy: 0.7768\u001b[0m\n",
      "\u001b[34m283/727 [==========>...................] - ETA: 0s - loss: 0.5043 - accuracy: 0.7809\u001b[0m\n",
      "\u001b[34m338/727 [============>.................] - ETA: 0s - loss: 0.5035 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m398/727 [===============>..............] - ETA: 0s - loss: 0.5024 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m455/727 [=================>............] - ETA: 0s - loss: 0.5065 - accuracy: 0.7857\u001b[0m\n",
      "\u001b[34m513/727 [====================>.........] - ETA: 0s - loss: 0.5107 - accuracy: 0.7836\u001b[0m\n",
      "\u001b[34m572/727 [======================>.......] - ETA: 0s - loss: 0.5170 - accuracy: 0.7780\u001b[0m\n",
      "\u001b[34m623/727 [========================>.....] - ETA: 0s - loss: 0.5155 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m668/727 [==========================>...] - ETA: 0s - loss: 0.5142 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34m715/727 [============================>.] - ETA: 0s - loss: 0.5156 - accuracy: 0.7776\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 921us/step - loss: 0.5152 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 12/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6321 - accuracy: 0.5000\n",
      " 57/727 [=>............................] - ETA: 0s - loss: 0.5446 - accuracy: 0.7456\u001b[0m\n",
      "\u001b[34m111/727 [===>..........................] - ETA: 0s - loss: 0.4847 - accuracy: 0.7928\u001b[0m\n",
      "\u001b[34m163/727 [=====>........................] - ETA: 0s - loss: 0.5035 - accuracy: 0.7822\u001b[0m\n",
      "\u001b[34m211/727 [=======>......................] - ETA: 0s - loss: 0.5021 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m255/727 [=========>....................] - ETA: 0s - loss: 0.5020 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m287/727 [==========>...................] - ETA: 0s - loss: 0.5048 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34m322/727 [============>.................] - ETA: 0s - loss: 0.4927 - accuracy: 0.7919\u001b[0m\n",
      "\u001b[34m376/727 [==============>...............] - ETA: 0s - loss: 0.4930 - accuracy: 0.7926\u001b[0m\n",
      "\u001b[34m422/727 [================>.............] - ETA: 0s - loss: 0.5077 - accuracy: 0.7855\u001b[0m\n",
      "\u001b[34m475/727 [==================>...........] - ETA: 0s - loss: 0.5094 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m517/727 [====================>.........] - ETA: 0s - loss: 0.5097 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34m561/727 [======================>.......] - ETA: 0s - loss: 0.5152 - accuracy: 0.7790\u001b[0m\n",
      "\u001b[34m604/727 [=======================>......] - ETA: 0s - loss: 0.5116 - accuracy: 0.7815\u001b[0m\n",
      "\u001b[34m657/727 [==========================>...] - ETA: 0s - loss: 0.5121 - accuracy: 0.7808\u001b[0m\n",
      "\u001b[34m714/727 [============================>.] - ETA: 0s - loss: 0.5133 - accuracy: 0.7794\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34mEpoch 13/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6683 - accuracy: 0.5000\n",
      " 55/727 [=>............................] - ETA: 0s - loss: 0.5609 - accuracy: 0.7273\u001b[0m\n",
      "\u001b[34m108/727 [===>..........................] - ETA: 0s - loss: 0.5316 - accuracy: 0.7593\u001b[0m\n",
      "\u001b[34m154/727 [=====>........................] - ETA: 0s - loss: 0.5233 - accuracy: 0.7630\u001b[0m\n",
      "\u001b[34m207/727 [=======>......................] - ETA: 0s - loss: 0.5206 - accuracy: 0.7729\u001b[0m\n",
      "\u001b[34m267/727 [==========>...................] - ETA: 0s - loss: 0.5277 - accuracy: 0.7697\u001b[0m\n",
      "\u001b[34m327/727 [============>.................] - ETA: 0s - loss: 0.5330 - accuracy: 0.7661\u001b[0m\n",
      "\u001b[34m387/727 [==============>...............] - ETA: 0s - loss: 0.5248 - accuracy: 0.7752\u001b[0m\n",
      "\u001b[34m440/727 [=================>............] - ETA: 0s - loss: 0.5221 - accuracy: 0.7773\u001b[0m\n",
      "\u001b[34m500/727 [===================>..........] - ETA: 0s - loss: 0.5204 - accuracy: 0.7770\u001b[0m\n",
      "\u001b[34m558/727 [======================>.......] - ETA: 0s - loss: 0.5245 - accuracy: 0.7742\u001b[0m\n",
      "\u001b[34m615/727 [========================>.....] - ETA: 0s - loss: 0.5180 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34m675/727 [==========================>...] - ETA: 0s - loss: 0.5164 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 903us/step - loss: 0.5195 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 14/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2623 - accuracy: 1.0000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.4495 - accuracy: 0.8190\u001b[0m\n",
      "\u001b[34m115/727 [===>..........................] - ETA: 0s - loss: 0.5139 - accuracy: 0.7783\u001b[0m\n",
      "\u001b[34m174/727 [======>.......................] - ETA: 0s - loss: 0.5103 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.5176 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m291/727 [===========>..................] - ETA: 0s - loss: 0.5064 - accuracy: 0.7887\u001b[0m\n",
      "\u001b[34m347/727 [=============>................] - ETA: 0s - loss: 0.5092 - accuracy: 0.7853\u001b[0m\n",
      "\u001b[34m391/727 [===============>..............] - ETA: 0s - loss: 0.5058 - accuracy: 0.7877\u001b[0m\n",
      "\u001b[34m442/727 [=================>............] - ETA: 0s - loss: 0.5076 - accuracy: 0.7873\u001b[0m\n",
      "\u001b[34m500/727 [===================>..........] - ETA: 0s - loss: 0.5141 - accuracy: 0.7830\u001b[0m\n",
      "\u001b[34m557/727 [=====================>........] - ETA: 0s - loss: 0.5154 - accuracy: 0.7810\u001b[0m\n",
      "\u001b[34m616/727 [========================>.....] - ETA: 0s - loss: 0.5151 - accuracy: 0.7800\u001b[0m\n",
      "\u001b[34m674/727 [==========================>...] - ETA: 0s - loss: 0.5149 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 896us/step - loss: 0.5177 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34mEpoch 15/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2678 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4952 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4742 - accuracy: 0.7920\u001b[0m\n",
      "\u001b[34m168/727 [=====>........................] - ETA: 0s - loss: 0.5160 - accuracy: 0.7768\u001b[0m\n",
      "\u001b[34m221/727 [========>.....................] - ETA: 0s - loss: 0.5124 - accuracy: 0.7828\u001b[0m\n",
      "\u001b[34m258/727 [=========>....................] - ETA: 0s - loss: 0.5191 - accuracy: 0.7752\u001b[0m\n",
      "\u001b[34m301/727 [===========>..................] - ETA: 0s - loss: 0.5195 - accuracy: 0.7724\u001b[0m\n",
      "\u001b[34m359/727 [=============>................] - ETA: 0s - loss: 0.5220 - accuracy: 0.7688\u001b[0m\n",
      "\u001b[34m418/727 [================>.............] - ETA: 0s - loss: 0.5209 - accuracy: 0.7691\u001b[0m\n",
      "\u001b[34m471/727 [==================>...........] - ETA: 0s - loss: 0.5111 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m531/727 [====================>.........] - ETA: 0s - loss: 0.5115 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m588/727 [=======================>......] - ETA: 0s - loss: 0.5073 - accuracy: 0.7815\u001b[0m\n",
      "\u001b[34m646/727 [=========================>....] - ETA: 0s - loss: 0.5147 - accuracy: 0.7771\u001b[0m\n",
      "\u001b[34m706/727 [============================>.] - ETA: 0s - loss: 0.5167 - accuracy: 0.7741\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 929us/step - loss: 0.5140 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34mEpoch 16/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.3198 - accuracy: 1.0000\n",
      " 47/727 [>.............................] - ETA: 0s - loss: 0.4487 - accuracy: 0.8191\n",
      " 94/727 [==>...........................] - ETA: 0s - loss: 0.5025 - accuracy: 0.7872\u001b[0m\n",
      "\u001b[34m123/727 [====>.........................] - ETA: 0s - loss: 0.5183 - accuracy: 0.7805\u001b[0m\n",
      "\u001b[34m161/727 [=====>........................] - ETA: 0s - loss: 0.5164 - accuracy: 0.7826\u001b[0m\n",
      "\u001b[34m191/727 [======>.......................] - ETA: 0s - loss: 0.5047 - accuracy: 0.7853\u001b[0m\n",
      "\u001b[34m219/727 [========>.....................] - ETA: 0s - loss: 0.5049 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m246/727 [=========>....................] - ETA: 0s - loss: 0.5045 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m272/727 [==========>...................] - ETA: 0s - loss: 0.5052 - accuracy: 0.7831\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4939 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m338/727 [============>.................] - ETA: 0s - loss: 0.4985 - accuracy: 0.7899\u001b[0m\n",
      "\u001b[34m394/727 [===============>..............] - ETA: 0s - loss: 0.4899 - accuracy: 0.7944\u001b[0m\n",
      "\u001b[34m453/727 [=================>............] - ETA: 0s - loss: 0.4901 - accuracy: 0.7925\u001b[0m\n",
      "\u001b[34m512/727 [====================>.........] - ETA: 0s - loss: 0.4932 - accuracy: 0.7920\u001b[0m\n",
      "\u001b[34m569/727 [======================>.......] - ETA: 0s - loss: 0.4949 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m623/727 [========================>.....] - ETA: 0s - loss: 0.5024 - accuracy: 0.7849\u001b[0m\n",
      "\u001b[34m681/727 [===========================>..] - ETA: 0s - loss: 0.5102 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34mEpoch 17/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6055 - accuracy: 0.5000\n",
      " 54/727 [=>............................] - ETA: 0s - loss: 0.5197 - accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m108/727 [===>..........................] - ETA: 0s - loss: 0.5226 - accuracy: 0.7639\u001b[0m\n",
      "\u001b[34m167/727 [=====>........................] - ETA: 0s - loss: 0.5021 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m225/727 [========>.....................] - ETA: 0s - loss: 0.5010 - accuracy: 0.7867\u001b[0m\n",
      "\u001b[34m284/727 [==========>...................] - ETA: 0s - loss: 0.4929 - accuracy: 0.7887\u001b[0m\n",
      "\u001b[34m343/727 [=============>................] - ETA: 0s - loss: 0.4976 - accuracy: 0.7872\u001b[0m\n",
      "\u001b[34m400/727 [===============>..............] - ETA: 0s - loss: 0.4991 - accuracy: 0.7837\u001b[0m\n",
      "\u001b[34m458/727 [=================>............] - ETA: 0s - loss: 0.5004 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34m517/727 [====================>.........] - ETA: 0s - loss: 0.4982 - accuracy: 0.7814\u001b[0m\n",
      "\u001b[34m576/727 [======================>.......] - ETA: 0s - loss: 0.5023 - accuracy: 0.7795\u001b[0m\n",
      "\u001b[34m634/727 [=========================>....] - ETA: 0s - loss: 0.5031 - accuracy: 0.7815\u001b[0m\n",
      "\u001b[34m690/727 [===========================>..] - ETA: 0s - loss: 0.5115 - accuracy: 0.7732\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 879us/step - loss: 0.5075 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 18/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.4042 - accuracy: 1.0000\n",
      " 48/727 [>.............................] - ETA: 0s - loss: 0.4929 - accuracy: 0.8125\u001b[0m\n",
      "\u001b[34m107/727 [===>..........................] - ETA: 0s - loss: 0.5319 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m167/727 [=====>........................] - ETA: 0s - loss: 0.5278 - accuracy: 0.7784\u001b[0m\n",
      "\u001b[34m223/727 [========>.....................] - ETA: 0s - loss: 0.5081 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m279/727 [==========>...................] - ETA: 0s - loss: 0.5225 - accuracy: 0.7688\u001b[0m\n",
      "\u001b[34m338/727 [============>.................] - ETA: 0s - loss: 0.5205 - accuracy: 0.7766\u001b[0m\n",
      "\u001b[34m398/727 [===============>..............] - ETA: 0s - loss: 0.5082 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m457/727 [=================>............] - ETA: 0s - loss: 0.5010 - accuracy: 0.7888\u001b[0m\n",
      "\u001b[34m517/727 [====================>.........] - ETA: 0s - loss: 0.4985 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m577/727 [======================>.......] - ETA: 0s - loss: 0.4984 - accuracy: 0.7903\u001b[0m\n",
      "\u001b[34m636/727 [=========================>....] - ETA: 0s - loss: 0.5059 - accuracy: 0.7846\u001b[0m\n",
      "\u001b[34m694/727 [===========================>..] - ETA: 0s - loss: 0.5068 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 874us/step - loss: 0.5084 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34mEpoch 19/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8055 - accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m 58/727 [=>............................] - ETA: 0s - loss: 0.5477 - accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.4943 - accuracy: 0.7716\u001b[0m\n",
      "\u001b[34m175/727 [======>.......................] - ETA: 0s - loss: 0.5112 - accuracy: 0.7629\u001b[0m\n",
      "\u001b[34m235/727 [========>.....................] - ETA: 0s - loss: 0.5043 - accuracy: 0.7723\u001b[0m\n",
      "\u001b[34m295/727 [===========>..................] - ETA: 0s - loss: 0.5073 - accuracy: 0.7729\u001b[0m\n",
      "\u001b[34m345/727 [=============>................] - ETA: 0s - loss: 0.5107 - accuracy: 0.7681\u001b[0m\n",
      "\u001b[34m404/727 [===============>..............] - ETA: 0s - loss: 0.5093 - accuracy: 0.7748\u001b[0m\n",
      "\u001b[34m464/727 [==================>...........] - ETA: 0s - loss: 0.5041 - accuracy: 0.7791\u001b[0m\n",
      "\u001b[34m521/727 [====================>.........] - ETA: 0s - loss: 0.5032 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m580/727 [======================>.......] - ETA: 0s - loss: 0.5051 - accuracy: 0.7802\u001b[0m\n",
      "\u001b[34m635/727 [=========================>....] - ETA: 0s - loss: 0.5056 - accuracy: 0.7795\u001b[0m\n",
      "\u001b[34m681/727 [===========================>..] - ETA: 0s - loss: 0.5091 - accuracy: 0.7790\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 889us/step - loss: 0.5103 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 20/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1562 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.5247 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.5177 - accuracy: 0.7881\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4908 - accuracy: 0.8079\u001b[0m\n",
      "\u001b[34m236/727 [========>.....................] - ETA: 0s - loss: 0.4903 - accuracy: 0.8030\u001b[0m\n",
      "\u001b[34m296/727 [===========>..................] - ETA: 0s - loss: 0.4975 - accuracy: 0.7956\u001b[0m\n",
      "\u001b[34m354/727 [=============>................] - ETA: 0s - loss: 0.4970 - accuracy: 0.7924\u001b[0m\n",
      "\u001b[34m413/727 [================>.............] - ETA: 0s - loss: 0.4962 - accuracy: 0.7893\u001b[0m\n",
      "\u001b[34m471/727 [==================>...........] - ETA: 0s - loss: 0.4948 - accuracy: 0.7898\u001b[0m\n",
      "\u001b[34m528/727 [====================>.........] - ETA: 0s - loss: 0.5005 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m585/727 [=======================>......] - ETA: 0s - loss: 0.5001 - accuracy: 0.7846\u001b[0m\n",
      "\u001b[34m642/727 [=========================>....] - ETA: 0s - loss: 0.5002 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m700/727 [===========================>..] - ETA: 0s - loss: 0.5008 - accuracy: 0.7814\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 867us/step - loss: 0.5044 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34mEpoch 21/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7159 - accuracy: 0.5000\n",
      " 55/727 [=>............................] - ETA: 0s - loss: 0.5673 - accuracy: 0.7455\u001b[0m\n",
      "\u001b[34m112/727 [===>..........................] - ETA: 0s - loss: 0.5406 - accuracy: 0.7589\u001b[0m\n",
      "\u001b[34m165/727 [=====>........................] - ETA: 0s - loss: 0.5402 - accuracy: 0.7576\u001b[0m\n",
      "\u001b[34m224/727 [========>.....................] - ETA: 0s - loss: 0.5193 - accuracy: 0.7701\u001b[0m\n",
      "\u001b[34m283/727 [==========>...................] - ETA: 0s - loss: 0.5062 - accuracy: 0.7756\u001b[0m\n",
      "\u001b[34m339/727 [============>.................] - ETA: 0s - loss: 0.5119 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m397/727 [===============>..............] - ETA: 0s - loss: 0.5131 - accuracy: 0.7733\u001b[0m\n",
      "\u001b[34m455/727 [=================>............] - ETA: 0s - loss: 0.5147 - accuracy: 0.7714\u001b[0m\n",
      "\u001b[34m512/727 [====================>.........] - ETA: 0s - loss: 0.5129 - accuracy: 0.7705\u001b[0m\n",
      "\u001b[34m570/727 [======================>.......] - ETA: 0s - loss: 0.5084 - accuracy: 0.7763\u001b[0m\n",
      "\u001b[34m625/727 [========================>.....] - ETA: 0s - loss: 0.5095 - accuracy: 0.7760\u001b[0m\n",
      "\u001b[34m679/727 [===========================>..] - ETA: 0s - loss: 0.5099 - accuracy: 0.7761\u001b[0m\n",
      "\u001b[34m715/727 [============================>.] - ETA: 0s - loss: 0.5109 - accuracy: 0.7762\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 928us/step - loss: 0.5091 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 22/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1513 - accuracy: 1.0000\n",
      " 34/727 [>.............................] - ETA: 1s - loss: 0.4498 - accuracy: 0.8088\u001b[0m\n",
      "\u001b[34m 86/727 [==>...........................] - ETA: 0s - loss: 0.4937 - accuracy: 0.7791\u001b[0m\n",
      "\u001b[34m143/727 [====>.........................] - ETA: 0s - loss: 0.5004 - accuracy: 0.7762\u001b[0m\n",
      "\u001b[34m200/727 [=======>......................] - ETA: 0s - loss: 0.5154 - accuracy: 0.7700\u001b[0m\n",
      "\u001b[34m259/727 [=========>....................] - ETA: 0s - loss: 0.5203 - accuracy: 0.7606\u001b[0m\n",
      "\u001b[34m315/727 [===========>..................] - ETA: 0s - loss: 0.5133 - accuracy: 0.7635\u001b[0m\n",
      "\u001b[34m374/727 [==============>...............] - ETA: 0s - loss: 0.5125 - accuracy: 0.7674\u001b[0m\n",
      "\u001b[34m429/727 [================>.............] - ETA: 0s - loss: 0.5184 - accuracy: 0.7634\u001b[0m\n",
      "\u001b[34m489/727 [===================>..........] - ETA: 0s - loss: 0.5123 - accuracy: 0.7658\u001b[0m\n",
      "\u001b[34m545/727 [=====================>........] - ETA: 0s - loss: 0.5103 - accuracy: 0.7679\u001b[0m\n",
      "\u001b[34m600/727 [=======================>......] - ETA: 0s - loss: 0.5094 - accuracy: 0.7692\u001b[0m\n",
      "\u001b[34m659/727 [==========================>...] - ETA: 0s - loss: 0.5063 - accuracy: 0.7724\u001b[0m\n",
      "\u001b[34m717/727 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.7775\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 920us/step - loss: 0.5008 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 23/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8410 - accuracy: 0.5000\n",
      " 55/727 [=>............................] - ETA: 0s - loss: 0.5465 - accuracy: 0.7364\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.5158 - accuracy: 0.7434\u001b[0m\n",
      "\u001b[34m172/727 [======>.......................] - ETA: 0s - loss: 0.4896 - accuracy: 0.7733\u001b[0m\n",
      "\u001b[34m231/727 [========>.....................] - ETA: 0s - loss: 0.4837 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m288/727 [==========>...................] - ETA: 0s - loss: 0.4936 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m347/727 [=============>................] - ETA: 0s - loss: 0.4926 - accuracy: 0.7767\u001b[0m\n",
      "\u001b[34m403/727 [===============>..............] - ETA: 0s - loss: 0.4842 - accuracy: 0.7841\u001b[0m\n",
      "\u001b[34m462/727 [==================>...........] - ETA: 0s - loss: 0.4870 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m520/727 [====================>.........] - ETA: 0s - loss: 0.4836 - accuracy: 0.7856\u001b[0m\n",
      "\u001b[34m577/727 [======================>.......] - ETA: 0s - loss: 0.4850 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m636/727 [=========================>....] - ETA: 0s - loss: 0.4819 - accuracy: 0.7862\u001b[0m\n",
      "\u001b[34m688/727 [===========================>..] - ETA: 0s - loss: 0.4927 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 879us/step - loss: 0.4959 - accuracy: 0.7779\u001b[0m\n",
      "\u001b[34mEpoch 24/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2995 - accuracy: 1.0000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.4687 - accuracy: 0.8136\u001b[0m\n",
      "\u001b[34m101/727 [===>..........................] - ETA: 0s - loss: 0.4534 - accuracy: 0.8267\u001b[0m\n",
      "\u001b[34m156/727 [=====>........................] - ETA: 0s - loss: 0.4722 - accuracy: 0.8269\u001b[0m\n",
      "\u001b[34m207/727 [=======>......................] - ETA: 0s - loss: 0.4756 - accuracy: 0.8164\u001b[0m\n",
      "\u001b[34m265/727 [=========>....................] - ETA: 0s - loss: 0.4856 - accuracy: 0.8000\u001b[0m\n",
      "\u001b[34m323/727 [============>.................] - ETA: 0s - loss: 0.4902 - accuracy: 0.7972\u001b[0m\n",
      "\u001b[34m379/727 [==============>...............] - ETA: 0s - loss: 0.4906 - accuracy: 0.7955\u001b[0m\n",
      "\u001b[34m437/727 [=================>............] - ETA: 0s - loss: 0.4938 - accuracy: 0.7906\u001b[0m\n",
      "\u001b[34m494/727 [===================>..........] - ETA: 0s - loss: 0.4985 - accuracy: 0.7864\u001b[0m\n",
      "\u001b[34m540/727 [=====================>........] - ETA: 0s - loss: 0.5009 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m598/727 [=======================>......] - ETA: 0s - loss: 0.4959 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34m655/727 [==========================>...] - ETA: 0s - loss: 0.4984 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m713/727 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 920us/step - loss: 0.5024 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 25/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1245 - accuracy: 1.0000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.5046 - accuracy: 0.8051\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.5254 - accuracy: 0.7669\u001b[0m\n",
      "\u001b[34m175/727 [======>.......................] - ETA: 0s - loss: 0.5068 - accuracy: 0.7800\u001b[0m\n",
      "\u001b[34m231/727 [========>.....................] - ETA: 0s - loss: 0.4946 - accuracy: 0.7857\u001b[0m\n",
      "\u001b[34m288/727 [==========>...................] - ETA: 0s - loss: 0.4904 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m345/727 [=============>................] - ETA: 0s - loss: 0.4922 - accuracy: 0.7841\u001b[0m\n",
      "\u001b[34m401/727 [===============>..............] - ETA: 0s - loss: 0.4983 - accuracy: 0.7805\u001b[0m\n",
      "\u001b[34m454/727 [=================>............] - ETA: 0s - loss: 0.5007 - accuracy: 0.7786\u001b[0m\n",
      "\u001b[34m508/727 [===================>..........] - ETA: 0s - loss: 0.5011 - accuracy: 0.7766\u001b[0m\n",
      "\u001b[34m544/727 [=====================>........] - ETA: 0s - loss: 0.5003 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m601/727 [=======================>......] - ETA: 0s - loss: 0.4955 - accuracy: 0.7829\u001b[0m\n",
      "\u001b[34m660/727 [==========================>...] - ETA: 0s - loss: 0.5000 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m718/727 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 915us/step - loss: 0.5005 - accuracy: 0.7813\u001b[0m\n",
      "\u001b[34mEpoch 26/100\n",
      "  1/727 [..............................] - ETA: 2s - loss: 0.3660 - accuracy: 1.0000\n",
      " 57/727 [=>............................] - ETA: 0s - loss: 0.5358 - accuracy: 0.7632\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.5465 - accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m169/727 [=====>........................] - ETA: 0s - loss: 0.5356 - accuracy: 0.7574\u001b[0m\n",
      "\u001b[34m222/727 [========>.....................] - ETA: 0s - loss: 0.5278 - accuracy: 0.7658\u001b[0m\n",
      "\u001b[34m277/727 [==========>...................] - ETA: 0s - loss: 0.5091 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34m331/727 [============>.................] - ETA: 0s - loss: 0.5144 - accuracy: 0.7810\u001b[0m\n",
      "\u001b[34m389/727 [===============>..............] - ETA: 0s - loss: 0.5166 - accuracy: 0.7763\u001b[0m\n",
      "\u001b[34m448/727 [=================>............] - ETA: 0s - loss: 0.5115 - accuracy: 0.7768\u001b[0m\n",
      "\u001b[34m504/727 [===================>..........] - ETA: 0s - loss: 0.5110 - accuracy: 0.7758\u001b[0m\n",
      "\u001b[34m561/727 [======================>.......] - ETA: 0s - loss: 0.5044 - accuracy: 0.7807\u001b[0m\n",
      "\u001b[34m620/727 [========================>.....] - ETA: 0s - loss: 0.5095 - accuracy: 0.7774\u001b[0m\n",
      "\u001b[34m680/727 [===========================>..] - ETA: 0s - loss: 0.5055 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 893us/step - loss: 0.5033 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 27/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.7611 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.5256 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.4840 - accuracy: 0.7895\u001b[0m\n",
      "\u001b[34m173/727 [======>.......................] - ETA: 0s - loss: 0.4875 - accuracy: 0.7948\u001b[0m\n",
      "\u001b[34m232/727 [========>.....................] - ETA: 0s - loss: 0.4768 - accuracy: 0.8017\u001b[0m\n",
      "\u001b[34m290/727 [==========>...................] - ETA: 0s - loss: 0.4852 - accuracy: 0.7948\u001b[0m\n",
      "\u001b[34m348/727 [=============>................] - ETA: 0s - loss: 0.4866 - accuracy: 0.7902\u001b[0m\n",
      "\u001b[34m403/727 [===============>..............] - ETA: 0s - loss: 0.4890 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m457/727 [=================>............] - ETA: 0s - loss: 0.4852 - accuracy: 0.7823\u001b[0m\n",
      "\u001b[34m516/727 [====================>.........] - ETA: 0s - loss: 0.4874 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m573/727 [======================>.......] - ETA: 0s - loss: 0.4915 - accuracy: 0.7775\u001b[0m\n",
      "\u001b[34m630/727 [========================>.....] - ETA: 0s - loss: 0.4961 - accuracy: 0.7746\u001b[0m\n",
      "\u001b[34m687/727 [===========================>..] - ETA: 0s - loss: 0.5012 - accuracy: 0.7737\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 885us/step - loss: 0.4973 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34mEpoch 28/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.9333 - accuracy: 0.5000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.4680 - accuracy: 0.8276\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.4894 - accuracy: 0.8070\u001b[0m\n",
      "\u001b[34m168/727 [=====>........................] - ETA: 0s - loss: 0.4834 - accuracy: 0.7976\u001b[0m\n",
      "\u001b[34m225/727 [========>.....................] - ETA: 0s - loss: 0.4878 - accuracy: 0.7911\u001b[0m\n",
      "\u001b[34m281/727 [==========>...................] - ETA: 0s - loss: 0.4976 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m340/727 [=============>................] - ETA: 0s - loss: 0.5032 - accuracy: 0.7794\u001b[0m\n",
      "\u001b[34m397/727 [===============>..............] - ETA: 0s - loss: 0.5104 - accuracy: 0.7746\u001b[0m\n",
      "\u001b[34m455/727 [=================>............] - ETA: 0s - loss: 0.5092 - accuracy: 0.7769\u001b[0m\n",
      "\u001b[34m514/727 [====================>.........] - ETA: 0s - loss: 0.5135 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m568/727 [======================>.......] - ETA: 0s - loss: 0.5020 - accuracy: 0.7826\u001b[0m\n",
      "\u001b[34m627/727 [========================>.....] - ETA: 0s - loss: 0.5041 - accuracy: 0.7807\u001b[0m\n",
      "\u001b[34m686/727 [===========================>..] - ETA: 0s - loss: 0.5029 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 884us/step - loss: 0.5051 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34mEpoch 29/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 1.1039 - accuracy: 0.5000\n",
      " 54/727 [=>............................] - ETA: 0s - loss: 0.5262 - accuracy: 0.7407\u001b[0m\n",
      "\u001b[34m111/727 [===>..........................] - ETA: 0s - loss: 0.4865 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m171/727 [======>.......................] - ETA: 0s - loss: 0.4894 - accuracy: 0.7749\u001b[0m\n",
      "\u001b[34m230/727 [========>.....................] - ETA: 0s - loss: 0.4922 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m290/727 [==========>...................] - ETA: 0s - loss: 0.5169 - accuracy: 0.7707\u001b[0m\n",
      "\u001b[34m349/727 [=============>................] - ETA: 0s - loss: 0.5149 - accuracy: 0.7650\u001b[0m\n",
      "\u001b[34m408/727 [===============>..............] - ETA: 0s - loss: 0.5120 - accuracy: 0.7696\u001b[0m\n",
      "\u001b[34m464/727 [==================>...........] - ETA: 0s - loss: 0.5049 - accuracy: 0.7748\u001b[0m\n",
      "\u001b[34m519/727 [====================>.........] - ETA: 0s - loss: 0.5043 - accuracy: 0.7755\u001b[0m\n",
      "\u001b[34m574/727 [======================>.......] - ETA: 0s - loss: 0.5059 - accuracy: 0.7726\u001b[0m\n",
      "\u001b[34m624/727 [========================>.....] - ETA: 0s - loss: 0.5022 - accuracy: 0.7748\u001b[0m\n",
      "\u001b[34m677/727 [==========================>...] - ETA: 0s - loss: 0.4994 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 902us/step - loss: 0.4991 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34mEpoch 30/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2034 - accuracy: 1.0000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.4740 - accuracy: 0.8190\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.4991 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m174/727 [======>.......................] - ETA: 0s - loss: 0.4853 - accuracy: 0.8046\u001b[0m\n",
      "\u001b[34m226/727 [========>.....................] - ETA: 0s - loss: 0.5003 - accuracy: 0.7942\u001b[0m\n",
      "\u001b[34m285/727 [==========>...................] - ETA: 0s - loss: 0.4870 - accuracy: 0.7982\u001b[0m\n",
      "\u001b[34m345/727 [=============>................] - ETA: 0s - loss: 0.4853 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m404/727 [===============>..............] - ETA: 0s - loss: 0.4879 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34m463/727 [==================>...........] - ETA: 0s - loss: 0.4963 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m522/727 [====================>.........] - ETA: 0s - loss: 0.4995 - accuracy: 0.7749\u001b[0m\n",
      "\u001b[34m582/727 [=======================>......] - ETA: 0s - loss: 0.4944 - accuracy: 0.7784\u001b[0m\n",
      "\u001b[34m641/727 [=========================>....] - ETA: 0s - loss: 0.5007 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m698/727 [===========================>..] - ETA: 0s - loss: 0.5033 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 868us/step - loss: 0.5022 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34mEpoch 31/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1204 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4007 - accuracy: 0.8333\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.4428 - accuracy: 0.8178\u001b[0m\n",
      "\u001b[34m175/727 [======>.......................] - ETA: 0s - loss: 0.4693 - accuracy: 0.7971\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.4791 - accuracy: 0.7918\u001b[0m\n",
      "\u001b[34m292/727 [===========>..................] - ETA: 0s - loss: 0.4827 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m351/727 [=============>................] - ETA: 0s - loss: 0.4942 - accuracy: 0.7764\u001b[0m\n",
      "\u001b[34m410/727 [===============>..............] - ETA: 0s - loss: 0.4925 - accuracy: 0.7744\u001b[0m\n",
      "\u001b[34m468/727 [==================>...........] - ETA: 0s - loss: 0.4899 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m527/727 [====================>.........] - ETA: 0s - loss: 0.4921 - accuracy: 0.7780\u001b[0m\n",
      "\u001b[34m586/727 [=======================>......] - ETA: 0s - loss: 0.4899 - accuracy: 0.7739\u001b[0m\n",
      "\u001b[34m640/727 [=========================>....] - ETA: 0s - loss: 0.4903 - accuracy: 0.7758\u001b[0m\n",
      "\u001b[34m700/727 [===========================>..] - ETA: 0s - loss: 0.4923 - accuracy: 0.7771\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 865us/step - loss: 0.4929 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 32/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3509 - accuracy: 1.0000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.5585 - accuracy: 0.7054\u001b[0m\n",
      "\u001b[34m115/727 [===>..........................] - ETA: 0s - loss: 0.5000 - accuracy: 0.7783\u001b[0m\n",
      "\u001b[34m174/727 [======>.......................] - ETA: 0s - loss: 0.4924 - accuracy: 0.7759\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.4744 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34m293/727 [===========>..................] - ETA: 0s - loss: 0.4778 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34m352/727 [=============>................] - ETA: 0s - loss: 0.4829 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m411/727 [===============>..............] - ETA: 0s - loss: 0.4907 - accuracy: 0.7749\u001b[0m\n",
      "\u001b[34m470/727 [==================>...........] - ETA: 0s - loss: 0.4963 - accuracy: 0.7723\u001b[0m\n",
      "\u001b[34m529/727 [====================>.........] - ETA: 0s - loss: 0.4963 - accuracy: 0.7760\u001b[0m\n",
      "\u001b[34m588/727 [=======================>......] - ETA: 0s - loss: 0.4966 - accuracy: 0.7738\u001b[0m\n",
      "\u001b[34m646/727 [=========================>....] - ETA: 0s - loss: 0.4953 - accuracy: 0.7755\u001b[0m\n",
      "\u001b[34m704/727 [============================>.] - ETA: 0s - loss: 0.4950 - accuracy: 0.7770\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 862us/step - loss: 0.4977 - accuracy: 0.7751\u001b[0m\n",
      "\u001b[34mEpoch 33/100\u001b[0m\n",
      "\u001b[34m  1/727 [..............................] - ETA: 0s - loss: 0.2159 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4901 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m119/727 [===>..........................] - ETA: 0s - loss: 0.5084 - accuracy: 0.7689\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.5108 - accuracy: 0.7682\u001b[0m\n",
      "\u001b[34m238/727 [========>.....................] - ETA: 0s - loss: 0.4969 - accuracy: 0.7794\u001b[0m\n",
      "\u001b[34m297/727 [===========>..................] - ETA: 0s - loss: 0.4967 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m351/727 [=============>................] - ETA: 0s - loss: 0.4936 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m403/727 [===============>..............] - ETA: 0s - loss: 0.4983 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m451/727 [=================>............] - ETA: 0s - loss: 0.4945 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34m510/727 [====================>.........] - ETA: 0s - loss: 0.4905 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m570/727 [======================>.......] - ETA: 0s - loss: 0.4934 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m627/727 [========================>.....] - ETA: 0s - loss: 0.4964 - accuracy: 0.7807\u001b[0m\n",
      "\u001b[34m686/727 [===========================>..] - ETA: 0s - loss: 0.4960 - accuracy: 0.7813\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 884us/step - loss: 0.5005 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34mEpoch 34/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8133 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4884 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4706 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.4820 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m240/727 [========>.....................] - ETA: 0s - loss: 0.4833 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34m298/727 [===========>..................] - ETA: 0s - loss: 0.4868 - accuracy: 0.7903\u001b[0m\n",
      "\u001b[34m357/727 [=============>................] - ETA: 0s - loss: 0.4839 - accuracy: 0.7885\u001b[0m\n",
      "\u001b[34m414/727 [================>.............] - ETA: 0s - loss: 0.4797 - accuracy: 0.7923\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.4794 - accuracy: 0.7903\u001b[0m\n",
      "\u001b[34m531/727 [====================>.........] - ETA: 0s - loss: 0.4815 - accuracy: 0.7938\u001b[0m\n",
      "\u001b[34m580/727 [======================>.......] - ETA: 0s - loss: 0.4803 - accuracy: 0.7914\u001b[0m\n",
      "\u001b[34m626/727 [========================>.....] - ETA: 0s - loss: 0.4883 - accuracy: 0.7851\u001b[0m\n",
      "\u001b[34m659/727 [==========================>...] - ETA: 0s - loss: 0.4917 - accuracy: 0.7822\u001b[0m\n",
      "\u001b[34m693/727 [===========================>..] - ETA: 0s - loss: 0.4923 - accuracy: 0.7814\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 976us/step - loss: 0.4938 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 35/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.6258 - accuracy: 0.5000\n",
      " 36/727 [>.............................] - ETA: 0s - loss: 0.4648 - accuracy: 0.8056\n",
      " 72/727 [=>............................] - ETA: 0s - loss: 0.4804 - accuracy: 0.7778\u001b[0m\n",
      "\u001b[34m106/727 [===>..........................] - ETA: 0s - loss: 0.4833 - accuracy: 0.7689\u001b[0m\n",
      "\u001b[34m137/727 [====>.........................] - ETA: 0s - loss: 0.4865 - accuracy: 0.7701\u001b[0m\n",
      "\u001b[34m168/727 [=====>........................] - ETA: 0s - loss: 0.4994 - accuracy: 0.7679\u001b[0m\n",
      "\u001b[34m207/727 [=======>......................] - ETA: 0s - loss: 0.4867 - accuracy: 0.7778\u001b[0m\n",
      "\u001b[34m266/727 [=========>....................] - ETA: 0s - loss: 0.4992 - accuracy: 0.7744\u001b[0m\n",
      "\u001b[34m326/727 [============>.................] - ETA: 0s - loss: 0.4877 - accuracy: 0.7837\u001b[0m\n",
      "\u001b[34m386/727 [==============>...............] - ETA: 0s - loss: 0.4915 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m446/727 [=================>............] - ETA: 0s - loss: 0.4822 - accuracy: 0.7870\u001b[0m\n",
      "\u001b[34m505/727 [===================>..........] - ETA: 0s - loss: 0.4842 - accuracy: 0.7851\u001b[0m\n",
      "\u001b[34m564/727 [======================>.......] - ETA: 0s - loss: 0.4875 - accuracy: 0.7819\u001b[0m\n",
      "\u001b[34m624/727 [========================>.....] - ETA: 0s - loss: 0.4900 - accuracy: 0.7796\u001b[0m\n",
      "\u001b[34m683/727 [===========================>..] - ETA: 0s - loss: 0.4877 - accuracy: 0.7789\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.4893 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34mEpoch 36/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1812 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4271 - accuracy: 0.8250\u001b[0m\n",
      "\u001b[34m105/727 [===>..........................] - ETA: 0s - loss: 0.4221 - accuracy: 0.8381\u001b[0m\n",
      "\u001b[34m148/727 [=====>........................] - ETA: 0s - loss: 0.4497 - accuracy: 0.8108\u001b[0m\n",
      "\u001b[34m208/727 [=======>......................] - ETA: 0s - loss: 0.4597 - accuracy: 0.8077\u001b[0m\n",
      "\u001b[34m261/727 [=========>....................] - ETA: 0s - loss: 0.4781 - accuracy: 0.7989\u001b[0m\n",
      "\u001b[34m321/727 [============>.................] - ETA: 0s - loss: 0.4812 - accuracy: 0.7928\u001b[0m\n",
      "\u001b[34m381/727 [==============>...............] - ETA: 0s - loss: 0.4759 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m441/727 [=================>............] - ETA: 0s - loss: 0.4755 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34m497/727 [===================>..........] - ETA: 0s - loss: 0.4698 - accuracy: 0.7948\u001b[0m\n",
      "\u001b[34m556/727 [=====================>........] - ETA: 0s - loss: 0.4853 - accuracy: 0.7896\u001b[0m\n",
      "\u001b[34m617/727 [========================>.....] - ETA: 0s - loss: 0.4854 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m676/727 [==========================>...] - ETA: 0s - loss: 0.4903 - accuracy: 0.7862\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 893us/step - loss: 0.4962 - accuracy: 0.7813\u001b[0m\n",
      "\u001b[34mEpoch 37/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7769 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4907 - accuracy: 0.7417\u001b[0m\n",
      "\u001b[34m119/727 [===>..........................] - ETA: 0s - loss: 0.5171 - accuracy: 0.7479\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4990 - accuracy: 0.7627\u001b[0m\n",
      "\u001b[34m237/727 [========>.....................] - ETA: 0s - loss: 0.5110 - accuracy: 0.7616\u001b[0m\n",
      "\u001b[34m297/727 [===========>..................] - ETA: 0s - loss: 0.5104 - accuracy: 0.7660\u001b[0m\n",
      "\u001b[34m356/727 [=============>................] - ETA: 0s - loss: 0.5045 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m416/727 [================>.............] - ETA: 0s - loss: 0.5065 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m474/727 [==================>...........] - ETA: 0s - loss: 0.5063 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m529/727 [====================>.........] - ETA: 0s - loss: 0.5051 - accuracy: 0.7817\u001b[0m\n",
      "\u001b[34m565/727 [======================>.......] - ETA: 0s - loss: 0.5045 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m605/727 [=======================>......] - ETA: 0s - loss: 0.5010 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m645/727 [=========================>....] - ETA: 0s - loss: 0.4995 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34m681/727 [===========================>..] - ETA: 0s - loss: 0.5011 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34m714/727 [============================>.] - ETA: 0s - loss: 0.5027 - accuracy: 0.7815\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.5027 - accuracy: 0.7813\u001b[0m\n",
      "\u001b[34mEpoch 38/100\n",
      "  1/727 [..............................] - ETA: 2s - loss: 0.7066 - accuracy: 0.5000\n",
      " 33/727 [>.............................] - ETA: 1s - loss: 0.4653 - accuracy: 0.8030\n",
      " 67/727 [=>............................] - ETA: 1s - loss: 0.4481 - accuracy: 0.8134\n",
      " 98/727 [===>..........................] - ETA: 1s - loss: 0.4910 - accuracy: 0.7959\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 1s - loss: 0.4807 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m139/727 [====>.........................] - ETA: 1s - loss: 0.4801 - accuracy: 0.7878\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 1s - loss: 0.4989 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m210/727 [=======>......................] - ETA: 0s - loss: 0.4918 - accuracy: 0.7810\u001b[0m\n",
      "\u001b[34m249/727 [=========>....................] - ETA: 0s - loss: 0.4778 - accuracy: 0.7932\u001b[0m\n",
      "\u001b[34m287/727 [==========>...................] - ETA: 0s - loss: 0.4844 - accuracy: 0.7909\u001b[0m\n",
      "\u001b[34m321/727 [============>.................] - ETA: 0s - loss: 0.4870 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4923 - accuracy: 0.7807\u001b[0m\n",
      "\u001b[34m395/727 [===============>..............] - ETA: 0s - loss: 0.4916 - accuracy: 0.7810\u001b[0m\n",
      "\u001b[34m434/727 [================>.............] - ETA: 0s - loss: 0.4878 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34m471/727 [==================>...........] - ETA: 0s - loss: 0.4896 - accuracy: 0.7803\u001b[0m\n",
      "\u001b[34m509/727 [====================>.........] - ETA: 0s - loss: 0.4853 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m545/727 [=====================>........] - ETA: 0s - loss: 0.4916 - accuracy: 0.7780\u001b[0m\n",
      "\u001b[34m593/727 [=======================>......] - ETA: 0s - loss: 0.4938 - accuracy: 0.7774\u001b[0m\n",
      "\u001b[34m642/727 [=========================>....] - ETA: 0s - loss: 0.4941 - accuracy: 0.7741\u001b[0m\n",
      "\u001b[34m700/727 [===========================>..] - ETA: 0s - loss: 0.4950 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.4900 - accuracy: 0.7779\u001b[0m\n",
      "\u001b[34mEpoch 39/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3903 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4504 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m117/727 [===>..........................] - ETA: 0s - loss: 0.4431 - accuracy: 0.7991\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4495 - accuracy: 0.7966\u001b[0m\n",
      "\u001b[34m235/727 [========>.....................] - ETA: 0s - loss: 0.4552 - accuracy: 0.7957\u001b[0m\n",
      "\u001b[34m294/727 [===========>..................] - ETA: 0s - loss: 0.4619 - accuracy: 0.7891\u001b[0m\n",
      "\u001b[34m353/727 [=============>................] - ETA: 0s - loss: 0.4665 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m413/727 [================>.............] - ETA: 0s - loss: 0.4681 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m471/727 [==================>...........] - ETA: 0s - loss: 0.4625 - accuracy: 0.7930\u001b[0m\n",
      "\u001b[34m531/727 [====================>.........] - ETA: 0s - loss: 0.4801 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m589/727 [=======================>......] - ETA: 0s - loss: 0.4825 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m646/727 [=========================>....] - ETA: 0s - loss: 0.4822 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m706/727 [============================>.] - ETA: 0s - loss: 0.4850 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 860us/step - loss: 0.4866 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34mEpoch 40/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2465 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4477 - accuracy: 0.8197\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4935 - accuracy: 0.7708\u001b[0m\n",
      "\u001b[34m165/727 [=====>........................] - ETA: 0s - loss: 0.4850 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m218/727 [=======>......................] - ETA: 0s - loss: 0.4872 - accuracy: 0.7661\u001b[0m\n",
      "\u001b[34m270/727 [==========>...................] - ETA: 0s - loss: 0.4934 - accuracy: 0.7667\u001b[0m\n",
      "\u001b[34m325/727 [============>.................] - ETA: 0s - loss: 0.4909 - accuracy: 0.7738\u001b[0m\n",
      "\u001b[34m384/727 [==============>...............] - ETA: 0s - loss: 0.4946 - accuracy: 0.7708\u001b[0m\n",
      "\u001b[34m443/727 [=================>............] - ETA: 0s - loss: 0.4889 - accuracy: 0.7731\u001b[0m\n",
      "\u001b[34m493/727 [===================>..........] - ETA: 0s - loss: 0.4851 - accuracy: 0.7708\u001b[0m\n",
      "\u001b[34m546/727 [=====================>........] - ETA: 0s - loss: 0.4906 - accuracy: 0.7711\u001b[0m\n",
      "\u001b[34m605/727 [=======================>......] - ETA: 0s - loss: 0.4890 - accuracy: 0.7760\u001b[0m\n",
      "\u001b[34m665/727 [==========================>...] - ETA: 0s - loss: 0.4859 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m720/727 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 912us/step - loss: 0.4851 - accuracy: 0.7813\u001b[0m\n",
      "\u001b[34mEpoch 41/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7691 - accuracy: 0.5000\n",
      " 33/727 [>.............................] - ETA: 1s - loss: 0.4533 - accuracy: 0.7879\n",
      " 70/727 [=>............................] - ETA: 0s - loss: 0.5286 - accuracy: 0.7286\u001b[0m\n",
      "\u001b[34m127/727 [====>.........................] - ETA: 0s - loss: 0.5087 - accuracy: 0.7520\u001b[0m\n",
      "\u001b[34m185/727 [======>.......................] - ETA: 0s - loss: 0.4823 - accuracy: 0.7649\u001b[0m\n",
      "\u001b[34m243/727 [=========>....................] - ETA: 0s - loss: 0.4799 - accuracy: 0.7675\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4734 - accuracy: 0.7767\u001b[0m\n",
      "\u001b[34m359/727 [=============>................] - ETA: 0s - loss: 0.4903 - accuracy: 0.7660\u001b[0m\n",
      "\u001b[34m419/727 [================>.............] - ETA: 0s - loss: 0.4919 - accuracy: 0.7673\u001b[0m\n",
      "\u001b[34m474/727 [==================>...........] - ETA: 0s - loss: 0.4852 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m524/727 [====================>.........] - ETA: 0s - loss: 0.4804 - accuracy: 0.7786\u001b[0m\n",
      "\u001b[34m583/727 [=======================>......] - ETA: 0s - loss: 0.4819 - accuracy: 0.7779\u001b[0m\n",
      "\u001b[34m641/727 [=========================>....] - ETA: 0s - loss: 0.4885 - accuracy: 0.7746\u001b[0m\n",
      "\u001b[34m696/727 [===========================>..] - ETA: 0s - loss: 0.4899 - accuracy: 0.7744\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 947us/step - loss: 0.4875 - accuracy: 0.7779\u001b[0m\n",
      "\u001b[34mEpoch 42/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.8211 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4358 - accuracy: 0.8279\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.4363 - accuracy: 0.8276\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 0s - loss: 0.4436 - accuracy: 0.8176\u001b[0m\n",
      "\u001b[34m229/727 [========>.....................] - ETA: 0s - loss: 0.4515 - accuracy: 0.8057\u001b[0m\n",
      "\u001b[34m287/727 [==========>...................] - ETA: 0s - loss: 0.4625 - accuracy: 0.7944\u001b[0m\n",
      "\u001b[34m346/727 [=============>................] - ETA: 0s - loss: 0.4891 - accuracy: 0.7775\u001b[0m\n",
      "\u001b[34m403/727 [===============>..............] - ETA: 0s - loss: 0.4915 - accuracy: 0.7717\u001b[0m\n",
      "\u001b[34m458/727 [=================>............] - ETA: 0s - loss: 0.4887 - accuracy: 0.7729\u001b[0m\n",
      "\u001b[34m517/727 [====================>.........] - ETA: 0s - loss: 0.4890 - accuracy: 0.7737\u001b[0m\n",
      "\u001b[34m576/727 [======================>.......] - ETA: 0s - loss: 0.4869 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m634/727 [=========================>....] - ETA: 0s - loss: 0.4826 - accuracy: 0.7737\u001b[0m\n",
      "\u001b[34m684/727 [===========================>..] - ETA: 0s - loss: 0.4791 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 894us/step - loss: 0.4808 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34mEpoch 43/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6824 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4493 - accuracy: 0.8083\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4972 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.4800 - accuracy: 0.7889\u001b[0m\n",
      "\u001b[34m238/727 [========>.....................] - ETA: 0s - loss: 0.4907 - accuracy: 0.7773\u001b[0m\n",
      "\u001b[34m296/727 [===========>..................] - ETA: 0s - loss: 0.4825 - accuracy: 0.7905\u001b[0m\n",
      "\u001b[34m348/727 [=============>................] - ETA: 0s - loss: 0.4719 - accuracy: 0.7989\u001b[0m\n",
      "\u001b[34m407/727 [===============>..............] - ETA: 0s - loss: 0.4814 - accuracy: 0.7948\u001b[0m\n",
      "\u001b[34m463/727 [==================>...........] - ETA: 0s - loss: 0.4818 - accuracy: 0.7927\u001b[0m\n",
      "\u001b[34m518/727 [====================>.........] - ETA: 0s - loss: 0.4824 - accuracy: 0.7896\u001b[0m\n",
      "\u001b[34m574/727 [======================>.......] - ETA: 0s - loss: 0.4807 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m633/727 [=========================>....] - ETA: 0s - loss: 0.4852 - accuracy: 0.7852\u001b[0m\n",
      "\u001b[34m693/727 [===========================>..] - ETA: 0s - loss: 0.4886 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 876us/step - loss: 0.4901 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34mEpoch 44/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2558 - accuracy: 1.0000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.4435 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.4446 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m176/727 [======>.......................] - ETA: 0s - loss: 0.4734 - accuracy: 0.7756\u001b[0m\n",
      "\u001b[34m235/727 [========>.....................] - ETA: 0s - loss: 0.4775 - accuracy: 0.7745\u001b[0m\n",
      "\u001b[34m294/727 [===========>..................] - ETA: 0s - loss: 0.4894 - accuracy: 0.7670\u001b[0m\n",
      "\u001b[34m352/727 [=============>................] - ETA: 0s - loss: 0.4956 - accuracy: 0.7656\u001b[0m\n",
      "\u001b[34m412/727 [================>.............] - ETA: 0s - loss: 0.4857 - accuracy: 0.7755\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.4783 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m529/727 [====================>.........] - ETA: 0s - loss: 0.4842 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m589/727 [=======================>......] - ETA: 0s - loss: 0.4843 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m644/727 [=========================>....] - ETA: 0s - loss: 0.4856 - accuracy: 0.7795\u001b[0m\n",
      "\u001b[34m701/727 [===========================>..] - ETA: 0s - loss: 0.4835 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 867us/step - loss: 0.4847 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 45/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6600 - accuracy: 0.5000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.4497 - accuracy: 0.8125\n",
      " 97/727 [===>..........................] - ETA: 0s - loss: 0.4538 - accuracy: 0.7887\u001b[0m\n",
      "\u001b[34m157/727 [=====>........................] - ETA: 0s - loss: 0.4422 - accuracy: 0.7962\u001b[0m\n",
      "\u001b[34m212/727 [=======>......................] - ETA: 0s - loss: 0.4571 - accuracy: 0.7877\u001b[0m\n",
      "\u001b[34m262/727 [=========>....................] - ETA: 0s - loss: 0.4780 - accuracy: 0.7691\u001b[0m\n",
      "\u001b[34m306/727 [===========>..................] - ETA: 0s - loss: 0.4785 - accuracy: 0.7729\u001b[0m\n",
      "\u001b[34m347/727 [=============>................] - ETA: 0s - loss: 0.4822 - accuracy: 0.7695\u001b[0m\n",
      "\u001b[34m387/727 [==============>...............] - ETA: 0s - loss: 0.4772 - accuracy: 0.7739\u001b[0m\n",
      "\u001b[34m445/727 [=================>............] - ETA: 0s - loss: 0.4798 - accuracy: 0.7742\u001b[0m\n",
      "\u001b[34m501/727 [===================>..........] - ETA: 0s - loss: 0.4825 - accuracy: 0.7695\u001b[0m\n",
      "\u001b[34m557/727 [=====================>........] - ETA: 0s - loss: 0.4756 - accuracy: 0.7756\u001b[0m\n",
      "\u001b[34m602/727 [=======================>......] - ETA: 0s - loss: 0.4768 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34m651/727 [=========================>....] - ETA: 0s - loss: 0.4710 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m699/727 [===========================>..] - ETA: 0s - loss: 0.4762 - accuracy: 0.7818\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.4801 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 46/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.8139 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.5038 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m109/727 [===>..........................] - ETA: 0s - loss: 0.5001 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m155/727 [=====>........................] - ETA: 0s - loss: 0.4819 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m211/727 [=======>......................] - ETA: 0s - loss: 0.4836 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m265/727 [=========>....................] - ETA: 0s - loss: 0.4756 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34m311/727 [===========>..................] - ETA: 0s - loss: 0.4794 - accuracy: 0.7846\u001b[0m\n",
      "\u001b[34m361/727 [=============>................] - ETA: 0s - loss: 0.4859 - accuracy: 0.7715\u001b[0m\n",
      "\u001b[34m407/727 [===============>..............] - ETA: 0s - loss: 0.4809 - accuracy: 0.7764\u001b[0m\n",
      "\u001b[34m456/727 [=================>............] - ETA: 0s - loss: 0.4818 - accuracy: 0.7730\u001b[0m\n",
      "\u001b[34m515/727 [====================>.........] - ETA: 0s - loss: 0.4709 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34m568/727 [======================>.......] - ETA: 0s - loss: 0.4671 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m613/727 [========================>.....] - ETA: 0s - loss: 0.4729 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m671/727 [==========================>...] - ETA: 0s - loss: 0.4731 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 969us/step - loss: 0.4755 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34mEpoch 47/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1675 - accuracy: 1.0000\n",
      " 57/727 [=>............................] - ETA: 0s - loss: 0.4601 - accuracy: 0.7982\u001b[0m\n",
      "\u001b[34m111/727 [===>..........................] - ETA: 0s - loss: 0.4232 - accuracy: 0.8198\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 0s - loss: 0.4279 - accuracy: 0.8206\u001b[0m\n",
      "\u001b[34m229/727 [========>.....................] - ETA: 0s - loss: 0.4235 - accuracy: 0.8166\u001b[0m\n",
      "\u001b[34m289/727 [==========>...................] - ETA: 0s - loss: 0.4359 - accuracy: 0.7993\u001b[0m\n",
      "\u001b[34m349/727 [=============>................] - ETA: 0s - loss: 0.4448 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34m405/727 [===============>..............] - ETA: 0s - loss: 0.4632 - accuracy: 0.7914\u001b[0m\n",
      "\u001b[34m460/727 [=================>............] - ETA: 0s - loss: 0.4675 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m512/727 [====================>.........] - ETA: 0s - loss: 0.4710 - accuracy: 0.7900\u001b[0m\n",
      "\u001b[34m555/727 [=====================>........] - ETA: 0s - loss: 0.4698 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m608/727 [========================>.....] - ETA: 0s - loss: 0.4757 - accuracy: 0.7870\u001b[0m\n",
      "\u001b[34m661/727 [==========================>...] - ETA: 0s - loss: 0.4734 - accuracy: 0.7897\u001b[0m\n",
      "\u001b[34m717/727 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.7873\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 916us/step - loss: 0.4792 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34mEpoch 48/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2087 - accuracy: 1.0000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.5140 - accuracy: 0.7542\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.4923 - accuracy: 0.7672\u001b[0m\n",
      "\u001b[34m167/727 [=====>........................] - ETA: 0s - loss: 0.4908 - accuracy: 0.7605\u001b[0m\n",
      "\u001b[34m216/727 [=======>......................] - ETA: 0s - loss: 0.4831 - accuracy: 0.7708\u001b[0m\n",
      "\u001b[34m272/727 [==========>...................] - ETA: 0s - loss: 0.4890 - accuracy: 0.7610\u001b[0m\n",
      "\u001b[34m328/727 [============>.................] - ETA: 0s - loss: 0.4946 - accuracy: 0.7591\u001b[0m\n",
      "\u001b[34m385/727 [==============>...............] - ETA: 0s - loss: 0.4955 - accuracy: 0.7610\u001b[0m\n",
      "\u001b[34m439/727 [=================>............] - ETA: 0s - loss: 0.4972 - accuracy: 0.7642\u001b[0m\n",
      "\u001b[34m496/727 [===================>..........] - ETA: 0s - loss: 0.4926 - accuracy: 0.7681\u001b[0m\n",
      "\u001b[34m550/727 [=====================>........] - ETA: 0s - loss: 0.4879 - accuracy: 0.7727\u001b[0m\n",
      "\u001b[34m605/727 [=======================>......] - ETA: 0s - loss: 0.4850 - accuracy: 0.7752\u001b[0m\n",
      "\u001b[34m665/727 [==========================>...] - ETA: 0s - loss: 0.4883 - accuracy: 0.7744\u001b[0m\n",
      "\u001b[34m725/727 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 906us/step - loss: 0.4812 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34mEpoch 49/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1281 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.5408 - accuracy: 0.7583\u001b[0m\n",
      "\u001b[34m119/727 [===>..........................] - ETA: 0s - loss: 0.5357 - accuracy: 0.7479\u001b[0m\n",
      "\u001b[34m178/727 [======>.......................] - ETA: 0s - loss: 0.5213 - accuracy: 0.7528\u001b[0m\n",
      "\u001b[34m235/727 [========>.....................] - ETA: 0s - loss: 0.4973 - accuracy: 0.7681\u001b[0m\n",
      "\u001b[34m293/727 [===========>..................] - ETA: 0s - loss: 0.4900 - accuracy: 0.7730\u001b[0m\n",
      "\u001b[34m348/727 [=============>................] - ETA: 0s - loss: 0.4907 - accuracy: 0.7773\u001b[0m\n",
      "\u001b[34m408/727 [===============>..............] - ETA: 0s - loss: 0.4852 - accuracy: 0.7770\u001b[0m\n",
      "\u001b[34m463/727 [==================>...........] - ETA: 0s - loss: 0.4831 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m502/727 [===================>..........] - ETA: 0s - loss: 0.4783 - accuracy: 0.7829\u001b[0m\n",
      "\u001b[34m546/727 [=====================>........] - ETA: 0s - loss: 0.4797 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m595/727 [=======================>......] - ETA: 0s - loss: 0.4858 - accuracy: 0.7782\u001b[0m\n",
      "\u001b[34m644/727 [=========================>....] - ETA: 0s - loss: 0.4781 - accuracy: 0.7849\u001b[0m\n",
      "\u001b[34m698/727 [===========================>..] - ETA: 0s - loss: 0.4751 - accuracy: 0.7858\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 942us/step - loss: 0.4779 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34mEpoch 50/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 1.0707 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.5250 - accuracy: 0.7333\u001b[0m\n",
      "\u001b[34m119/727 [===>..........................] - ETA: 0s - loss: 0.4792 - accuracy: 0.7689\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.5006 - accuracy: 0.7570\u001b[0m\n",
      "\u001b[34m238/727 [========>.....................] - ETA: 0s - loss: 0.4996 - accuracy: 0.7668\u001b[0m\n",
      "\u001b[34m298/727 [===========>..................] - ETA: 0s - loss: 0.4954 - accuracy: 0.7685\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4966 - accuracy: 0.7682\u001b[0m\n",
      "\u001b[34m418/727 [================>.............] - ETA: 0s - loss: 0.5043 - accuracy: 0.7632\u001b[0m\n",
      "\u001b[34m478/727 [==================>...........] - ETA: 0s - loss: 0.4979 - accuracy: 0.7678\u001b[0m\n",
      "\u001b[34m538/727 [=====================>........] - ETA: 0s - loss: 0.4872 - accuracy: 0.7742\u001b[0m\n",
      "\u001b[34m598/727 [=======================>......] - ETA: 0s - loss: 0.4804 - accuracy: 0.7784\u001b[0m\n",
      "\u001b[34m658/727 [==========================>...] - ETA: 0s - loss: 0.4756 - accuracy: 0.7819\u001b[0m\n",
      "\u001b[34m711/727 [============================>.] - ETA: 0s - loss: 0.4738 - accuracy: 0.7813\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 854us/step - loss: 0.4728 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34mEpoch 51/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1571 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4883 - accuracy: 0.7667\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.4946 - accuracy: 0.7669\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4983 - accuracy: 0.7627\u001b[0m\n",
      "\u001b[34m236/727 [========>.....................] - ETA: 0s - loss: 0.5108 - accuracy: 0.7564\u001b[0m\n",
      "\u001b[34m296/727 [===========>..................] - ETA: 0s - loss: 0.5104 - accuracy: 0.7584\u001b[0m\n",
      "\u001b[34m355/727 [=============>................] - ETA: 0s - loss: 0.5079 - accuracy: 0.7620\u001b[0m\n",
      "\u001b[34m414/727 [================>.............] - ETA: 0s - loss: 0.5110 - accuracy: 0.7645\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.4993 - accuracy: 0.7733\u001b[0m\n",
      "\u001b[34m526/727 [====================>.........] - ETA: 0s - loss: 0.4948 - accuracy: 0.7738\u001b[0m\n",
      "\u001b[34m583/727 [=======================>......] - ETA: 0s - loss: 0.4923 - accuracy: 0.7770\u001b[0m\n",
      "\u001b[34m640/727 [=========================>....] - ETA: 0s - loss: 0.4872 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m695/727 [===========================>..] - ETA: 0s - loss: 0.4847 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 873us/step - loss: 0.4831 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34mEpoch 52/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2420 - accuracy: 1.0000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.5112 - accuracy: 0.7328\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.4940 - accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m169/727 [=====>........................] - ETA: 0s - loss: 0.4692 - accuracy: 0.7663\u001b[0m\n",
      "\u001b[34m222/727 [========>.....................] - ETA: 0s - loss: 0.4654 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m266/727 [=========>....................] - ETA: 0s - loss: 0.4560 - accuracy: 0.7876\u001b[0m\n",
      "\u001b[34m315/727 [===========>..................] - ETA: 0s - loss: 0.4569 - accuracy: 0.7857\u001b[0m\n",
      "\u001b[34m370/727 [==============>...............] - ETA: 0s - loss: 0.4648 - accuracy: 0.7838\u001b[0m\n",
      "\u001b[34m425/727 [================>.............] - ETA: 0s - loss: 0.4735 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m479/727 [==================>...........] - ETA: 0s - loss: 0.4748 - accuracy: 0.7766\u001b[0m\n",
      "\u001b[34m533/727 [====================>.........] - ETA: 0s - loss: 0.4721 - accuracy: 0.7814\u001b[0m\n",
      "\u001b[34m588/727 [=======================>......] - ETA: 0s - loss: 0.4713 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34m641/727 [=========================>....] - ETA: 0s - loss: 0.4660 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m699/727 [===========================>..] - ETA: 0s - loss: 0.4647 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 937us/step - loss: 0.4664 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34mEpoch 53/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6012 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4432 - accuracy: 0.8083\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4589 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 0s - loss: 0.5020 - accuracy: 0.7647\u001b[0m\n",
      "\u001b[34m229/727 [========>.....................] - ETA: 0s - loss: 0.4867 - accuracy: 0.7686\u001b[0m\n",
      "\u001b[34m287/727 [==========>...................] - ETA: 0s - loss: 0.4842 - accuracy: 0.7718\u001b[0m\n",
      "\u001b[34m345/727 [=============>................] - ETA: 0s - loss: 0.4817 - accuracy: 0.7754\u001b[0m\n",
      "\u001b[34m404/727 [===============>..............] - ETA: 0s - loss: 0.4765 - accuracy: 0.7809\u001b[0m\n",
      "\u001b[34m463/727 [==================>...........] - ETA: 0s - loss: 0.4702 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34m522/727 [====================>.........] - ETA: 0s - loss: 0.4784 - accuracy: 0.7807\u001b[0m\n",
      "\u001b[34m582/727 [=======================>......] - ETA: 0s - loss: 0.4787 - accuracy: 0.7801\u001b[0m\n",
      "\u001b[34m637/727 [=========================>....] - ETA: 0s - loss: 0.4811 - accuracy: 0.7802\u001b[0m\n",
      "\u001b[34m696/727 [===========================>..] - ETA: 0s - loss: 0.4729 - accuracy: 0.7838\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 872us/step - loss: 0.4731 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34mEpoch 54/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 1.3765 - accuracy: 0.5000\n",
      " 55/727 [=>............................] - ETA: 0s - loss: 0.4522 - accuracy: 0.7818\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4660 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m173/727 [======>.......................] - ETA: 0s - loss: 0.4673 - accuracy: 0.7948\u001b[0m\n",
      "\u001b[34m232/727 [========>.....................] - ETA: 0s - loss: 0.4650 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m291/727 [===========>..................] - ETA: 0s - loss: 0.4558 - accuracy: 0.7904\u001b[0m\n",
      "\u001b[34m335/727 [============>.................] - ETA: 0s - loss: 0.4604 - accuracy: 0.7910\u001b[0m\n",
      "\u001b[34m388/727 [===============>..............] - ETA: 0s - loss: 0.4671 - accuracy: 0.7887\u001b[0m\n",
      "\u001b[34m438/727 [=================>............] - ETA: 0s - loss: 0.4786 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34m484/727 [==================>...........] - ETA: 0s - loss: 0.4775 - accuracy: 0.7851\u001b[0m\n",
      "\u001b[34m536/727 [=====================>........] - ETA: 0s - loss: 0.4819 - accuracy: 0.7808\u001b[0m\n",
      "\u001b[34m589/727 [=======================>......] - ETA: 0s - loss: 0.4783 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34m641/727 [=========================>....] - ETA: 0s - loss: 0.4777 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m693/727 [===========================>..] - ETA: 0s - loss: 0.4740 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 953us/step - loss: 0.4738 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34mEpoch 55/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.1534 - accuracy: 1.0000\n",
      " 53/727 [=>............................] - ETA: 0s - loss: 0.4457 - accuracy: 0.8302\u001b[0m\n",
      "\u001b[34m105/727 [===>..........................] - ETA: 0s - loss: 0.4270 - accuracy: 0.8333\u001b[0m\n",
      "\u001b[34m159/727 [=====>........................] - ETA: 0s - loss: 0.4438 - accuracy: 0.8145\u001b[0m\n",
      "\u001b[34m210/727 [=======>......................] - ETA: 0s - loss: 0.4567 - accuracy: 0.8024\u001b[0m\n",
      "\u001b[34m262/727 [=========>....................] - ETA: 0s - loss: 0.4648 - accuracy: 0.7977\u001b[0m\n",
      "\u001b[34m309/727 [===========>..................] - ETA: 0s - loss: 0.4631 - accuracy: 0.7994\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4581 - accuracy: 0.8003\u001b[0m\n",
      "\u001b[34m406/727 [===============>..............] - ETA: 0s - loss: 0.4518 - accuracy: 0.8017\u001b[0m\n",
      "\u001b[34m461/727 [==================>...........] - ETA: 0s - loss: 0.4577 - accuracy: 0.7972\u001b[0m\n",
      "\u001b[34m517/727 [====================>.........] - ETA: 0s - loss: 0.4554 - accuracy: 0.7969\u001b[0m\n",
      "\u001b[34m567/727 [======================>.......] - ETA: 0s - loss: 0.4570 - accuracy: 0.7972\u001b[0m\n",
      "\u001b[34m618/727 [========================>.....] - ETA: 0s - loss: 0.4670 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m676/727 [==========================>...] - ETA: 0s - loss: 0.4766 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 970us/step - loss: 0.4754 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34mEpoch 56/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.2241 - accuracy: 1.0000\n",
      " 49/727 [=>............................] - ETA: 0s - loss: 0.4089 - accuracy: 0.7857\n",
      " 98/727 [===>..........................] - ETA: 0s - loss: 0.4793 - accuracy: 0.7551\u001b[0m\n",
      "\u001b[34m150/727 [=====>........................] - ETA: 0s - loss: 0.4739 - accuracy: 0.7600\u001b[0m\n",
      "\u001b[34m195/727 [=======>......................] - ETA: 0s - loss: 0.4710 - accuracy: 0.7667\u001b[0m\n",
      "\u001b[34m251/727 [=========>....................] - ETA: 0s - loss: 0.4596 - accuracy: 0.7769\u001b[0m\n",
      "\u001b[34m311/727 [===========>..................] - ETA: 0s - loss: 0.4519 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m371/727 [==============>...............] - ETA: 0s - loss: 0.4544 - accuracy: 0.7830\u001b[0m\n",
      "\u001b[34m430/727 [================>.............] - ETA: 0s - loss: 0.4583 - accuracy: 0.7849\u001b[0m\n",
      "\u001b[34m490/727 [===================>..........] - ETA: 0s - loss: 0.4652 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34m550/727 [=====================>........] - ETA: 0s - loss: 0.4651 - accuracy: 0.7855\u001b[0m\n",
      "\u001b[34m608/727 [========================>.....] - ETA: 0s - loss: 0.4646 - accuracy: 0.7895\u001b[0m\n",
      "\u001b[34m667/727 [==========================>...] - ETA: 0s - loss: 0.4608 - accuracy: 0.7916\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 904us/step - loss: 0.4616 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34mEpoch 57/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3111 - accuracy: 1.0000\n",
      " 55/727 [=>............................] - ETA: 0s - loss: 0.4427 - accuracy: 0.7909\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.4455 - accuracy: 0.8070\u001b[0m\n",
      "\u001b[34m168/727 [=====>........................] - ETA: 0s - loss: 0.4418 - accuracy: 0.7976\u001b[0m\n",
      "\u001b[34m215/727 [=======>......................] - ETA: 0s - loss: 0.4507 - accuracy: 0.7953\u001b[0m\n",
      "\u001b[34m274/727 [==========>...................] - ETA: 0s - loss: 0.4562 - accuracy: 0.7993\u001b[0m\n",
      "\u001b[34m331/727 [============>.................] - ETA: 0s - loss: 0.4618 - accuracy: 0.7931\u001b[0m\n",
      "\u001b[34m388/727 [===============>..............] - ETA: 0s - loss: 0.4603 - accuracy: 0.7964\u001b[0m\n",
      "\u001b[34m446/727 [=================>............] - ETA: 0s - loss: 0.4632 - accuracy: 0.7915\u001b[0m\n",
      "\u001b[34m505/727 [===================>..........] - ETA: 0s - loss: 0.4653 - accuracy: 0.7891\u001b[0m\n",
      "\u001b[34m560/727 [======================>.......] - ETA: 0s - loss: 0.4656 - accuracy: 0.7902\u001b[0m\n",
      "\u001b[34m606/727 [========================>.....] - ETA: 0s - loss: 0.4694 - accuracy: 0.7871\u001b[0m\n",
      "\u001b[34m664/727 [==========================>...] - ETA: 0s - loss: 0.4667 - accuracy: 0.7907\u001b[0m\n",
      "\u001b[34m724/727 [============================>.] - ETA: 0s - loss: 0.4674 - accuracy: 0.7880\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 907us/step - loss: 0.4675 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34mEpoch 58/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7890 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4342 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4215 - accuracy: 0.7934\u001b[0m\n",
      "\u001b[34m181/727 [======>.......................] - ETA: 0s - loss: 0.4219 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m240/727 [========>.....................] - ETA: 0s - loss: 0.4501 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4647 - accuracy: 0.7750\u001b[0m\n",
      "\u001b[34m360/727 [=============>................] - ETA: 0s - loss: 0.4663 - accuracy: 0.7736\u001b[0m\n",
      "\u001b[34m420/727 [================>.............] - ETA: 0s - loss: 0.4676 - accuracy: 0.7750\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.4675 - accuracy: 0.7786\u001b[0m\n",
      "\u001b[34m530/727 [====================>.........] - ETA: 0s - loss: 0.4641 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34m581/727 [======================>.......] - ETA: 0s - loss: 0.4632 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34m640/727 [=========================>....] - ETA: 0s - loss: 0.4614 - accuracy: 0.7867\u001b[0m\n",
      "\u001b[34m698/727 [===========================>..] - ETA: 0s - loss: 0.4655 - accuracy: 0.7822\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 870us/step - loss: 0.4626 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34mEpoch 59/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7122 - accuracy: 0.5000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.4583 - accuracy: 0.7768\u001b[0m\n",
      "\u001b[34m115/727 [===>..........................] - ETA: 0s - loss: 0.4702 - accuracy: 0.7739\u001b[0m\n",
      "\u001b[34m173/727 [======>.......................] - ETA: 0s - loss: 0.4558 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m232/727 [========>.....................] - ETA: 0s - loss: 0.4613 - accuracy: 0.7888\u001b[0m\n",
      "\u001b[34m292/727 [===========>..................] - ETA: 0s - loss: 0.4597 - accuracy: 0.7894\u001b[0m\n",
      "\u001b[34m352/727 [=============>................] - ETA: 0s - loss: 0.4700 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m411/727 [===============>..............] - ETA: 0s - loss: 0.4690 - accuracy: 0.7749\u001b[0m\n",
      "\u001b[34m471/727 [==================>...........] - ETA: 0s - loss: 0.4647 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m529/727 [====================>.........] - ETA: 0s - loss: 0.4549 - accuracy: 0.7864\u001b[0m\n",
      "\u001b[34m589/727 [=======================>......] - ETA: 0s - loss: 0.4569 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m647/727 [=========================>....] - ETA: 0s - loss: 0.4604 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m704/727 [============================>.] - ETA: 0s - loss: 0.4598 - accuracy: 0.7884\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 862us/step - loss: 0.4617 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34mEpoch 60/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3106 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4695 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4749 - accuracy: 0.7727\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4858 - accuracy: 0.7599\u001b[0m\n",
      "\u001b[34m236/727 [========>.....................] - ETA: 0s - loss: 0.4910 - accuracy: 0.7585\u001b[0m\n",
      "\u001b[34m295/727 [===========>..................] - ETA: 0s - loss: 0.4787 - accuracy: 0.7610\u001b[0m\n",
      "\u001b[34m352/727 [=============>................] - ETA: 0s - loss: 0.4684 - accuracy: 0.7656\u001b[0m\n",
      "\u001b[34m409/727 [===============>..............] - ETA: 0s - loss: 0.4746 - accuracy: 0.7665\u001b[0m\n",
      "\u001b[34m463/727 [==================>...........] - ETA: 0s - loss: 0.4749 - accuracy: 0.7711\u001b[0m\n",
      "\u001b[34m523/727 [====================>.........] - ETA: 0s - loss: 0.4699 - accuracy: 0.7763\u001b[0m\n",
      "\u001b[34m582/727 [=======================>......] - ETA: 0s - loss: 0.4735 - accuracy: 0.7732\u001b[0m\n",
      "\u001b[34m641/727 [=========================>....] - ETA: 0s - loss: 0.4743 - accuracy: 0.7730\u001b[0m\n",
      "\u001b[34m701/727 [===========================>..] - ETA: 0s - loss: 0.4669 - accuracy: 0.7796\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 866us/step - loss: 0.4671 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 61/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6783 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4727 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4705 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.4560 - accuracy: 0.7944\u001b[0m\n",
      "\u001b[34m240/727 [========>.....................] - ETA: 0s - loss: 0.4463 - accuracy: 0.7979\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4455 - accuracy: 0.7967\u001b[0m\n",
      "\u001b[34m360/727 [=============>................] - ETA: 0s - loss: 0.4615 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m419/727 [================>.............] - ETA: 0s - loss: 0.4655 - accuracy: 0.7828\u001b[0m\n",
      "\u001b[34m479/727 [==================>...........] - ETA: 0s - loss: 0.4630 - accuracy: 0.7818\u001b[0m\n",
      "\u001b[34m538/727 [=====================>........] - ETA: 0s - loss: 0.4622 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m590/727 [=======================>......] - ETA: 0s - loss: 0.4612 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m650/727 [=========================>....] - ETA: 0s - loss: 0.4609 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m708/727 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 857us/step - loss: 0.4655 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34mEpoch 62/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2141 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4641 - accuracy: 0.7705\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.4630 - accuracy: 0.7669\u001b[0m\n",
      "\u001b[34m176/727 [======>.......................] - ETA: 0s - loss: 0.4665 - accuracy: 0.7670\u001b[0m\n",
      "\u001b[34m235/727 [========>.....................] - ETA: 0s - loss: 0.4772 - accuracy: 0.7638\u001b[0m\n",
      "\u001b[34m293/727 [===========>..................] - ETA: 0s - loss: 0.4710 - accuracy: 0.7662\u001b[0m\n",
      "\u001b[34m352/727 [=============>................] - ETA: 0s - loss: 0.4700 - accuracy: 0.7670\u001b[0m\n",
      "\u001b[34m409/727 [===============>..............] - ETA: 0s - loss: 0.4631 - accuracy: 0.7726\u001b[0m\n",
      "\u001b[34m468/727 [==================>...........] - ETA: 0s - loss: 0.4690 - accuracy: 0.7703\u001b[0m\n",
      "\u001b[34m528/727 [====================>.........] - ETA: 0s - loss: 0.4644 - accuracy: 0.7756\u001b[0m\n",
      "\u001b[34m587/727 [=======================>......] - ETA: 0s - loss: 0.4628 - accuracy: 0.7802\u001b[0m\n",
      "\u001b[34m646/727 [=========================>....] - ETA: 0s - loss: 0.4723 - accuracy: 0.7771\u001b[0m\n",
      "\u001b[34m705/727 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 861us/step - loss: 0.4647 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34mEpoch 63/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2010 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 54/727 [=>............................] - ETA: 0s - loss: 0.5082 - accuracy: 0.7778\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4808 - accuracy: 0.7788\u001b[0m\n",
      "\u001b[34m173/727 [======>.......................] - ETA: 0s - loss: 0.4868 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m232/727 [========>.....................] - ETA: 0s - loss: 0.4911 - accuracy: 0.7672\u001b[0m\n",
      "\u001b[34m288/727 [==========>...................] - ETA: 0s - loss: 0.4912 - accuracy: 0.7569\u001b[0m\n",
      "\u001b[34m347/727 [=============>................] - ETA: 0s - loss: 0.4734 - accuracy: 0.7709\u001b[0m\n",
      "\u001b[34m406/727 [===============>..............] - ETA: 0s - loss: 0.4707 - accuracy: 0.7734\u001b[0m\n",
      "\u001b[34m459/727 [=================>............] - ETA: 0s - loss: 0.4738 - accuracy: 0.7702\u001b[0m\n",
      "\u001b[34m518/727 [====================>.........] - ETA: 0s - loss: 0.4716 - accuracy: 0.7722\u001b[0m\n",
      "\u001b[34m576/727 [======================>.......] - ETA: 0s - loss: 0.4681 - accuracy: 0.7760\u001b[0m\n",
      "\u001b[34m629/727 [========================>.....] - ETA: 0s - loss: 0.4638 - accuracy: 0.7814\u001b[0m\n",
      "\u001b[34m688/727 [===========================>..] - ETA: 0s - loss: 0.4644 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 887us/step - loss: 0.4647 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34mEpoch 64/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.4835 - accuracy: 0.5000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.4683 - accuracy: 0.7542\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4088 - accuracy: 0.8009\u001b[0m\n",
      "\u001b[34m172/727 [======>.......................] - ETA: 0s - loss: 0.4143 - accuracy: 0.7936\u001b[0m\n",
      "\u001b[34m232/727 [========>.....................] - ETA: 0s - loss: 0.4209 - accuracy: 0.7909\u001b[0m\n",
      "\u001b[34m291/727 [===========>..................] - ETA: 0s - loss: 0.4362 - accuracy: 0.7852\u001b[0m\n",
      "\u001b[34m349/727 [=============>................] - ETA: 0s - loss: 0.4373 - accuracy: 0.7851\u001b[0m\n",
      "\u001b[34m409/727 [===============>..............] - ETA: 0s - loss: 0.4468 - accuracy: 0.7824\u001b[0m\n",
      "\u001b[34m468/727 [==================>...........] - ETA: 0s - loss: 0.4558 - accuracy: 0.7831\u001b[0m\n",
      "\u001b[34m525/727 [====================>.........] - ETA: 0s - loss: 0.4555 - accuracy: 0.7876\u001b[0m\n",
      "\u001b[34m581/727 [======================>.......] - ETA: 0s - loss: 0.4527 - accuracy: 0.7892\u001b[0m\n",
      "\u001b[34m640/727 [=========================>....] - ETA: 0s - loss: 0.4530 - accuracy: 0.7891\u001b[0m\n",
      "\u001b[34m699/727 [===========================>..] - ETA: 0s - loss: 0.4562 - accuracy: 0.7911\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 874us/step - loss: 0.4635 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34mEpoch 65/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2175 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4706 - accuracy: 0.7623\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.4396 - accuracy: 0.7982\u001b[0m\n",
      "\u001b[34m164/727 [=====>........................] - ETA: 0s - loss: 0.4389 - accuracy: 0.8049\u001b[0m\n",
      "\u001b[34m218/727 [=======>......................] - ETA: 0s - loss: 0.4489 - accuracy: 0.7936\u001b[0m\n",
      "\u001b[34m272/727 [==========>...................] - ETA: 0s - loss: 0.4549 - accuracy: 0.7941\u001b[0m\n",
      "\u001b[34m326/727 [============>.................] - ETA: 0s - loss: 0.4604 - accuracy: 0.7899\u001b[0m\n",
      "\u001b[34m385/727 [==============>...............] - ETA: 0s - loss: 0.4619 - accuracy: 0.7831\u001b[0m\n",
      "\u001b[34m443/727 [=================>............] - ETA: 0s - loss: 0.4686 - accuracy: 0.7777\u001b[0m\n",
      "\u001b[34m496/727 [===================>..........] - ETA: 0s - loss: 0.4716 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m545/727 [=====================>........] - ETA: 0s - loss: 0.4716 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m600/727 [=======================>......] - ETA: 0s - loss: 0.4725 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m660/727 [==========================>...] - ETA: 0s - loss: 0.4693 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m712/727 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.7823\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 923us/step - loss: 0.4687 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34mEpoch 66/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.8572 - accuracy: 0.5000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.4941 - accuracy: 0.7857\u001b[0m\n",
      "\u001b[34m111/727 [===>..........................] - ETA: 0s - loss: 0.4730 - accuracy: 0.7883\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 0s - loss: 0.5062 - accuracy: 0.7765\u001b[0m\n",
      "\u001b[34m228/727 [========>.....................] - ETA: 0s - loss: 0.4976 - accuracy: 0.7785\u001b[0m\n",
      "\u001b[34m279/727 [==========>...................] - ETA: 0s - loss: 0.4802 - accuracy: 0.7867\u001b[0m\n",
      "\u001b[34m338/727 [============>.................] - ETA: 0s - loss: 0.4769 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m387/727 [==============>...............] - ETA: 0s - loss: 0.4786 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m446/727 [=================>............] - ETA: 0s - loss: 0.4790 - accuracy: 0.7803\u001b[0m\n",
      "\u001b[34m502/727 [===================>..........] - ETA: 0s - loss: 0.4732 - accuracy: 0.7819\u001b[0m\n",
      "\u001b[34m559/727 [======================>.......] - ETA: 0s - loss: 0.4714 - accuracy: 0.7818\u001b[0m\n",
      "\u001b[34m618/727 [========================>.....] - ETA: 0s - loss: 0.4667 - accuracy: 0.7848\u001b[0m\n",
      "\u001b[34m674/727 [==========================>...] - ETA: 0s - loss: 0.4674 - accuracy: 0.7864\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 898us/step - loss: 0.4667 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34mEpoch 67/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2222 - accuracy: 1.0000\n",
      " 57/727 [=>............................] - ETA: 0s - loss: 0.4018 - accuracy: 0.8333\u001b[0m\n",
      "\u001b[34m103/727 [===>..........................] - ETA: 0s - loss: 0.4045 - accuracy: 0.8495\u001b[0m\n",
      "\u001b[34m143/727 [====>.........................] - ETA: 0s - loss: 0.4256 - accuracy: 0.8252\u001b[0m\n",
      "\u001b[34m193/727 [======>.......................] - ETA: 0s - loss: 0.4494 - accuracy: 0.8109\u001b[0m\n",
      "\u001b[34m241/727 [========>.....................] - ETA: 0s - loss: 0.4472 - accuracy: 0.8133\u001b[0m\n",
      "\u001b[34m291/727 [===========>..................] - ETA: 0s - loss: 0.4535 - accuracy: 0.8024\u001b[0m\n",
      "\u001b[34m349/727 [=============>................] - ETA: 0s - loss: 0.4481 - accuracy: 0.7980\u001b[0m\n",
      "\u001b[34m404/727 [===============>..............] - ETA: 0s - loss: 0.4512 - accuracy: 0.7970\u001b[0m\n",
      "\u001b[34m452/727 [=================>............] - ETA: 0s - loss: 0.4613 - accuracy: 0.7887\u001b[0m\n",
      "\u001b[34m506/727 [===================>..........] - ETA: 0s - loss: 0.4646 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m560/727 [======================>.......] - ETA: 0s - loss: 0.4679 - accuracy: 0.7839\u001b[0m\n",
      "\u001b[34m616/727 [========================>.....] - ETA: 0s - loss: 0.4659 - accuracy: 0.7857\u001b[0m\n",
      "\u001b[34m671/727 [==========================>...] - ETA: 0s - loss: 0.4618 - accuracy: 0.7891\u001b[0m\n",
      "\u001b[34m722/727 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.7874\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 982us/step - loss: 0.4613 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34mEpoch 68/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 1.1315 - accuracy: 0.5000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.4802 - accuracy: 0.7627\u001b[0m\n",
      "\u001b[34m119/727 [===>..........................] - ETA: 0s - loss: 0.4693 - accuracy: 0.7899\u001b[0m\n",
      "\u001b[34m178/727 [======>.......................] - ETA: 0s - loss: 0.4640 - accuracy: 0.7865\u001b[0m\n",
      "\u001b[34m234/727 [========>.....................] - ETA: 0s - loss: 0.4595 - accuracy: 0.7863\u001b[0m\n",
      "\u001b[34m287/727 [==========>...................] - ETA: 0s - loss: 0.4457 - accuracy: 0.7927\u001b[0m\n",
      "\u001b[34m341/727 [=============>................] - ETA: 0s - loss: 0.4538 - accuracy: 0.7947\u001b[0m\n",
      "\u001b[34m395/727 [===============>..............] - ETA: 0s - loss: 0.4507 - accuracy: 0.7949\u001b[0m\n",
      "\u001b[34m451/727 [=================>............] - ETA: 0s - loss: 0.4501 - accuracy: 0.7960\u001b[0m\n",
      "\u001b[34m509/727 [====================>.........] - ETA: 0s - loss: 0.4557 - accuracy: 0.7898\u001b[0m\n",
      "\u001b[34m565/727 [======================>.......] - ETA: 0s - loss: 0.4586 - accuracy: 0.7929\u001b[0m\n",
      "\u001b[34m611/727 [========================>.....] - ETA: 0s - loss: 0.4606 - accuracy: 0.7905\u001b[0m\n",
      "\u001b[34m657/727 [==========================>...] - ETA: 0s - loss: 0.4659 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m706/727 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 935us/step - loss: 0.4664 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34mEpoch 69/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.8661 - accuracy: 0.5000\u001b[0m\n",
      "\u001b[34m 46/727 [>.............................] - ETA: 0s - loss: 0.4689 - accuracy: 0.7826\u001b[0m\n",
      "\u001b[34m100/727 [===>..........................] - ETA: 0s - loss: 0.4802 - accuracy: 0.7800\u001b[0m\n",
      "\u001b[34m160/727 [=====>........................] - ETA: 0s - loss: 0.4743 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m219/727 [========>.....................] - ETA: 0s - loss: 0.4609 - accuracy: 0.7831\u001b[0m\n",
      "\u001b[34m279/727 [==========>...................] - ETA: 0s - loss: 0.4635 - accuracy: 0.7796\u001b[0m\n",
      "\u001b[34m328/727 [============>.................] - ETA: 0s - loss: 0.4588 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34m384/727 [==============>...............] - ETA: 0s - loss: 0.4605 - accuracy: 0.7826\u001b[0m\n",
      "\u001b[34m443/727 [=================>............] - ETA: 0s - loss: 0.4583 - accuracy: 0.7856\u001b[0m\n",
      "\u001b[34m498/727 [===================>..........] - ETA: 0s - loss: 0.4608 - accuracy: 0.7801\u001b[0m\n",
      "\u001b[34m558/727 [======================>.......] - ETA: 0s - loss: 0.4586 - accuracy: 0.7796\u001b[0m\n",
      "\u001b[34m616/727 [========================>.....] - ETA: 0s - loss: 0.4602 - accuracy: 0.7784\u001b[0m\n",
      "\u001b[34m674/727 [==========================>...] - ETA: 0s - loss: 0.4625 - accuracy: 0.7797\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 900us/step - loss: 0.4633 - accuracy: 0.7806\u001b[0m\n",
      "\u001b[34mEpoch 70/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6470 - accuracy: 0.5000\n",
      " 58/727 [=>............................] - ETA: 0s - loss: 0.3358 - accuracy: 0.8707\u001b[0m\n",
      "\u001b[34m116/727 [===>..........................] - ETA: 0s - loss: 0.3996 - accuracy: 0.8060\u001b[0m\n",
      "\u001b[34m175/727 [======>.......................] - ETA: 0s - loss: 0.4219 - accuracy: 0.7914\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.4161 - accuracy: 0.7897\u001b[0m\n",
      "\u001b[34m291/727 [===========>..................] - ETA: 0s - loss: 0.4223 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m347/727 [=============>................] - ETA: 0s - loss: 0.4280 - accuracy: 0.7911\u001b[0m\n",
      "\u001b[34m404/727 [===============>..............] - ETA: 0s - loss: 0.4236 - accuracy: 0.7958\u001b[0m\n",
      "\u001b[34m452/727 [=================>............] - ETA: 0s - loss: 0.4341 - accuracy: 0.7987\u001b[0m\n",
      "\u001b[34m510/727 [====================>.........] - ETA: 0s - loss: 0.4440 - accuracy: 0.7892\u001b[0m\n",
      "\u001b[34m567/727 [======================>.......] - ETA: 0s - loss: 0.4500 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m620/727 [========================>.....] - ETA: 0s - loss: 0.4530 - accuracy: 0.7871\u001b[0m\n",
      "\u001b[34m679/727 [===========================>..] - ETA: 0s - loss: 0.4596 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 903us/step - loss: 0.4631 - accuracy: 0.7840\u001b[0m\n",
      "\u001b[34mEpoch 71/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2663 - accuracy: 1.0000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4586 - accuracy: 0.7750\u001b[0m\n",
      "\u001b[34m117/727 [===>..........................] - ETA: 0s - loss: 0.4355 - accuracy: 0.8077\u001b[0m\n",
      "\u001b[34m175/727 [======>.......................] - ETA: 0s - loss: 0.4464 - accuracy: 0.8000\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.4379 - accuracy: 0.8047\u001b[0m\n",
      "\u001b[34m290/727 [==========>...................] - ETA: 0s - loss: 0.4334 - accuracy: 0.8052\u001b[0m\n",
      "\u001b[34m346/727 [=============>................] - ETA: 0s - loss: 0.4406 - accuracy: 0.7934\u001b[0m\n",
      "\u001b[34m400/727 [===============>..............] - ETA: 0s - loss: 0.4465 - accuracy: 0.7900\u001b[0m\n",
      "\u001b[34m458/727 [=================>............] - ETA: 0s - loss: 0.4447 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34m513/727 [====================>.........] - ETA: 0s - loss: 0.4514 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m572/727 [======================>.......] - ETA: 0s - loss: 0.4511 - accuracy: 0.7876\u001b[0m\n",
      "\u001b[34m631/727 [=========================>....] - ETA: 0s - loss: 0.4578 - accuracy: 0.7821\u001b[0m\n",
      "\u001b[34m691/727 [===========================>..] - ETA: 0s - loss: 0.4542 - accuracy: 0.7822\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 878us/step - loss: 0.4546 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34mEpoch 72/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3435 - accuracy: 1.0000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.4040 - accuracy: 0.8136\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.4537 - accuracy: 0.7924\u001b[0m\n",
      "\u001b[34m175/727 [======>.......................] - ETA: 0s - loss: 0.4524 - accuracy: 0.7943\u001b[0m\n",
      "\u001b[34m232/727 [========>.....................] - ETA: 0s - loss: 0.4418 - accuracy: 0.7974\u001b[0m\n",
      "\u001b[34m283/727 [==========>...................] - ETA: 0s - loss: 0.4409 - accuracy: 0.7933\u001b[0m\n",
      "\u001b[34m337/727 [============>.................] - ETA: 0s - loss: 0.4404 - accuracy: 0.7953\u001b[0m\n",
      "\u001b[34m392/727 [===============>..............] - ETA: 0s - loss: 0.4448 - accuracy: 0.7934\u001b[0m\n",
      "\u001b[34m444/727 [=================>............] - ETA: 0s - loss: 0.4482 - accuracy: 0.7872\u001b[0m\n",
      "\u001b[34m497/727 [===================>..........] - ETA: 0s - loss: 0.4547 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34m548/727 [=====================>........] - ETA: 0s - loss: 0.4612 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m608/727 [========================>.....] - ETA: 0s - loss: 0.4626 - accuracy: 0.7763\u001b[0m\n",
      "\u001b[34m667/727 [==========================>...] - ETA: 0s - loss: 0.4616 - accuracy: 0.7759\u001b[0m\n",
      "\u001b[34m724/727 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.7769\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 912us/step - loss: 0.4619 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34mEpoch 73/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3436 - accuracy: 1.0000\n",
      " 59/727 [=>............................] - ETA: 0s - loss: 0.4339 - accuracy: 0.7881\u001b[0m\n",
      "\u001b[34m115/727 [===>..........................] - ETA: 0s - loss: 0.4389 - accuracy: 0.7783\u001b[0m\n",
      "\u001b[34m170/727 [======>.......................] - ETA: 0s - loss: 0.4342 - accuracy: 0.7882\u001b[0m\n",
      "\u001b[34m230/727 [========>.....................] - ETA: 0s - loss: 0.4353 - accuracy: 0.7870\u001b[0m\n",
      "\u001b[34m288/727 [==========>...................] - ETA: 0s - loss: 0.4451 - accuracy: 0.7865\u001b[0m\n",
      "\u001b[34m337/727 [============>.................] - ETA: 0s - loss: 0.4466 - accuracy: 0.7878\u001b[0m\n",
      "\u001b[34m396/727 [===============>..............] - ETA: 0s - loss: 0.4477 - accuracy: 0.7841\u001b[0m\n",
      "\u001b[34m455/727 [=================>............] - ETA: 0s - loss: 0.4470 - accuracy: 0.7846\u001b[0m\n",
      "\u001b[34m515/727 [====================>.........] - ETA: 0s - loss: 0.4436 - accuracy: 0.7893\u001b[0m\n",
      "\u001b[34m565/727 [======================>.......] - ETA: 0s - loss: 0.4451 - accuracy: 0.7912\u001b[0m\n",
      "\u001b[34m622/727 [========================>.....] - ETA: 0s - loss: 0.4400 - accuracy: 0.7950\u001b[0m\n",
      "\u001b[34m680/727 [===========================>..] - ETA: 0s - loss: 0.4411 - accuracy: 0.7926\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 894us/step - loss: 0.4436 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34mEpoch 74/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2175 - accuracy: 1.0000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.4292 - accuracy: 0.8304\u001b[0m\n",
      "\u001b[34m109/727 [===>..........................] - ETA: 0s - loss: 0.4633 - accuracy: 0.8073\u001b[0m\n",
      "\u001b[34m163/727 [=====>........................] - ETA: 0s - loss: 0.4969 - accuracy: 0.7730\u001b[0m\n",
      "\u001b[34m216/727 [=======>......................] - ETA: 0s - loss: 0.4725 - accuracy: 0.7824\u001b[0m\n",
      "\u001b[34m275/727 [==========>...................] - ETA: 0s - loss: 0.4615 - accuracy: 0.7855\u001b[0m\n",
      "\u001b[34m328/727 [============>.................] - ETA: 0s - loss: 0.4599 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m386/727 [==============>...............] - ETA: 0s - loss: 0.4529 - accuracy: 0.7889\u001b[0m\n",
      "\u001b[34m436/727 [================>.............] - ETA: 0s - loss: 0.4608 - accuracy: 0.7798\u001b[0m\n",
      "\u001b[34m487/727 [===================>..........] - ETA: 0s - loss: 0.4600 - accuracy: 0.7782\u001b[0m\n",
      "\u001b[34m540/727 [=====================>........] - ETA: 0s - loss: 0.4649 - accuracy: 0.7731\u001b[0m\n",
      "\u001b[34m597/727 [=======================>......] - ETA: 0s - loss: 0.4601 - accuracy: 0.7781\u001b[0m\n",
      "\u001b[34m648/727 [=========================>....] - ETA: 0s - loss: 0.4558 - accuracy: 0.7824\u001b[0m\n",
      "\u001b[34m696/727 [===========================>..] - ETA: 0s - loss: 0.4562 - accuracy: 0.7852\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 950us/step - loss: 0.4560 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34mEpoch 75/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6458 - accuracy: 0.5000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.4083 - accuracy: 0.8036\u001b[0m\n",
      "\u001b[34m 99/727 [===>..........................] - ETA: 0s - loss: 0.4265 - accuracy: 0.8131\u001b[0m\n",
      "\u001b[34m142/727 [====>.........................] - ETA: 0s - loss: 0.4203 - accuracy: 0.8134\u001b[0m\n",
      "\u001b[34m173/727 [======>.......................] - ETA: 0s - loss: 0.4434 - accuracy: 0.7977\u001b[0m\n",
      "\u001b[34m210/727 [=======>......................] - ETA: 0s - loss: 0.4468 - accuracy: 0.7929\u001b[0m\n",
      "\u001b[34m254/727 [=========>....................] - ETA: 0s - loss: 0.4554 - accuracy: 0.7933\u001b[0m\n",
      "\u001b[34m298/727 [===========>..................] - ETA: 0s - loss: 0.4446 - accuracy: 0.8020\u001b[0m\n",
      "\u001b[34m335/727 [============>.................] - ETA: 0s - loss: 0.4462 - accuracy: 0.7985\u001b[0m\n",
      "\u001b[34m388/727 [===============>..............] - ETA: 0s - loss: 0.4421 - accuracy: 0.8003\u001b[0m\n",
      "\u001b[34m435/727 [================>.............] - ETA: 0s - loss: 0.4447 - accuracy: 0.7989\u001b[0m\n",
      "\u001b[34m482/727 [==================>...........] - ETA: 0s - loss: 0.4534 - accuracy: 0.7936\u001b[0m\n",
      "\u001b[34m538/727 [=====================>........] - ETA: 0s - loss: 0.4532 - accuracy: 0.7918\u001b[0m\n",
      "\u001b[34m584/727 [=======================>......] - ETA: 0s - loss: 0.4492 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34m620/727 [========================>.....] - ETA: 0s - loss: 0.4501 - accuracy: 0.7919\u001b[0m\n",
      "\u001b[34m668/727 [==========================>...] - ETA: 0s - loss: 0.4475 - accuracy: 0.7912\u001b[0m\n",
      "\u001b[34m723/727 [============================>.] - ETA: 0s - loss: 0.4543 - accuracy: 0.7898\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 1ms/step - loss: 0.4536 - accuracy: 0.7902\u001b[0m\n",
      "\u001b[34mEpoch 76/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2632 - accuracy: 1.0000\n",
      " 55/727 [=>............................] - ETA: 0s - loss: 0.4463 - accuracy: 0.8091\u001b[0m\n",
      "\u001b[34m111/727 [===>..........................] - ETA: 0s - loss: 0.4265 - accuracy: 0.8108\u001b[0m\n",
      "\u001b[34m169/727 [=====>........................] - ETA: 0s - loss: 0.4377 - accuracy: 0.7959\u001b[0m\n",
      "\u001b[34m227/727 [========>.....................] - ETA: 0s - loss: 0.4542 - accuracy: 0.7841\u001b[0m\n",
      "\u001b[34m282/727 [==========>...................] - ETA: 0s - loss: 0.4529 - accuracy: 0.7872\u001b[0m\n",
      "\u001b[34m340/727 [=============>................] - ETA: 0s - loss: 0.4501 - accuracy: 0.7882\u001b[0m\n",
      "\u001b[34m395/727 [===============>..............] - ETA: 0s - loss: 0.4659 - accuracy: 0.7823\u001b[0m\n",
      "\u001b[34m448/727 [=================>............] - ETA: 0s - loss: 0.4599 - accuracy: 0.7879\u001b[0m\n",
      "\u001b[34m505/727 [===================>..........] - ETA: 0s - loss: 0.4649 - accuracy: 0.7802\u001b[0m\n",
      "\u001b[34m564/727 [======================>.......] - ETA: 0s - loss: 0.4640 - accuracy: 0.7801\u001b[0m\n",
      "\u001b[34m623/727 [========================>.....] - ETA: 0s - loss: 0.4644 - accuracy: 0.7809\u001b[0m\n",
      "\u001b[34m678/727 [==========================>...] - ETA: 0s - loss: 0.4647 - accuracy: 0.7817\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 892us/step - loss: 0.4641 - accuracy: 0.7827\u001b[0m\n",
      "\u001b[34mEpoch 77/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6080 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4359 - accuracy: 0.7500\u001b[0m\n",
      "\u001b[34m119/727 [===>..........................] - ETA: 0s - loss: 0.4420 - accuracy: 0.7605\u001b[0m\n",
      "\u001b[34m178/727 [======>.......................] - ETA: 0s - loss: 0.4392 - accuracy: 0.7697\u001b[0m\n",
      "\u001b[34m236/727 [========>.....................] - ETA: 0s - loss: 0.4494 - accuracy: 0.7669\u001b[0m\n",
      "\u001b[34m291/727 [===========>..................] - ETA: 0s - loss: 0.4502 - accuracy: 0.7698\u001b[0m\n",
      "\u001b[34m339/727 [============>.................] - ETA: 0s - loss: 0.4357 - accuracy: 0.7876\u001b[0m\n",
      "\u001b[34m377/727 [==============>...............] - ETA: 0s - loss: 0.4367 - accuracy: 0.7891\u001b[0m\n",
      "\u001b[34m412/727 [================>.............] - ETA: 0s - loss: 0.4391 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m461/727 [==================>...........] - ETA: 0s - loss: 0.4312 - accuracy: 0.7983\u001b[0m\n",
      "\u001b[34m520/727 [====================>.........] - ETA: 0s - loss: 0.4396 - accuracy: 0.7933\u001b[0m\n",
      "\u001b[34m580/727 [======================>.......] - ETA: 0s - loss: 0.4402 - accuracy: 0.7931\u001b[0m\n",
      "\u001b[34m637/727 [=========================>....] - ETA: 0s - loss: 0.4438 - accuracy: 0.7920\u001b[0m\n",
      "\u001b[34m692/727 [===========================>..] - ETA: 0s - loss: 0.4482 - accuracy: 0.7919\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 948us/step - loss: 0.4486 - accuracy: 0.7902\u001b[0m\n",
      "\u001b[34mEpoch 78/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2532 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4735 - accuracy: 0.7459\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4599 - accuracy: 0.7603\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.4543 - accuracy: 0.7709\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4626 - accuracy: 0.7699\u001b[0m\n",
      "\u001b[34m295/727 [===========>..................] - ETA: 0s - loss: 0.4456 - accuracy: 0.7746\u001b[0m\n",
      "\u001b[34m354/727 [=============>................] - ETA: 0s - loss: 0.4470 - accuracy: 0.7782\u001b[0m\n",
      "\u001b[34m409/727 [===============>..............] - ETA: 0s - loss: 0.4501 - accuracy: 0.7751\u001b[0m\n",
      "\u001b[34m469/727 [==================>...........] - ETA: 0s - loss: 0.4509 - accuracy: 0.7761\u001b[0m\n",
      "\u001b[34m529/727 [====================>.........] - ETA: 0s - loss: 0.4496 - accuracy: 0.7807\u001b[0m\n",
      "\u001b[34m588/727 [=======================>......] - ETA: 0s - loss: 0.4494 - accuracy: 0.7823\u001b[0m\n",
      "\u001b[34m647/727 [=========================>....] - ETA: 0s - loss: 0.4482 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34m703/727 [============================>.] - ETA: 0s - loss: 0.4497 - accuracy: 0.7859\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 869us/step - loss: 0.4493 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34mEpoch 79/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.5224 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.5032 - accuracy: 0.7459\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4713 - accuracy: 0.7769\u001b[0m\n",
      "\u001b[34m181/727 [======>.......................] - ETA: 0s - loss: 0.4780 - accuracy: 0.7707\u001b[0m\n",
      "\u001b[34m241/727 [========>.....................] - ETA: 0s - loss: 0.4844 - accuracy: 0.7697\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4671 - accuracy: 0.7767\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4656 - accuracy: 0.7751\u001b[0m\n",
      "\u001b[34m418/727 [================>.............] - ETA: 0s - loss: 0.4588 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m477/727 [==================>...........] - ETA: 0s - loss: 0.4570 - accuracy: 0.7799\u001b[0m\n",
      "\u001b[34m537/727 [=====================>........] - ETA: 0s - loss: 0.4601 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m596/727 [=======================>......] - ETA: 0s - loss: 0.4582 - accuracy: 0.7802\u001b[0m\n",
      "\u001b[34m655/727 [==========================>...] - ETA: 0s - loss: 0.4538 - accuracy: 0.7870\u001b[0m\n",
      "\u001b[34m712/727 [============================>.] - ETA: 0s - loss: 0.4555 - accuracy: 0.7900\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 859us/step - loss: 0.4530 - accuracy: 0.7916\u001b[0m\n",
      "\u001b[34mEpoch 80/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1274 - accuracy: 1.0000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.5109 - accuracy: 0.7411\u001b[0m\n",
      "\u001b[34m107/727 [===>..........................] - ETA: 0s - loss: 0.4790 - accuracy: 0.7710\u001b[0m\n",
      "\u001b[34m167/727 [=====>........................] - ETA: 0s - loss: 0.4553 - accuracy: 0.7844\u001b[0m\n",
      "\u001b[34m226/727 [========>.....................] - ETA: 0s - loss: 0.4453 - accuracy: 0.7965\u001b[0m\n",
      "\u001b[34m283/727 [==========>...................] - ETA: 0s - loss: 0.4402 - accuracy: 0.7986\u001b[0m\n",
      "\u001b[34m342/727 [=============>................] - ETA: 0s - loss: 0.4432 - accuracy: 0.7982\u001b[0m\n",
      "\u001b[34m399/727 [===============>..............] - ETA: 0s - loss: 0.4500 - accuracy: 0.7932\u001b[0m\n",
      "\u001b[34m458/727 [=================>............] - ETA: 0s - loss: 0.4518 - accuracy: 0.7904\u001b[0m\n",
      "\u001b[34m518/727 [====================>.........] - ETA: 0s - loss: 0.4529 - accuracy: 0.7876\u001b[0m\n",
      "\u001b[34m575/727 [======================>.......] - ETA: 0s - loss: 0.4514 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m635/727 [=========================>....] - ETA: 0s - loss: 0.4570 - accuracy: 0.7866\u001b[0m\n",
      "\u001b[34m693/727 [===========================>..] - ETA: 0s - loss: 0.4549 - accuracy: 0.7872\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 873us/step - loss: 0.4531 - accuracy: 0.7889\u001b[0m\n",
      "\u001b[34mEpoch 81/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.4181 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4513 - accuracy: 0.7459\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4244 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.4525 - accuracy: 0.7821\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4553 - accuracy: 0.7803\u001b[0m\n",
      "\u001b[34m299/727 [===========>..................] - ETA: 0s - loss: 0.4405 - accuracy: 0.7993\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4460 - accuracy: 0.7961\u001b[0m\n",
      "\u001b[34m418/727 [================>.............] - ETA: 0s - loss: 0.4504 - accuracy: 0.7931\u001b[0m\n",
      "\u001b[34m473/727 [==================>...........] - ETA: 0s - loss: 0.4502 - accuracy: 0.7960\u001b[0m\n",
      "\u001b[34m533/727 [====================>.........] - ETA: 0s - loss: 0.4474 - accuracy: 0.7946\u001b[0m\n",
      "\u001b[34m593/727 [=======================>......] - ETA: 0s - loss: 0.4440 - accuracy: 0.7951\u001b[0m\n",
      "\u001b[34m653/727 [=========================>....] - ETA: 0s - loss: 0.4435 - accuracy: 0.7971\u001b[0m\n",
      "\u001b[34m711/727 [============================>.] - ETA: 0s - loss: 0.4521 - accuracy: 0.7925\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 852us/step - loss: 0.4489 - accuracy: 0.7944\u001b[0m\n",
      "\u001b[34mEpoch 82/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2850 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.3869 - accuracy: 0.8033\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4439 - accuracy: 0.7958\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.4362 - accuracy: 0.7961\u001b[0m\n",
      "\u001b[34m238/727 [========>.....................] - ETA: 0s - loss: 0.4397 - accuracy: 0.7878\u001b[0m\n",
      "\u001b[34m297/727 [===========>..................] - ETA: 0s - loss: 0.4366 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m356/727 [=============>................] - ETA: 0s - loss: 0.4324 - accuracy: 0.7907\u001b[0m\n",
      "\u001b[34m415/727 [================>.............] - ETA: 0s - loss: 0.4399 - accuracy: 0.7892\u001b[0m\n",
      "\u001b[34m475/727 [==================>...........] - ETA: 0s - loss: 0.4341 - accuracy: 0.7926\u001b[0m\n",
      "\u001b[34m535/727 [=====================>........] - ETA: 0s - loss: 0.4255 - accuracy: 0.8009\u001b[0m\n",
      "\u001b[34m594/727 [=======================>......] - ETA: 0s - loss: 0.4285 - accuracy: 0.7963\u001b[0m\n",
      "\u001b[34m654/727 [=========================>....] - ETA: 0s - loss: 0.4298 - accuracy: 0.7951\u001b[0m\n",
      "\u001b[34m714/727 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.7920\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 849us/step - loss: 0.4360 - accuracy: 0.7916\u001b[0m\n",
      "\u001b[34mEpoch 83/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1330 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4715 - accuracy: 0.7459\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4498 - accuracy: 0.7603\u001b[0m\n",
      "\u001b[34m176/727 [======>.......................] - ETA: 0s - loss: 0.4561 - accuracy: 0.7699\u001b[0m\n",
      "\u001b[34m235/727 [========>.....................] - ETA: 0s - loss: 0.4685 - accuracy: 0.7681\u001b[0m\n",
      "\u001b[34m294/727 [===========>..................] - ETA: 0s - loss: 0.4641 - accuracy: 0.7772\u001b[0m\n",
      "\u001b[34m354/727 [=============>................] - ETA: 0s - loss: 0.4530 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m413/727 [================>.............] - ETA: 0s - loss: 0.4488 - accuracy: 0.7893\u001b[0m\n",
      "\u001b[34m472/727 [==================>...........] - ETA: 0s - loss: 0.4424 - accuracy: 0.7913\u001b[0m\n",
      "\u001b[34m532/727 [====================>.........] - ETA: 0s - loss: 0.4426 - accuracy: 0.7932\u001b[0m\n",
      "\u001b[34m592/727 [=======================>......] - ETA: 0s - loss: 0.4492 - accuracy: 0.7914\u001b[0m\n",
      "\u001b[34m648/727 [=========================>....] - ETA: 0s - loss: 0.4524 - accuracy: 0.7894\u001b[0m\n",
      "\u001b[34m702/727 [===========================>..] - ETA: 0s - loss: 0.4565 - accuracy: 0.7863\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 886us/step - loss: 0.4522 - accuracy: 0.7889\u001b[0m\n",
      "\u001b[34mEpoch 84/100\n",
      "  1/727 [..............................] - ETA: 1s - loss: 0.5992 - accuracy: 0.5000\n",
      " 41/727 [>.............................] - ETA: 0s - loss: 0.4470 - accuracy: 0.7317\n",
      " 80/727 [==>...........................] - ETA: 0s - loss: 0.4333 - accuracy: 0.7750\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4391 - accuracy: 0.7743\u001b[0m\n",
      "\u001b[34m157/727 [=====>........................] - ETA: 0s - loss: 0.4086 - accuracy: 0.7898\u001b[0m\n",
      "\u001b[34m216/727 [=======>......................] - ETA: 0s - loss: 0.4285 - accuracy: 0.7870\u001b[0m\n",
      "\u001b[34m276/727 [==========>...................] - ETA: 0s - loss: 0.4381 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m336/727 [============>.................] - ETA: 0s - loss: 0.4474 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m394/727 [===============>..............] - ETA: 0s - loss: 0.4398 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34m454/727 [=================>............] - ETA: 0s - loss: 0.4374 - accuracy: 0.7874\u001b[0m\n",
      "\u001b[34m510/727 [====================>.........] - ETA: 0s - loss: 0.4302 - accuracy: 0.7922\u001b[0m\n",
      "\u001b[34m569/727 [======================>.......] - ETA: 0s - loss: 0.4378 - accuracy: 0.7882\u001b[0m\n",
      "\u001b[34m628/727 [========================>.....] - ETA: 0s - loss: 0.4392 - accuracy: 0.7874\u001b[0m\n",
      "\u001b[34m688/727 [===========================>..] - ETA: 0s - loss: 0.4443 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 953us/step - loss: 0.4460 - accuracy: 0.7834\u001b[0m\n",
      "\u001b[34mEpoch 85/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.7929 - accuracy: 0.5000\n",
      " 60/727 [=>............................] - ETA: 0s - loss: 0.4084 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4243 - accuracy: 0.8083\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.4130 - accuracy: 0.8073\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4172 - accuracy: 0.7992\u001b[0m\n",
      "\u001b[34m299/727 [===========>..................] - ETA: 0s - loss: 0.4204 - accuracy: 0.8010\u001b[0m\n",
      "\u001b[34m359/727 [=============>................] - ETA: 0s - loss: 0.4306 - accuracy: 0.7939\u001b[0m\n",
      "\u001b[34m419/727 [================>.............] - ETA: 0s - loss: 0.4297 - accuracy: 0.7959\u001b[0m\n",
      "\u001b[34m478/727 [==================>...........] - ETA: 0s - loss: 0.4272 - accuracy: 0.7950\u001b[0m\n",
      "\u001b[34m528/727 [====================>.........] - ETA: 0s - loss: 0.4282 - accuracy: 0.7917\u001b[0m\n",
      "\u001b[34m583/727 [=======================>......] - ETA: 0s - loss: 0.4352 - accuracy: 0.7882\u001b[0m\n",
      "\u001b[34m643/727 [=========================>....] - ETA: 0s - loss: 0.4416 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34m703/727 [============================>.] - ETA: 0s - loss: 0.4449 - accuracy: 0.7852\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 863us/step - loss: 0.4420 - accuracy: 0.7875\u001b[0m\n",
      "\u001b[34mEpoch 86/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2451 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4123 - accuracy: 0.8197\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4236 - accuracy: 0.8208\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.4506 - accuracy: 0.7972\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.4626 - accuracy: 0.7897\u001b[0m\n",
      "\u001b[34m293/727 [===========>..................] - ETA: 0s - loss: 0.4580 - accuracy: 0.7969\u001b[0m\n",
      "\u001b[34m349/727 [=============>................] - ETA: 0s - loss: 0.4534 - accuracy: 0.7980\u001b[0m\n",
      "\u001b[34m409/727 [===============>..............] - ETA: 0s - loss: 0.4554 - accuracy: 0.7922\u001b[0m\n",
      "\u001b[34m468/727 [==================>...........] - ETA: 0s - loss: 0.4519 - accuracy: 0.7906\u001b[0m\n",
      "\u001b[34m526/727 [====================>.........] - ETA: 0s - loss: 0.4545 - accuracy: 0.7823\u001b[0m\n",
      "\u001b[34m575/727 [======================>.......] - ETA: 0s - loss: 0.4512 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m625/727 [========================>.....] - ETA: 0s - loss: 0.4488 - accuracy: 0.7856\u001b[0m\n",
      "\u001b[34m684/727 [===========================>..] - ETA: 0s - loss: 0.4444 - accuracy: 0.7909\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 885us/step - loss: 0.4465 - accuracy: 0.7923\u001b[0m\n",
      "\u001b[34mEpoch 87/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2331 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4649 - accuracy: 0.8033\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4749 - accuracy: 0.7727\u001b[0m\n",
      "\u001b[34m181/727 [======>.......................] - ETA: 0s - loss: 0.4484 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m241/727 [========>.....................] - ETA: 0s - loss: 0.4408 - accuracy: 0.7946\u001b[0m\n",
      "\u001b[34m301/727 [===========>..................] - ETA: 0s - loss: 0.4421 - accuracy: 0.8007\u001b[0m\n",
      "\u001b[34m361/727 [=============>................] - ETA: 0s - loss: 0.4401 - accuracy: 0.7992\u001b[0m\n",
      "\u001b[34m421/727 [================>.............] - ETA: 0s - loss: 0.4491 - accuracy: 0.7933\u001b[0m\n",
      "\u001b[34m481/727 [==================>...........] - ETA: 0s - loss: 0.4530 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m540/727 [=====================>........] - ETA: 0s - loss: 0.4488 - accuracy: 0.7889\u001b[0m\n",
      "\u001b[34m599/727 [=======================>......] - ETA: 0s - loss: 0.4513 - accuracy: 0.7922\u001b[0m\n",
      "\u001b[34m653/727 [=========================>....] - ETA: 0s - loss: 0.4544 - accuracy: 0.7902\u001b[0m\n",
      "\u001b[34m706/727 [============================>.] - ETA: 0s - loss: 0.4518 - accuracy: 0.7925\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 866us/step - loss: 0.4468 - accuracy: 0.7964\u001b[0m\n",
      "\u001b[34mEpoch 88/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.5766 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4246 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4367 - accuracy: 0.7810\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.4432 - accuracy: 0.7889\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4465 - accuracy: 0.7866\u001b[0m\n",
      "\u001b[34m299/727 [===========>..................] - ETA: 0s - loss: 0.4486 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4513 - accuracy: 0.7835\u001b[0m\n",
      "\u001b[34m418/727 [================>.............] - ETA: 0s - loss: 0.4537 - accuracy: 0.7811\u001b[0m\n",
      "\u001b[34m478/727 [==================>...........] - ETA: 0s - loss: 0.4604 - accuracy: 0.7793\u001b[0m\n",
      "\u001b[34m538/727 [=====================>........] - ETA: 0s - loss: 0.4533 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m598/727 [=======================>......] - ETA: 0s - loss: 0.4578 - accuracy: 0.7826\u001b[0m\n",
      "\u001b[34m658/727 [==========================>...] - ETA: 0s - loss: 0.4580 - accuracy: 0.7804\u001b[0m\n",
      "\u001b[34m714/727 [============================>.] - ETA: 0s - loss: 0.4581 - accuracy: 0.7829\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 848us/step - loss: 0.4578 - accuracy: 0.7820\u001b[0m\n",
      "\u001b[34mEpoch 89/100\u001b[0m\n",
      "\u001b[34m  1/727 [..............................] - ETA: 0s - loss: 0.4465 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4016 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4219 - accuracy: 0.8017\u001b[0m\n",
      "\u001b[34m181/727 [======>.......................] - ETA: 0s - loss: 0.4276 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m240/727 [========>.....................] - ETA: 0s - loss: 0.4320 - accuracy: 0.7812\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4319 - accuracy: 0.7767\u001b[0m\n",
      "\u001b[34m359/727 [=============>................] - ETA: 0s - loss: 0.4450 - accuracy: 0.7730\u001b[0m\n",
      "\u001b[34m415/727 [================>.............] - ETA: 0s - loss: 0.4511 - accuracy: 0.7747\u001b[0m\n",
      "\u001b[34m474/727 [==================>...........] - ETA: 0s - loss: 0.4584 - accuracy: 0.7732\u001b[0m\n",
      "\u001b[34m534/727 [=====================>........] - ETA: 0s - loss: 0.4623 - accuracy: 0.7725\u001b[0m\n",
      "\u001b[34m594/727 [=======================>......] - ETA: 0s - loss: 0.4514 - accuracy: 0.7795\u001b[0m\n",
      "\u001b[34m653/727 [=========================>....] - ETA: 0s - loss: 0.4506 - accuracy: 0.7810\u001b[0m\n",
      "\u001b[34m713/727 [============================>.] - ETA: 0s - loss: 0.4516 - accuracy: 0.7833\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 851us/step - loss: 0.4494 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34mEpoch 90/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.0806 - accuracy: 1.0000\n",
      " 56/727 [=>............................] - ETA: 0s - loss: 0.4392 - accuracy: 0.8036\u001b[0m\n",
      "\u001b[34m113/727 [===>..........................] - ETA: 0s - loss: 0.4720 - accuracy: 0.7832\u001b[0m\n",
      "\u001b[34m173/727 [======>.......................] - ETA: 0s - loss: 0.4522 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m233/727 [========>.....................] - ETA: 0s - loss: 0.4415 - accuracy: 0.7983\u001b[0m\n",
      "\u001b[34m293/727 [===========>..................] - ETA: 0s - loss: 0.4489 - accuracy: 0.7901\u001b[0m\n",
      "\u001b[34m353/727 [=============>................] - ETA: 0s - loss: 0.4593 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m413/727 [================>.............] - ETA: 0s - loss: 0.4502 - accuracy: 0.7918\u001b[0m\n",
      "\u001b[34m463/727 [==================>...........] - ETA: 0s - loss: 0.4414 - accuracy: 0.7981\u001b[0m\n",
      "\u001b[34m521/727 [====================>.........] - ETA: 0s - loss: 0.4447 - accuracy: 0.7946\u001b[0m\n",
      "\u001b[34m581/727 [======================>.......] - ETA: 0s - loss: 0.4415 - accuracy: 0.7969\u001b[0m\n",
      "\u001b[34m640/727 [=========================>....] - ETA: 0s - loss: 0.4460 - accuracy: 0.7953\u001b[0m\n",
      "\u001b[34m700/727 [===========================>..] - ETA: 0s - loss: 0.4407 - accuracy: 0.7964\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 866us/step - loss: 0.4400 - accuracy: 0.7978\u001b[0m\n",
      "\u001b[34mEpoch 91/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3268 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.3994 - accuracy: 0.8443\u001b[0m\n",
      "\u001b[34m118/727 [===>..........................] - ETA: 0s - loss: 0.4004 - accuracy: 0.8220\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4350 - accuracy: 0.7966\u001b[0m\n",
      "\u001b[34m237/727 [========>.....................] - ETA: 0s - loss: 0.4175 - accuracy: 0.8080\u001b[0m\n",
      "\u001b[34m296/727 [===========>..................] - ETA: 0s - loss: 0.4310 - accuracy: 0.8007\u001b[0m\n",
      "\u001b[34m355/727 [=============>................] - ETA: 0s - loss: 0.4374 - accuracy: 0.7986\u001b[0m\n",
      "\u001b[34m415/727 [================>.............] - ETA: 0s - loss: 0.4557 - accuracy: 0.7904\u001b[0m\n",
      "\u001b[34m474/727 [==================>...........] - ETA: 0s - loss: 0.4515 - accuracy: 0.7932\u001b[0m\n",
      "\u001b[34m534/727 [=====================>........] - ETA: 0s - loss: 0.4508 - accuracy: 0.7940\u001b[0m\n",
      "\u001b[34m594/727 [=======================>......] - ETA: 0s - loss: 0.4437 - accuracy: 0.7963\u001b[0m\n",
      "\u001b[34m654/727 [=========================>....] - ETA: 0s - loss: 0.4365 - accuracy: 0.7982\u001b[0m\n",
      "\u001b[34m713/727 [============================>.] - ETA: 0s - loss: 0.4442 - accuracy: 0.7952\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 850us/step - loss: 0.4457 - accuracy: 0.7930\u001b[0m\n",
      "\u001b[34mEpoch 92/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.5060 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4150 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4268 - accuracy: 0.8140\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.4188 - accuracy: 0.8128\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4113 - accuracy: 0.8096\u001b[0m\n",
      "\u001b[34m299/727 [===========>..................] - ETA: 0s - loss: 0.4217 - accuracy: 0.8043\u001b[0m\n",
      "\u001b[34m359/727 [=============>................] - ETA: 0s - loss: 0.4170 - accuracy: 0.8120\u001b[0m\n",
      "\u001b[34m419/727 [================>.............] - ETA: 0s - loss: 0.4351 - accuracy: 0.7995\u001b[0m\n",
      "\u001b[34m479/727 [==================>...........] - ETA: 0s - loss: 0.4331 - accuracy: 0.7996\u001b[0m\n",
      "\u001b[34m538/727 [=====================>........] - ETA: 0s - loss: 0.4303 - accuracy: 0.8011\u001b[0m\n",
      "\u001b[34m593/727 [=======================>......] - ETA: 0s - loss: 0.4340 - accuracy: 0.8019\u001b[0m\n",
      "\u001b[34m652/727 [=========================>....] - ETA: 0s - loss: 0.4343 - accuracy: 0.7998\u001b[0m\n",
      "\u001b[34m712/727 [============================>.] - ETA: 0s - loss: 0.4382 - accuracy: 0.7971\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 852us/step - loss: 0.4388 - accuracy: 0.7957\u001b[0m\n",
      "\u001b[34mEpoch 93/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2099 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.3767 - accuracy: 0.8525\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4068 - accuracy: 0.8306\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.3940 - accuracy: 0.8333\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4222 - accuracy: 0.8117\u001b[0m\n",
      "\u001b[34m299/727 [===========>..................] - ETA: 0s - loss: 0.4173 - accuracy: 0.8144\u001b[0m\n",
      "\u001b[34m359/727 [=============>................] - ETA: 0s - loss: 0.4291 - accuracy: 0.8134\u001b[0m\n",
      "\u001b[34m419/727 [================>.............] - ETA: 0s - loss: 0.4281 - accuracy: 0.8091\u001b[0m\n",
      "\u001b[34m479/727 [==================>...........] - ETA: 0s - loss: 0.4374 - accuracy: 0.8017\u001b[0m\n",
      "\u001b[34m529/727 [====================>.........] - ETA: 0s - loss: 0.4490 - accuracy: 0.7958\u001b[0m\n",
      "\u001b[34m589/727 [=======================>......] - ETA: 0s - loss: 0.4483 - accuracy: 0.7954\u001b[0m\n",
      "\u001b[34m649/727 [=========================>....] - ETA: 0s - loss: 0.4516 - accuracy: 0.7897\u001b[0m\n",
      "\u001b[34m709/727 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.7884\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 857us/step - loss: 0.4543 - accuracy: 0.7895\u001b[0m\n",
      "\u001b[34mEpoch 94/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.6217 - accuracy: 0.5000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4580 - accuracy: 0.7541\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4407 - accuracy: 0.7769\u001b[0m\n",
      "\u001b[34m178/727 [======>.......................] - ETA: 0s - loss: 0.4363 - accuracy: 0.7837\u001b[0m\n",
      "\u001b[34m239/727 [========>.....................] - ETA: 0s - loss: 0.4239 - accuracy: 0.7971\u001b[0m\n",
      "\u001b[34m294/727 [===========>..................] - ETA: 0s - loss: 0.4345 - accuracy: 0.7959\u001b[0m\n",
      "\u001b[34m348/727 [=============>................] - ETA: 0s - loss: 0.4558 - accuracy: 0.7859\u001b[0m\n",
      "\u001b[34m408/727 [===============>..............] - ETA: 0s - loss: 0.4537 - accuracy: 0.7904\u001b[0m\n",
      "\u001b[34m467/727 [==================>...........] - ETA: 0s - loss: 0.4488 - accuracy: 0.7923\u001b[0m\n",
      "\u001b[34m526/727 [====================>.........] - ETA: 0s - loss: 0.4561 - accuracy: 0.7871\u001b[0m\n",
      "\u001b[34m585/727 [=======================>......] - ETA: 0s - loss: 0.4619 - accuracy: 0.7838\u001b[0m\n",
      "\u001b[34m641/727 [=========================>....] - ETA: 0s - loss: 0.4576 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m697/727 [===========================>..] - ETA: 0s - loss: 0.4558 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 868us/step - loss: 0.4568 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34mEpoch 95/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2708 - accuracy: 1.0000\n",
      " 62/727 [=>............................] - ETA: 0s - loss: 0.4473 - accuracy: 0.7661\u001b[0m\n",
      "\u001b[34m122/727 [====>.........................] - ETA: 0s - loss: 0.4895 - accuracy: 0.7664\u001b[0m\n",
      "\u001b[34m181/727 [======>.......................] - ETA: 0s - loss: 0.4668 - accuracy: 0.7790\u001b[0m\n",
      "\u001b[34m241/727 [========>.....................] - ETA: 0s - loss: 0.4633 - accuracy: 0.7822\u001b[0m\n",
      "\u001b[34m301/727 [===========>..................] - ETA: 0s - loss: 0.4597 - accuracy: 0.7824\u001b[0m\n",
      "\u001b[34m360/727 [=============>................] - ETA: 0s - loss: 0.4604 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m420/727 [================>.............] - ETA: 0s - loss: 0.4651 - accuracy: 0.7845\u001b[0m\n",
      "\u001b[34m480/727 [==================>...........] - ETA: 0s - loss: 0.4562 - accuracy: 0.7927\u001b[0m\n",
      "\u001b[34m539/727 [=====================>........] - ETA: 0s - loss: 0.4500 - accuracy: 0.7978\u001b[0m\n",
      "\u001b[34m598/727 [=======================>......] - ETA: 0s - loss: 0.4501 - accuracy: 0.7968\u001b[0m\n",
      "\u001b[34m658/727 [==========================>...] - ETA: 0s - loss: 0.4528 - accuracy: 0.7956\u001b[0m\n",
      "\u001b[34m711/727 [============================>.] - ETA: 0s - loss: 0.4534 - accuracy: 0.7947\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 854us/step - loss: 0.4534 - accuracy: 0.7944\u001b[0m\n",
      "\u001b[34mEpoch 96/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.9196 - accuracy: 0.5000\n",
      " 54/727 [=>............................] - ETA: 0s - loss: 0.4581 - accuracy: 0.7778\u001b[0m\n",
      "\u001b[34m114/727 [===>..........................] - ETA: 0s - loss: 0.4452 - accuracy: 0.7895\u001b[0m\n",
      "\u001b[34m174/727 [======>.......................] - ETA: 0s - loss: 0.4446 - accuracy: 0.7874\u001b[0m\n",
      "\u001b[34m234/727 [========>.....................] - ETA: 0s - loss: 0.4476 - accuracy: 0.7842\u001b[0m\n",
      "\u001b[34m293/727 [===========>..................] - ETA: 0s - loss: 0.4524 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m353/727 [=============>................] - ETA: 0s - loss: 0.4537 - accuracy: 0.7918\u001b[0m\n",
      "\u001b[34m412/727 [================>.............] - ETA: 0s - loss: 0.4537 - accuracy: 0.7888\u001b[0m\n",
      "\u001b[34m471/727 [==================>...........] - ETA: 0s - loss: 0.4518 - accuracy: 0.7898\u001b[0m\n",
      "\u001b[34m531/727 [====================>.........] - ETA: 0s - loss: 0.4519 - accuracy: 0.7872\u001b[0m\n",
      "\u001b[34m591/727 [=======================>......] - ETA: 0s - loss: 0.4515 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m651/727 [=========================>....] - ETA: 0s - loss: 0.4480 - accuracy: 0.7880\u001b[0m\n",
      "\u001b[34m711/727 [============================>.] - ETA: 0s - loss: 0.4402 - accuracy: 0.7947\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 854us/step - loss: 0.4399 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34mEpoch 97/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.2740 - accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m 61/727 [=>............................] - ETA: 0s - loss: 0.4456 - accuracy: 0.7869\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4157 - accuracy: 0.8042\u001b[0m\n",
      "\u001b[34m180/727 [======>.......................] - ETA: 0s - loss: 0.4168 - accuracy: 0.8056\u001b[0m\n",
      "\u001b[34m240/727 [========>.....................] - ETA: 0s - loss: 0.4072 - accuracy: 0.8188\u001b[0m\n",
      "\u001b[34m300/727 [===========>..................] - ETA: 0s - loss: 0.4084 - accuracy: 0.8217\u001b[0m\n",
      "\u001b[34m360/727 [=============>................] - ETA: 0s - loss: 0.4156 - accuracy: 0.8111\u001b[0m\n",
      "\u001b[34m420/727 [================>.............] - ETA: 0s - loss: 0.4179 - accuracy: 0.8083\u001b[0m\n",
      "\u001b[34m476/727 [==================>...........] - ETA: 0s - loss: 0.4254 - accuracy: 0.8004\u001b[0m\n",
      "\u001b[34m535/727 [=====================>........] - ETA: 0s - loss: 0.4352 - accuracy: 0.7963\u001b[0m\n",
      "\u001b[34m595/727 [=======================>......] - ETA: 0s - loss: 0.4364 - accuracy: 0.7950\u001b[0m\n",
      "\u001b[34m654/727 [=========================>....] - ETA: 0s - loss: 0.4397 - accuracy: 0.7920\u001b[0m\n",
      "\u001b[34m714/727 [============================>.] - ETA: 0s - loss: 0.4425 - accuracy: 0.7906\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 849us/step - loss: 0.4464 - accuracy: 0.7895\u001b[0m\n",
      "\u001b[34mEpoch 98/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1201 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4545 - accuracy: 0.7787\u001b[0m\n",
      "\u001b[34m120/727 [===>..........................] - ETA: 0s - loss: 0.4460 - accuracy: 0.7708\u001b[0m\n",
      "\u001b[34m179/727 [======>.......................] - ETA: 0s - loss: 0.4520 - accuracy: 0.7737\u001b[0m\n",
      "\u001b[34m238/727 [========>.....................] - ETA: 0s - loss: 0.4734 - accuracy: 0.7689\u001b[0m\n",
      "\u001b[34m298/727 [===========>..................] - ETA: 0s - loss: 0.4716 - accuracy: 0.7685\u001b[0m\n",
      "\u001b[34m358/727 [=============>................] - ETA: 0s - loss: 0.4692 - accuracy: 0.7709\u001b[0m\n",
      "\u001b[34m417/727 [================>.............] - ETA: 0s - loss: 0.4611 - accuracy: 0.7758\u001b[0m\n",
      "\u001b[34m477/727 [==================>...........] - ETA: 0s - loss: 0.4497 - accuracy: 0.7841\u001b[0m\n",
      "\u001b[34m536/727 [=====================>........] - ETA: 0s - loss: 0.4482 - accuracy: 0.7873\u001b[0m\n",
      "\u001b[34m595/727 [=======================>......] - ETA: 0s - loss: 0.4490 - accuracy: 0.7849\u001b[0m\n",
      "\u001b[34m655/727 [==========================>...] - ETA: 0s - loss: 0.4471 - accuracy: 0.7847\u001b[0m\n",
      "\u001b[34m714/727 [============================>.] - ETA: 0s - loss: 0.4492 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 850us/step - loss: 0.4467 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34mEpoch 99/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.1166 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4546 - accuracy: 0.8033\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4367 - accuracy: 0.7893\u001b[0m\n",
      "\u001b[34m177/727 [======>.......................] - ETA: 0s - loss: 0.4461 - accuracy: 0.7825\u001b[0m\n",
      "\u001b[34m236/727 [========>.....................] - ETA: 0s - loss: 0.4350 - accuracy: 0.7881\u001b[0m\n",
      "\u001b[34m296/727 [===========>..................] - ETA: 0s - loss: 0.4332 - accuracy: 0.7855\u001b[0m\n",
      "\u001b[34m355/727 [=============>................] - ETA: 0s - loss: 0.4290 - accuracy: 0.7887\u001b[0m\n",
      "\u001b[34m414/727 [================>.............] - ETA: 0s - loss: 0.4394 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m473/727 [==================>...........] - ETA: 0s - loss: 0.4350 - accuracy: 0.7854\u001b[0m\n",
      "\u001b[34m533/727 [====================>.........] - ETA: 0s - loss: 0.4417 - accuracy: 0.7861\u001b[0m\n",
      "\u001b[34m593/727 [=======================>......] - ETA: 0s - loss: 0.4410 - accuracy: 0.7850\u001b[0m\n",
      "\u001b[34m653/727 [=========================>....] - ETA: 0s - loss: 0.4425 - accuracy: 0.7864\u001b[0m\n",
      "\u001b[34m713/727 [============================>.] - ETA: 0s - loss: 0.4481 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 850us/step - loss: 0.4481 - accuracy: 0.7868\u001b[0m\n",
      "\u001b[34mEpoch 100/100\n",
      "  1/727 [..............................] - ETA: 0s - loss: 0.3796 - accuracy: 1.0000\n",
      " 61/727 [=>............................] - ETA: 0s - loss: 0.4576 - accuracy: 0.7459\u001b[0m\n",
      "\u001b[34m121/727 [===>..........................] - ETA: 0s - loss: 0.4707 - accuracy: 0.7521\u001b[0m\n",
      "\u001b[34m181/727 [======>.......................] - ETA: 0s - loss: 0.4588 - accuracy: 0.7597\u001b[0m\n",
      "\u001b[34m225/727 [========>.....................] - ETA: 0s - loss: 0.4406 - accuracy: 0.7733\u001b[0m\n",
      "\u001b[34m283/727 [==========>...................] - ETA: 0s - loss: 0.4418 - accuracy: 0.7792\u001b[0m\n",
      "\u001b[34m343/727 [=============>................] - ETA: 0s - loss: 0.4384 - accuracy: 0.7843\u001b[0m\n",
      "\u001b[34m402/727 [===============>..............] - ETA: 0s - loss: 0.4385 - accuracy: 0.7836\u001b[0m\n",
      "\u001b[34m462/727 [==================>...........] - ETA: 0s - loss: 0.4344 - accuracy: 0.7900\u001b[0m\n",
      "\u001b[34m522/727 [====================>.........] - ETA: 0s - loss: 0.4320 - accuracy: 0.7931\u001b[0m\n",
      "\u001b[34m581/727 [======================>.......] - ETA: 0s - loss: 0.4277 - accuracy: 0.7926\u001b[0m\n",
      "\u001b[34m634/727 [=========================>....] - ETA: 0s - loss: 0.4298 - accuracy: 0.7934\u001b[0m\n",
      "\u001b[34m693/727 [===========================>..] - ETA: 0s - loss: 0.4271 - accuracy: 0.7908\u001b[0m\n",
      "\u001b[34m727/727 [==============================] - 1s 874us/step - loss: 0.4232 - accuracy: 0.7937\u001b[0m\n",
      "\u001b[34mTraining Data accuracy: 81.29%\u001b[0m\n",
      "\u001b[34mTraining is complete. Model saved.\u001b[0m\n",
      "\u001b[34mTest Data accuracy: 74.77%\u001b[0m\n",
      "\n",
      "2025-06-12 16:31:35 Uploading - Uploading generated training model\n",
      "2025-06-12 16:31:35 Completed - Training job completed\n",
      "Training seconds: 169\n",
      "Billable seconds: 169\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import datetime\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import json\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = 'local/'+model_name+'/input/data/training'\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix='data')\n",
    "print(data_location)\n",
    "\n",
    "conf_file='local/'+model_name+'/input/config/hyperparameters.json'\n",
    "with open(conf_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "print(config)\n",
    "\n",
    "prefix=model_name\n",
    "job_name=prefix.replace('_','-')\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = f'{account}.dkr.ecr.{region}.amazonaws.com/{prefix}:latest'\n",
    "\n",
    "classifier = sage.estimator.Estimator(\n",
    "    image_uri=image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "    sagemaker_session=sess,\n",
    "    base_job_name=job_name)\n",
    "classifier.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Model Artifact from Amazon S3 and copy it to Strategies Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "-rw-r--r-- 1 ec2-user ec2-user 45936 Jun 12 16:31 model.h5\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 45936 Jun 12 16:31 ../2_Strategies/model/model_long_short_predict.h5\n"
     ]
    }
   ],
   "source": [
    "#Get Model from S3\n",
    "model_name_s3=classifier.model_data.replace('s3://'+sess.default_bucket()+'/','')\n",
    "import boto3\n",
    "s3 = boto3.resource('s3')\n",
    "my_bucket = s3.Bucket(sess.default_bucket())\n",
    "my_bucket.download_file(model_name_s3,'model.tar.gz')\n",
    "!tar -xzf model.tar.gz\n",
    "!rm model.tar.gz\n",
    "!cp model.h5 ../2_Strategies/model/{model_name}.h5\n",
    "!ls -la model.h5\n",
    "!ls -la ../2_Strategies/model/model_*.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
